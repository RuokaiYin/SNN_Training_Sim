{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "251e3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b07e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e21ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PoissonGen(inp, rescale_fac=2.0):\n",
    "    rand_inp = torch.rand_like(inp)\n",
    "    return torch.mul(torch.le(rand_inp * rescale_fac, torch.abs(inp)).float(), torch.sign(inp))\n",
    "\n",
    "def de_func(U):\n",
    "    k=1\n",
    "    U = 1 - k*abs(U)\n",
    "    U[U<0]=0\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d766c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "        \n",
    "        self.fc_1 = nn.Linear(28*28,4)\n",
    "        self.fc_2 = nn.Linear(4,6)\n",
    "        self.fc_out = nn.Linear(6,3)\n",
    "        self.lif1 = LIF()\n",
    "        self.lif2 = LIF()\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        x = self.fc_1(x)\n",
    "        x = self.lif1(x, t)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.lif2(x, t)\n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e6f78f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LIF, self).__init__()\n",
    "        \n",
    "        self.u_regs = None\n",
    "        self.du_regs = None\n",
    "        self.s_regs = None\n",
    "        self.leak = 0.8\n",
    "        self.time_step = 5\n",
    "        self.thresh = 0.5\n",
    "        \n",
    "    def forward(self,inp, t):\n",
    "        if t == 0:\n",
    "            size = inp.shape\n",
    "            self.u_regs = torch.zeros(self.time_step,*size)\n",
    "            self.du_regs = torch.zeros(self.time_step,*size)\n",
    "            self.u_regs[0] = inp\n",
    "            self.s_regs = torch.zeros(self.time_step,*size)\n",
    "            vol = inp - self.thresh\n",
    "            spike = spike_function(vol, k=1)\n",
    "            self.s_regs[0] = spike\n",
    "        else:\n",
    "            self.u_regs[t] = self.leak * self.u_regs[t-1] * (1 - self.s_regs[t-1]) + inp\n",
    "            vol = self.u_regs[t] - self.thresh\n",
    "            spike = spike_function(vol, k=1)\n",
    "            self.s_regs[t] = spike\n",
    "\n",
    "        return spike\n",
    "\n",
    "        \n",
    "\n",
    "def spike_function(x, k):\n",
    "    x_fwd = torch.sign(x) * 0.5 + 0.5\n",
    "    x_bwd = torch.clamp(1 - k*x.abs(), min=0.)\n",
    "    return (x_fwd - x_bwd).detach() + x_bwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "091edb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Back propagation\n",
    "def bp(toy,leak,time_step):\n",
    "    ## Use same Output derivative throught bp\n",
    "    du_out = torch.exp(u_out)/torch.sum(torch.exp(u_out),1)\n",
    "\n",
    "    ## Second fc\n",
    "    du_fc2 = torch.matmul(du_out,toy.fc_out.weight)*de_func(toy.lif2.u_regs[-1])\n",
    "    toy.lif2.du_regs[-1].data += du_fc2\n",
    "    ## First fc\n",
    "    du_fc1 = torch.matmul(du_fc2,toy.fc_2.weight)*de_func(toy.lif1.u_regs[-1])\n",
    "    #print(du_fc1)\n",
    "    toy.lif1.du_regs[-1].data += du_fc1\n",
    "    #print(toy.lif1.du_regs[-1])\n",
    "\n",
    "    ## Update weight\n",
    "    w_inp_1 = torch.matmul(torch.transpose(du_fc1,0,1),s_regs_inp[-1])\n",
    "    toy.fc_1.weight.data += w_inp_1\n",
    "\n",
    "    w_1_2 = torch.matmul(torch.transpose(du_fc2,0,1),toy.lif1.s_regs[-1])\n",
    "    toy.fc_2.weight.data += w_1_2\n",
    "\n",
    "    w_2_out = torch.matmul(torch.transpose(du_out,0,1),toy.lif2.s_regs[-1])\n",
    "    toy.fc_out.weight.data += w_2_out\n",
    "\n",
    "    for t in range(time_step-2,-1,-1):\n",
    "        ds_fc2 = torch.matmul(du_out,toy.fc_out.weight)+toy.lif2.du_regs[t+1]*(-leak*toy.lif2.u_regs[t])\n",
    "        du_fc2 = (ds_fc2)*de_func(toy.lif2.u_regs[t]) + toy.lif2.du_regs[t+1]*leak*(1-toy.lif2.s_regs[t])\n",
    "        toy.lif2.du_regs[t].data += du_fc2\n",
    "        ## First fc\n",
    "        ds_fc1 = torch.matmul(du_fc2,toy.fc_2.weight)+toy.lif1.du_regs[t+1]*(-leak*toy.lif1.u_regs[t])\n",
    "        du_fc1 = (ds_fc1)*de_func(toy.lif1.u_regs[t]) + toy.lif1.du_regs[t+1]*leak*(1-toy.lif1.s_regs[t])\n",
    "        #print(du_fc1)\n",
    "        toy.lif1.du_regs[t].data += du_fc1\n",
    "        #print(toy.lif1.du_regs[-1])\n",
    "\n",
    "        ## Update weight\n",
    "        w_inp_1 = torch.matmul(torch.transpose(du_fc1,0,1),s_regs_inp[t])\n",
    "        toy.fc_1.weight.data += w_inp_1\n",
    "\n",
    "        w_1_2 = torch.matmul(torch.transpose(du_fc2,0,1),toy.lif1.s_regs[t])\n",
    "        toy.fc_2.weight.data += w_1_2\n",
    "\n",
    "        w_2_out = torch.matmul(torch.transpose(du_out,0,1),toy.lif2.s_regs[t])\n",
    "        toy.fc_out.weight.data += w_2_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e2ce9ca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6726, grad_fn=<NllLossBackward>)\n",
      "Parameter containing:\n",
      "tensor([[ 1.1844,  1.0711,  0.3113, -0.2409, -0.0202,  0.0259],\n",
      "        [ 0.9232,  0.7646,  0.1416,  0.3941, -0.3911, -0.3959],\n",
      "        [ 0.7645,  0.4797,  0.0421, -0.2835, -0.0146, -0.1894]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "inp = torch.rand(1,28,28,requires_grad = True)\n",
    "inp = inp.view(1,-1)\n",
    "\n",
    "toy = model()\n",
    "u_out = 0\n",
    "time_step = 5\n",
    "leak = 0.8\n",
    "\n",
    "size = inp.shape\n",
    "#s_regs_inp = torch.zeros_like(inp).expand(time_step, *size)\n",
    "s_regs_inp = torch.zeros(time_step,*size)\n",
    "\n",
    "\n",
    "for t in range(time_step):\n",
    "    spike_inp = PoissonGen(inp)\n",
    "  \n",
    "    s_regs_inp[t].data += spike_inp\n",
    "    \n",
    "    u_out = u_out + toy(spike_inp,t)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "target = torch.tensor([2])\n",
    "#l = -1*u_out[0][1]+torch.log(torch.exp(u_out[0][0])+torch.exp(u_out[0][1]))\n",
    "err = loss(u_out,target)\n",
    "# print(\"err:\",err)\n",
    "# print(\"u_out:\",u_out)\n",
    "#torch.exp(u_out[0][0])/(torch.exp(u_out[0][0])+torch.exp(u_out[0][1])+torch.exp(u_out[0][2]))-0\n",
    "print(err)\n",
    "bp(toy,leak,time_step)\n",
    "print(toy.fc_out.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e18758a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
