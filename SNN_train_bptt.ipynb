{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "251e3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b07e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e21ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PoissonGen(inp, rescale_fac=2.0):\n",
    "    rand_inp = torch.rand_like(inp)\n",
    "    return torch.mul(torch.le(rand_inp * rescale_fac, torch.abs(inp)).float(), torch.sign(inp))\n",
    "\n",
    "def spike_function(x, k):\n",
    "    x[x>0] = 1\n",
    "    x[x<=0] = 0\n",
    "    return x\n",
    "\n",
    "def de_func(U,th):\n",
    "    alpha = 0.3\n",
    "    U = alpha*(1.0 - abs((U-th)/th))\n",
    "    U[U<0]=0\n",
    "    return U\n",
    "\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        output = toy(data)\n",
    "        test_loss +=F.cross_entropy(output, target, size_average=False).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d766c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "        \n",
    "        self.fc_1 = nn.Linear(28*28,6,bias=False)\n",
    "        self.fc_2 = nn.Linear(6,4,bias=False)\n",
    "        self.fc_out = nn.Linear(4,10,bias=False)\n",
    "        self.lif1 = LIF()\n",
    "        self.lif2 = LIF()\n",
    "        self.time_step = 10\n",
    "        self.s_regs_inp = None\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        inp = inp.view(inp.shape[0],-1)\n",
    "        size = inp.shape\n",
    "        self.s_regs_inp = torch.zeros(self.time_step,*size)\n",
    "        u_out = 0\n",
    "        \n",
    "        for t in range(self.time_step):\n",
    "            \n",
    "            spike_inp = PoissonGen(inp)\n",
    "            self.s_regs_inp[t] += spike_inp \n",
    "            \n",
    "            x = self.fc_1(spike_inp)\n",
    "            x = self.lif1(x, t)\n",
    "            x = self.fc_2(x)\n",
    "            x = self.lif2(x, t)\n",
    "            x = self.fc_out(x)\n",
    "            u_out = u_out + x\n",
    "        return u_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db8d72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.fc_1 = nn.Linear(28*28,512,bias=False)\n",
    "        self.fc_out = nn.Linear(512,10,bias=False)\n",
    "        self.lif1 = LIF()\n",
    "        self.time_step = 7\n",
    "        self.s_regs_inp = None\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        \n",
    "        inp = inp.view(inp.shape[0],-1)\n",
    "        size = inp.shape\n",
    "        self.s_regs_inp = torch.zeros(self.time_step,*size)\n",
    "        u_out = 0\n",
    "        \n",
    "        for t in range(self.time_step):\n",
    "            spike_inp = PoissonGen(inp)\n",
    "            self.s_regs_inp[t] += spike_inp \n",
    "\n",
    "            x = self.fc_1(spike_inp)\n",
    "            x = self.lif1(x, t)\n",
    "            x = self.fc_out(x)\n",
    "            u_out = u_out + x\n",
    "        return u_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e6f78f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LIF, self).__init__()\n",
    "        \n",
    "        self.u_regs = None\n",
    "        self.du_regs = None\n",
    "        self.s_regs = None\n",
    "        self.leak = 0.99\n",
    "        self.time_step = 7\n",
    "        self.thresh = 0.5\n",
    "        \n",
    "    def forward(self,inp,t):\n",
    "        if t == 0:\n",
    "            size = inp.shape\n",
    "            self.u_regs = torch.zeros(self.time_step,*size)\n",
    "            self.du_regs = torch.zeros(self.time_step,*size)\n",
    "            self.u_regs[0] = inp\n",
    "            self.s_regs = torch.zeros(self.time_step,*size)\n",
    "\n",
    "            vol = inp - self.thresh\n",
    "\n",
    "            spike = spike_function(vol, k=1)\n",
    "\n",
    "            self.s_regs[0] = spike\n",
    "        else:\n",
    "            self.u_regs[t] = self.leak * self.u_regs[t-1] * (1 - self.s_regs[t-1]) + inp\n",
    "\n",
    "            vol = self.u_regs[t] - self.thresh\n",
    "\n",
    "            spike = spike_function(vol, k=1)\n",
    "\n",
    "            self.s_regs[t] = spike\n",
    "        return spike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8fc2dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Back propagation for MLP\n",
    "def bp_MLP(toy,leak,time_step,du_out,s_regs_inp,l_r,th):\n",
    "    \n",
    "    ## First fc\n",
    "    du_fc1 = torch.matmul(du_out,toy.fc_out.weight)*de_func(toy.lif1.u_regs[-1],th)\n",
    "    toy.lif1.du_regs[-1] += du_fc1\n",
    "\n",
    "    ## Update weight\n",
    "    w_inp_1 = torch.matmul(torch.transpose(du_fc1,0,1),s_regs_inp[-1])\n",
    "    toy.fc_1.weight.data -= l_r*w_inp_1\n",
    "\n",
    "    w_1_out = torch.matmul(torch.transpose(du_out,0,1),toy.lif1.s_regs[-1])\n",
    "    toy.fc_out.weight.data -= l_r*w_1_out\n",
    "\n",
    "    for t in range(time_step-2,-1,-1):\n",
    "        \n",
    "        ## First fc\n",
    "        ds_fc1 = torch.matmul(du_out,toy.fc_out.weight)+toy.lif1.du_regs[t+1]*(-leak*toy.lif1.u_regs[t])\n",
    "        du_fc1 = (ds_fc1)*de_func(toy.lif1.u_regs[t],th) + toy.lif1.du_regs[t+1]*leak*(1-toy.lif1.s_regs[t])\n",
    "        toy.lif1.du_regs[t] += du_fc1\n",
    "\n",
    "        ## Update weight\n",
    "        w_inp_1 = torch.matmul(torch.transpose(du_fc1,0,1),s_regs_inp[t])\n",
    "        toy.fc_1.weight.data -= l_r*w_inp_1\n",
    "\n",
    "        w_1_out = torch.matmul(torch.transpose(du_out,0,1),toy.lif1.s_regs[t])\n",
    "        toy.fc_out.weight.data -= l_r*w_1_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08084b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Back propagation\n",
    "def bp(toy,leak,time_step,du_out,s_regs_inp,l_r,th):\n",
    "    \n",
    "    ## Second fc    \n",
    "    du_fc2 = torch.matmul(du_out,toy.fc_out.weight)*de_func(toy.lif2.u_regs[-1],th)    \n",
    "    toy.lif2.du_regs[-1] = toy.lif2.du_regs[-1] + du_fc2\n",
    "    \n",
    "    ## First fc\n",
    "    du_fc1 = torch.matmul(du_fc2,toy.fc_2.weight)*de_func(toy.lif1.u_regs[-1],th)\n",
    "    toy.lif1.du_regs[-1] += du_fc1\n",
    "\n",
    "    \n",
    "    ## Update weight\n",
    "    w_inp_1 = torch.matmul(torch.transpose(du_fc1,0,1),s_regs_inp[-1])\n",
    "    toy.fc_1.weight.data += w_inp_1\n",
    "\n",
    "    w_1_2 = torch.matmul(torch.transpose(du_fc2,0,1),toy.lif1.s_regs[-1])\n",
    "    toy.fc_2.weight.data += w_1_2\n",
    "\n",
    "    w_2_out = torch.matmul(torch.transpose(du_out,0,1),toy.lif2.s_regs[-1])\n",
    "    toy.fc_out.weight.data += w_2_out\n",
    "\n",
    "    for t in range(time_step-2,-1,-1):\n",
    "\n",
    "        ds_fc2 = torch.matmul(du_out,toy.fc_out.weight)+toy.lif2.du_regs[t+1]*(-leak*toy.lif2.u_regs[t])\n",
    "        du_fc2 = (ds_fc2)*de_func(toy.lif2.u_regs[t],th) + toy.lif2.du_regs[t+1]*leak*(1-toy.lif2.s_regs[t])\n",
    "        toy.lif2.du_regs[t] += du_fc2\n",
    "        \n",
    "        ## First fc\n",
    "        ds_fc1 = torch.matmul(du_fc2,toy.fc_2.weight)+toy.lif1.du_regs[t+1]*(-leak*toy.lif1.u_regs[t])\n",
    "        du_fc1 = (ds_fc1)*de_func(toy.lif1.u_regs[t],th) + toy.lif1.du_regs[t+1]*leak*(1-toy.lif1.s_regs[t])\n",
    "        toy.lif1.du_regs[t] += du_fc1\n",
    "\n",
    "        ## Update weight\n",
    "        w_inp_1 = torch.matmul(torch.transpose(du_fc1,0,1),s_regs_inp[t])\n",
    "        toy.fc_1.weight.data -= l_r*w_inp_1\n",
    "\n",
    "        w_1_2 = torch.matmul(torch.transpose(du_fc2,0,1),toy.lif1.s_regs[t])\n",
    "        toy.fc_2.weight.data -= l_r*w_1_2\n",
    "\n",
    "        w_2_out = torch.matmul(torch.transpose(du_out,0,1),toy.lif2.s_regs[t])\n",
    "        toy.fc_out.weight.data -= l_r*w_2_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c3de0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b70c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = []\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(10 + 1)]\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2ce9ca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruokai\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.9761, Accuracy: 804/10000 (8%)\n",
      "\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.781648\n",
      "Train Epoch: 0 [640/60000 (1%)]\tLoss: 1.486200\n",
      "Train Epoch: 0 [1280/60000 (2%)]\tLoss: 1.063899\n",
      "Train Epoch: 0 [1920/60000 (3%)]\tLoss: 0.946516\n",
      "Train Epoch: 0 [2560/60000 (4%)]\tLoss: 0.475169\n",
      "Train Epoch: 0 [3200/60000 (5%)]\tLoss: 0.845716\n",
      "Train Epoch: 0 [3840/60000 (6%)]\tLoss: 0.596982\n",
      "Train Epoch: 0 [4480/60000 (7%)]\tLoss: 0.444111\n",
      "Train Epoch: 0 [5120/60000 (9%)]\tLoss: 0.170122\n",
      "Train Epoch: 0 [5760/60000 (10%)]\tLoss: 0.466288\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.457892\n",
      "Train Epoch: 0 [7040/60000 (12%)]\tLoss: 0.385550\n",
      "Train Epoch: 0 [7680/60000 (13%)]\tLoss: 0.531666\n",
      "Train Epoch: 0 [8320/60000 (14%)]\tLoss: 0.353850\n",
      "Train Epoch: 0 [8960/60000 (15%)]\tLoss: 0.241993\n",
      "Train Epoch: 0 [9600/60000 (16%)]\tLoss: 0.578200\n",
      "Train Epoch: 0 [10240/60000 (17%)]\tLoss: 0.406024\n",
      "Train Epoch: 0 [10880/60000 (18%)]\tLoss: 0.491234\n",
      "Train Epoch: 0 [11520/60000 (19%)]\tLoss: 0.437475\n",
      "Train Epoch: 0 [12160/60000 (20%)]\tLoss: 0.201537\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.210004\n",
      "Train Epoch: 0 [13440/60000 (22%)]\tLoss: 0.133798\n",
      "Train Epoch: 0 [14080/60000 (23%)]\tLoss: 0.216373\n",
      "Train Epoch: 0 [14720/60000 (25%)]\tLoss: 0.477743\n",
      "Train Epoch: 0 [15360/60000 (26%)]\tLoss: 0.296520\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.243184\n",
      "Train Epoch: 0 [16640/60000 (28%)]\tLoss: 0.353535\n",
      "Train Epoch: 0 [17280/60000 (29%)]\tLoss: 0.172906\n",
      "Train Epoch: 0 [17920/60000 (30%)]\tLoss: 0.469160\n",
      "Train Epoch: 0 [18560/60000 (31%)]\tLoss: 0.351160\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.310444\n",
      "Train Epoch: 0 [19840/60000 (33%)]\tLoss: 0.190314\n",
      "Train Epoch: 0 [20480/60000 (34%)]\tLoss: 0.130452\n",
      "Train Epoch: 0 [21120/60000 (35%)]\tLoss: 0.066076\n",
      "Train Epoch: 0 [21760/60000 (36%)]\tLoss: 0.208389\n",
      "Train Epoch: 0 [22400/60000 (37%)]\tLoss: 0.573641\n",
      "Train Epoch: 0 [23040/60000 (38%)]\tLoss: 0.139811\n",
      "Train Epoch: 0 [23680/60000 (39%)]\tLoss: 0.187126\n",
      "Train Epoch: 0 [24320/60000 (41%)]\tLoss: 0.148700\n",
      "Train Epoch: 0 [24960/60000 (42%)]\tLoss: 0.066782\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.088394\n",
      "Train Epoch: 0 [26240/60000 (44%)]\tLoss: 0.335195\n",
      "Train Epoch: 0 [26880/60000 (45%)]\tLoss: 0.317925\n",
      "Train Epoch: 0 [27520/60000 (46%)]\tLoss: 0.232317\n",
      "Train Epoch: 0 [28160/60000 (47%)]\tLoss: 0.269129\n",
      "Train Epoch: 0 [28800/60000 (48%)]\tLoss: 0.350805\n",
      "Train Epoch: 0 [29440/60000 (49%)]\tLoss: 0.360674\n",
      "Train Epoch: 0 [30080/60000 (50%)]\tLoss: 0.178123\n",
      "Train Epoch: 0 [30720/60000 (51%)]\tLoss: 0.126695\n",
      "Train Epoch: 0 [31360/60000 (52%)]\tLoss: 0.371533\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.274337\n",
      "Train Epoch: 0 [32640/60000 (54%)]\tLoss: 0.119308\n",
      "Train Epoch: 0 [33280/60000 (55%)]\tLoss: 0.031163\n",
      "Train Epoch: 0 [33920/60000 (57%)]\tLoss: 0.115552\n",
      "Train Epoch: 0 [34560/60000 (58%)]\tLoss: 0.323108\n",
      "Train Epoch: 0 [35200/60000 (59%)]\tLoss: 0.398479\n",
      "Train Epoch: 0 [35840/60000 (60%)]\tLoss: 0.236535\n",
      "Train Epoch: 0 [36480/60000 (61%)]\tLoss: 0.379263\n",
      "Train Epoch: 0 [37120/60000 (62%)]\tLoss: 0.185603\n",
      "Train Epoch: 0 [37760/60000 (63%)]\tLoss: 0.524897\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.078435\n",
      "Train Epoch: 0 [39040/60000 (65%)]\tLoss: 0.141798\n",
      "Train Epoch: 0 [39680/60000 (66%)]\tLoss: 0.317317\n",
      "Train Epoch: 0 [40320/60000 (67%)]\tLoss: 0.081012\n",
      "Train Epoch: 0 [40960/60000 (68%)]\tLoss: 0.195759\n",
      "Train Epoch: 0 [41600/60000 (69%)]\tLoss: 0.081697\n",
      "Train Epoch: 0 [42240/60000 (70%)]\tLoss: 0.110333\n",
      "Train Epoch: 0 [42880/60000 (71%)]\tLoss: 0.092257\n",
      "Train Epoch: 0 [43520/60000 (72%)]\tLoss: 0.345661\n",
      "Train Epoch: 0 [44160/60000 (74%)]\tLoss: 0.171707\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.128945\n",
      "Train Epoch: 0 [45440/60000 (76%)]\tLoss: 0.431617\n",
      "Train Epoch: 0 [46080/60000 (77%)]\tLoss: 0.172426\n",
      "Train Epoch: 0 [46720/60000 (78%)]\tLoss: 0.063269\n",
      "Train Epoch: 0 [47360/60000 (79%)]\tLoss: 0.150365\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.144474\n",
      "Train Epoch: 0 [48640/60000 (81%)]\tLoss: 0.109904\n",
      "Train Epoch: 0 [49280/60000 (82%)]\tLoss: 0.109773\n",
      "Train Epoch: 0 [49920/60000 (83%)]\tLoss: 0.185155\n",
      "Train Epoch: 0 [50560/60000 (84%)]\tLoss: 0.183566\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.266964\n",
      "Train Epoch: 0 [51840/60000 (86%)]\tLoss: 0.141841\n",
      "Train Epoch: 0 [52480/60000 (87%)]\tLoss: 0.170173\n",
      "Train Epoch: 0 [53120/60000 (88%)]\tLoss: 0.135163\n",
      "Train Epoch: 0 [53760/60000 (90%)]\tLoss: 0.171744\n",
      "Train Epoch: 0 [54400/60000 (91%)]\tLoss: 0.371727\n",
      "Train Epoch: 0 [55040/60000 (92%)]\tLoss: 0.229865\n",
      "Train Epoch: 0 [55680/60000 (93%)]\tLoss: 0.228193\n",
      "Train Epoch: 0 [56320/60000 (94%)]\tLoss: 0.213516\n",
      "Train Epoch: 0 [56960/60000 (95%)]\tLoss: 0.288221\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.136135\n",
      "Train Epoch: 0 [58240/60000 (97%)]\tLoss: 0.257100\n",
      "Train Epoch: 0 [58880/60000 (98%)]\tLoss: 0.075540\n",
      "Train Epoch: 0 [59520/60000 (99%)]\tLoss: 0.114902\n",
      "\n",
      "Test set: Avg. loss: 0.1436, Accuracy: 9541/10000 (95%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.104277\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.116452\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.112182\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.059098\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.106647\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.212302\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.197155\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.156589\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.169917\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.200943\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.076967\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.088938\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.088802\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.045592\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.025443\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.214713\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.227056\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.245314\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.166236\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.129234\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.070758\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.167420\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.035441\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.040376\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.101063\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.110074\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.120153\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.088957\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.039066\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.108056\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.067425\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.121176\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.120044\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.039064\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.138858\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.126737\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.305447\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.023584\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.056594\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.080225\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.163805\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.108886\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.121970\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.059013\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.055919\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.141016\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.106916\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.046740\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.041601\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.072948\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.119626\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.105876\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.185537\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.160547\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.079002\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.147143\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.072265\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.160561\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.337430\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.013020\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.071842\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.220385\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.058195\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.176073\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.157552\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.067027\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.224654\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.205052\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.201287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.128370\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.090279\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.148628\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.043487\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.084799\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.043776\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.053157\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.128357\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.067644\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.074848\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.308066\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.051546\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.086995\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.079986\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.240099\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.122918\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.030615\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.073550\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.025258\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.158965\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.216938\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.196819\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.147009\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.147408\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.222704\n",
      "\n",
      "Test set: Avg. loss: 0.1120, Accuracy: 9633/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.093426\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.198632\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.079721\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.110292\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.061043\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.031812\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.126810\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.026515\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.009025\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.015411\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.071212\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.052348\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.155830\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.109793\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.041146\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.064789\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.084891\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.049126\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.057100\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.035421\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.039882\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.171994\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.092874\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.049413\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.060117\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.076675\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.042954\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.045824\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.105501\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.125390\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.025463\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.079425\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.037955\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.049327\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.062893\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.338768\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.095518\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.064128\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.238750\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.043393\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.265046\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.119685\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.226596\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.078877\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.017444\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.055942\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.035362\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.038204\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.095444\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.123208\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.174916\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.027834\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.169005\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.168055\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.039160\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.125706\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.146952\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.028057\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.091965\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.172452\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.009557\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.167060\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.370342\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.089394\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.142450\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.063387\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.026280\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.066917\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.114154\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.085044\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.083106\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.047870\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.154324\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.278175\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.076526\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.138492\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.103069\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.025608\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.042348\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.022964\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.112167\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.058526\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.026077\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.130277\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.017702\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.025286\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.078452\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.209880\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.020994\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.097174\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.033685\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.161178\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.032007\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.141533\n",
      "\n",
      "Test set: Avg. loss: 0.1045, Accuracy: 9681/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.042147\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.039670\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.039877\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.129515\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.028560\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.016149\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.060171\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.080804\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.097067\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.324651\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.122293\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.104090\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.115547\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.157740\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.075164\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.036383\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.172795\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.028196\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.010924\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.018521\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.104086\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.079014\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.074745\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.160486\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.045154\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.016686\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.081479\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.059635\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.022884\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.085730\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.004887\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.024396\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.126289\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.080097\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.061023\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.030810\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.032944\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.230401\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.057446\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.049435\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.044065\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.008197\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.062110\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.116839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.069337\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.152139\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.089940\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.101312\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.210995\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.159481\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.036070\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.063915\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.126666\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.138443\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.058893\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.095009\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.057666\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.081935\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.052513\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.140301\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.037486\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.064817\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.041535\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.050200\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.072236\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.053029\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.031056\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.098740\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.006345\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.091189\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.177095\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.120213\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.033611\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.049017\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.103127\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.142871\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.020645\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.122962\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.093994\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.056287\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.101988\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.115091\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.159095\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.042135\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.023589\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.161913\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.049111\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.017915\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.096862\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.026480\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.108190\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.043917\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.213139\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.036982\n",
      "\n",
      "Test set: Avg. loss: 0.0969, Accuracy: 9696/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.154307\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.018030\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.029974\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.018918\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.014425\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.061215\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.066026\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.067158\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.150832\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.062483\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.051438\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.049539\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.128381\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.019210\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.049818\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.052205\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.033697\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.094783\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.015893\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.014983\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.059142\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.026727\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.025886\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.014856\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.055443\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.048945\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.012775\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.042524\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.011011\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.061336\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.108182\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.009141\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.057675\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.038608\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.072447\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.101754\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.008349\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.135264\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.078646\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.105181\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.016824\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.088194\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.040195\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.128080\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.064335\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.035323\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.050399\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.090865\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.074577\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.016392\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.057268\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.086020\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.002824\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.054580\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.079755\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.014506\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.064233\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.019770\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.023376\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.030214\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.083924\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.043959\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.045819\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.049526\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.067338\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.037007\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.103284\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.056663\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.029894\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.057053\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.071200\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.026219\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.134104\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.043164\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.026973\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.069447\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.030729\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.060318\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.012139\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.009341\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.024361\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.029054\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.023709\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.083138\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.038615\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.032508\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.019740\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.221613\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.077254\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.037520\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.101698\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.013624\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.088037\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.038088\n",
      "\n",
      "Test set: Avg. loss: 0.0933, Accuracy: 9733/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.034490\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.025483\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.063921\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.143092\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.051301\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.021114\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.054102\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.104283\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.063923\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.072314\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.061160\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.066085\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.079782\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.085487\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.061443\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.025109\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.024891\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.053508\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.017387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.023062\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.002852\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.012741\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.093364\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.005313\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.014267\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.011626\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.016942\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.015498\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.041558\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.020850\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.045164\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.036429\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.024036\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.121536\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.060491\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.019593\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.042625\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.031935\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.021458\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.030463\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.029891\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.075703\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.027652\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.036899\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.098328\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.005183\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.022375\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.111818\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.019104\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.062034\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.019968\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.052057\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.042535\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.051681\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.015766\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.063388\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.080659\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.041614\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.078846\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.053813\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.019741\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.085416\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.008091\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.031357\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.092507\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.066772\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.054031\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.245290\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.019880\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.028231\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.143012\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.008437\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.013964\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.034168\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.139862\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.022704\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.158187\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.020338\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.085826\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.070326\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.047576\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.056998\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.054736\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.086996\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.011037\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.289892\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.009252\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.023571\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.100198\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.006724\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.025799\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.015043\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.027281\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.175151\n",
      "\n",
      "Test set: Avg. loss: 0.0882, Accuracy: 9744/10000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.006090\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.036091\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.008972\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.015229\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.082661\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.030755\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.023771\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.007487\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.038577\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.030447\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.030183\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.023065\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.022107\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.022432\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.052169\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.026088\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.005796\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.007156\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.026451\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.082019\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.006161\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.016322\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.003671\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.063847\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.029585\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.074684\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.058707\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.015583\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.060327\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.004739\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.044974\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.058572\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.036166\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.004229\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.063484\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.021439\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.003561\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.023989\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.004311\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.020197\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.011930\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.003529\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.008861\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.016297\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.015654\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.066122\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.003117\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.015342\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.028342\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.123413\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.003435\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.095420\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.071494\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.006160\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.046898\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.078675\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.030551\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.099799\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.102227\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.014592\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.069640\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.004338\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.077944\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.043582\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.031487\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.029477\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.019344\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.035953\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.045442\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.018916\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.009517\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.010254\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.086121\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.084788\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.044246\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.020094\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.022370\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.073314\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.070478\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.059303\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.050555\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.042585\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.084132\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.021213\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.001037\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.031854\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.016241\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.028981\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.016592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.092953\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.045912\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.010109\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.059042\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.092663\n",
      "\n",
      "Test set: Avg. loss: 0.0869, Accuracy: 9743/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.014286\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.031361\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.008034\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.027296\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.017435\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.028340\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.050966\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.008290\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.015677\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.012911\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.013165\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.018119\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.023952\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.017217\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.020652\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.043481\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.009256\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.057390\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.025295\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.029222\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.020865\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.059785\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.031294\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.003834\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.010150\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.031214\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.102624\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.003770\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.011828\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.059691\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.016847\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.020503\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.003321\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.004929\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.045840\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.034676\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.025780\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.044744\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.057823\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.020038\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.047756\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.005747\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.023966\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.042834\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.034861\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.011537\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.012057\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.058520\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.005312\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.024985\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.014034\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.016929\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.062286\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.012614\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.025835\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.023372\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.008345\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.015330\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.013380\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.030937\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.010241\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.007740\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.027451\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.017197\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.175030\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.033692\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.039863\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.024715\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.006557\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.004024\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.018632\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.025706\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.034043\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.029010\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.026604\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.002837\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.004422\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.053024\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.026490\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.004783\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.009681\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.003484\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.022430\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.024949\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.016493\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.040414\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.019198\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.020118\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.024845\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.071964\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.056597\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.077559\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.034888\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.005663\n",
      "\n",
      "Test set: Avg. loss: 0.0827, Accuracy: 9754/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.035484\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.008027\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.041578\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.003060\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.012758\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.040226\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.018360\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.003507\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.070354\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.007234\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.016628\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.003906\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.017097\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.012670\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.042959\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.003031\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.060279\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.039132\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.016937\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.080160\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.009426\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.017117\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.012372\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.000788\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.000522\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.019422\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.020662\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.016635\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.023184\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.019011\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.041138\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.015313\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.013367\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.022531\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.016416\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.024662\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.036514\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.009008\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.028535\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.021413\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.016658\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.062290\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.048086\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.006616\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.002781\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.111967\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.041092\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.036385\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.004344\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.011298\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.006185\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.006044\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.059687\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.073851\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.019165\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.015487\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.037114\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.002054\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.015996\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.011897\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.008770\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.020706\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.012084\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.015640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.003027\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.112878\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.014926\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.005764\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.006236\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.032870\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.006726\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.245355\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.003886\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.022307\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.005576\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.014088\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.038464\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.061883\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.116366\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.049728\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.018903\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.058023\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.012012\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.043666\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.028999\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.091949\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.005086\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.017763\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.040433\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.004753\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.031409\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.036179\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.008703\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.013059\n",
      "\n",
      "Test set: Avg. loss: 0.0762, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.014075\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.003547\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.013158\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.004854\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.023575\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.026130\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.043353\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.013751\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.007517\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.014285\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.018703\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.010563\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.007925\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.010093\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.006511\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.012440\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.052326\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.018530\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.022331\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.015114\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.006888\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.009836\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.008294\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.011660\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.013218\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.001404\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.077351\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.054616\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.032667\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.027493\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.045801\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.068234\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.053548\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.017451\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.016933\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.014623\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.009763\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.020576\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.030276\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.034707\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.084369\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.028157\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.016042\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.027936\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.062319\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.015062\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.025157\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.009237\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.104984\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.172118\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.109534\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.009543\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.011666\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.071036\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.009057\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.006786\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.004410\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.011889\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.032414\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.011305\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.011799\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.011559\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.040873\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.014842\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.028737\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.008535\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.011528\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.001035\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.010443\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.084490\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.006056\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.017090\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.013995\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.007030\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.037635\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.005170\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.006835\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.012066\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.061786\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.013218\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.022385\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.026186\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.035573\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.018469\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.015737\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.134200\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.007128\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.031107\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.042591\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.008054\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.002996\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.026393\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.013347\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.107773\n",
      "\n",
      "Test set: Avg. loss: 0.0762, Accuracy: 9781/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toy = MLP()\n",
    "leak = 0.99\n",
    "time_step = 7\n",
    "lr = 0.001\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "test()\n",
    "for epoch in range(10):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        out = toy(data)\n",
    "            \n",
    "        err = loss(out,target)\n",
    "        exp = torch.exp(out)\n",
    "        exp_sum = torch.sum(torch.exp(out),1, keepdim=True)\n",
    "        target = F.one_hot(target, num_classes=10)\n",
    "        L = -1*torch.sum((target*torch.log((exp/exp_sum))),1, keepdim=True)\n",
    "        \n",
    "        \n",
    "        du_out = exp/exp_sum\n",
    "\n",
    "        du_out = du_out - target\n",
    "        \n",
    "        bp_MLP(toy,leak,time_step,du_out,toy.s_regs_inp,lr,toy.lif1.thresh)\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), err.item()))\n",
    "            train_losses.append(err.item())\n",
    "            train_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cebce317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'negative log likelihood loss')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264b633d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
