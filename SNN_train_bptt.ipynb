{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "251e3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b07e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e21ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PoissonGen(inp, rescale_fac=2.0):\n",
    "    rand_inp = torch.rand_like(inp)\n",
    "    return torch.mul(torch.le(rand_inp * rescale_fac, torch.abs(inp)).float(), torch.sign(inp))\n",
    "\n",
    "# def spike_function(x):\n",
    "#     x[x>0] = 1\n",
    "#     x[x<=0] = 0\n",
    "#     return x\n",
    "\n",
    "def de_func(U,th):\n",
    "    alpha = 0.3\n",
    "    U = alpha*(1.0 - abs((U-th)/th))\n",
    "    U[U<0]=0\n",
    "    return U\n",
    "\n",
    "def test(toy):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    toy = toy.cuda()\n",
    "    for data, target in test_loader:\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "        output = toy(data)\n",
    "        test_loss +=F.cross_entropy(output, target, size_average=False).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "def quant(input, k):\n",
    "    size = input.size()\n",
    "    #mean = torch.mean(input.abs(), 1, keepdim=True)\n",
    "    x = input\n",
    "    #print(x)\n",
    "    xmax = x.abs().max()\n",
    "    num_bits=k\n",
    "    v0 = 1\n",
    "    v1 = 2\n",
    "    v2 = -0.5\n",
    "    y = k #2.**num_bits - 1.\n",
    "    #print(y)\n",
    "    x = x.add(v0).div(v1)\n",
    "    #print(x)\n",
    "    x = x.mul(y).round_()\n",
    "    #print(x)\n",
    "    x = x.div(y)\n",
    "    #print(x)\n",
    "    x = x.add(v2)\n",
    "    #print(x)\n",
    "    x = x.mul(v1)\n",
    "    #print(x)\n",
    "    input = x\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d766c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, time_step,leak):\n",
    "        super(model, self).__init__()\n",
    "        \n",
    "       \n",
    "        self.fc_1 = nn.Linear(28*28,256,bias=False)\n",
    "        self.fc_2 = nn.Linear(256,256,bias=False)\n",
    "        self.fc_out = nn.Linear(256,10,bias=False)\n",
    "        \n",
    "        self.lif1 = LIF(time_step,leak)\n",
    "        self.lif2 = LIF(time_step,leak)\n",
    "        self.time_step = time_step\n",
    "        self.s_regs_inp = None\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        inp = inp.view(inp.shape[0],-1)\n",
    "        size = inp.shape\n",
    "        self.s_regs_inp = torch.zeros(self.time_step,*size, device=device)\n",
    "        u_out = 0\n",
    "        \n",
    "        for t in range(self.time_step):\n",
    "            \n",
    "            spike_inp = PoissonGen(inp)\n",
    "            self.s_regs_inp[t] += spike_inp \n",
    "            \n",
    "            x = self.fc_1(spike_inp)\n",
    "            #x = quant(x,2**4)\n",
    "            x = self.lif1(x, t)\n",
    "            x = self.fc_2(x)\n",
    "            #x = quant(x,2**4)\n",
    "            x = self.lif2(x, t)\n",
    "            x = self.fc_out(x)\n",
    "            u_out = u_out + x\n",
    "        return u_out/self.time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db8d72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,time_step,leak):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.fc_1 = nn.Linear(28*28,512,bias=False)\n",
    "        self.fc_out = nn.Linear(512,10,bias=False)\n",
    "        self.lif1 = LIF(time_step,leak)\n",
    "        self.time_step = time_step\n",
    "        self.s_regs_inp = None\n",
    "        \n",
    "    def forward(self, inp):\n",
    "#         print(\"size is:\", (inp.view(inp.shape[0],1,28,28)).shape)\n",
    "        inp = inp.view(inp.shape[0],-1)\n",
    "        size = inp.shape\n",
    "        \n",
    "        self.s_regs_inp = torch.zeros(self.time_step,*size, device=device)\n",
    "        u_out = 0\n",
    "        \n",
    "        for t in range(self.time_step):\n",
    "            spike_inp = PoissonGen(inp)\n",
    "            self.s_regs_inp[t] += spike_inp \n",
    "            x = self.fc_1(spike_inp)\n",
    "            #x = quant(x,2**4)\n",
    "            x = self.lif1(x, t)\n",
    "            x = self.fc_out(x)\n",
    "            u_out = u_out + x\n",
    "        return u_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28765ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_5(nn.Module):\n",
    "    def __init__(self,time_step, leak):\n",
    "        super(VGG_5, self).__init__()\n",
    "        \n",
    "        self.time_step = time_step\n",
    "        self.s_regs_inp = None\n",
    "        self.s_regs_conv = None\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv_lif1 = LIF(time_step, leak)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.pool1_ind = []\n",
    "        self.unpool1 = nn.MaxUnpool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv_lif2 = LIF(time_step, leak)\n",
    "        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv_lif3 = LIF(time_step, leak)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.pool2_ind = []\n",
    "        self.unpool2 = nn.MaxUnpool2d(kernel_size=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 1024, bias=False)\n",
    "        self.fc_lif1 = LIF(time_step)\n",
    "        self.fc_out = nn.Linear(1024, 10, bias=False)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "\n",
    "        size = inp.shape\n",
    "        self.s_regs_inp = torch.zeros(self.time_step,*size, device=device)\n",
    "        self.pool1_ind = []\n",
    "        self.pool2_ind = []\n",
    "        u_out = 0\n",
    "        \n",
    "        for t in range(self.time_step):\n",
    "            spike_inp = PoissonGen(inp)\n",
    "            self.s_regs_inp[t] += spike_inp \n",
    "            x = self.conv1(spike_inp)\n",
    "            x = self.conv_lif1(x,t)\n",
    "            x, indices = self.pool1(x)\n",
    "            self.pool1_ind.append(indices)\n",
    "            x = self.conv2(x)\n",
    "            x = self.conv_lif2(x,t)\n",
    "            x = self.conv3(x)\n",
    "            x = self.conv_lif3(x,t)\n",
    "            x, indices = self.pool2(x)\n",
    "            x = x.view(x.shape[0],-1)\n",
    "            \n",
    "            if t == 0:\n",
    "                self.s_regs_conv = torch.zeros(self.time_step,*x.shape, device=device)\n",
    "            self.pool2_ind.append(indices)\n",
    "            self.s_regs_conv[t] += x\n",
    "            \n",
    "            x = self.fc1(x)\n",
    "            x = self.fc_lif1(x,t)\n",
    "            x = self.fc_out(x)\n",
    "            u_out = u_out + x\n",
    "        return u_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c149d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp_VGG5(vgg,leak,time_step,du_out,l_r,th):\n",
    "   \n",
    "    ## Update weight in FCs, time Ts\n",
    "    du_fc1 = torch.matmul(du_out,vgg.fc_out.weight)*de_func(vgg.fc_lif1.u_regs[-1],th)\n",
    "    vgg.fc_lif1.du_regs[-1] += du_fc1\n",
    "    w_conv_1 = torch.matmul(torch.transpose(du_fc1,0,1),vgg.s_regs_conv[-1])\n",
    "    vgg.fc1.weight.data -= l_r*w_conv_1   \n",
    "    w_1_out = torch.matmul(torch.transpose(du_out,0,1),vgg.fc_lif1.s_regs[-1])\n",
    "    vgg.fc_out.weight.data -= l_r*w_1_out\n",
    "    \n",
    "    ## Update du in pool2, time T\n",
    "    dx_pool2 = torch.matmul(du_fc1,vgg.fc1.weight)\n",
    "    dx_pool2 = dx_pool2.view(dx_pool2.shape[0],128,7,7)\n",
    "    du_pool2 = vgg.unpool2(dx_pool2,vgg.pool2_ind[-1])\n",
    "    du_pool2 = torch.sum(du_pool2,0)\n",
    "    du_pool2 = torch.unsqueeze(du_pool2,1)\n",
    "    \n",
    "    ## Update du in conv3, time T\n",
    "    d_conv3 = nn.Conv2d(128, 128, stride=1, kernel_size=f, padding=f-1, bias=False)\n",
    "    \n",
    "    ## Update weight in Conv3, time T\n",
    "    f = du_pool2.shape[-1]\n",
    "    d_conv3 = nn.Conv2d(128, 128, stride=1, padding=1, kernel_size=f, bias=False)\n",
    "    d_conv3.weight.data = du_pool2.type(torch.float)\n",
    "    dW_conv3 = d_conv3(vgg.conv_lif2.s_regs[-1].type(torch.float))\n",
    "    dW_conv3 = torch.sum(dW_conv3,0)\n",
    "    dW_conv3 = torch.unsqueeze(dW_conv3,1)\n",
    "    vgg.conv3.weight.data -= l_r*dW_conv3\n",
    "    \n",
    "    \n",
    "    \n",
    "    for t in range(time_step-2,-1,-1):\n",
    "        \n",
    "        ds_fc1 = torch.matmul(du_out,vgg.fc_out.weight)+vgg.lif_fc1.du_regs[t+1]*(-leak*vgg.lif_fc1.du_regs[t])\n",
    "        du_fc1 = (ds_fc1)*de_func(vgg.lif_fc1.du_regs[t],th) + vgg.lif_fc1.du_regs[t+1]*leak*(1-vgg.lif_fc1.s_regs[t])\n",
    "        vgg.lif_fc1.du_regs[t] += du_fc1\n",
    "        \n",
    "        w_conv_1 = torch.matmul(torch.transpose(du_fc1,0,1),vgg.s_regs_conv[t])\n",
    "        vgg.fc1.weight.data -= l_r*w_conv_1\n",
    "        \n",
    "        \n",
    "        dx_pool1 = torch.matmul(du_fc1,vgg.fc1.weight)\n",
    "        dx_pool1 = dx_pool1.view(dx_pool1.shape[0],16,14,14)\n",
    "        du_pool1 = vgg.unpool1(dx_pool1,vgg.pool1_ind[t])\n",
    "        du_pool1 = torch.sum(du_pool1,0)\n",
    "        du_pool1 = torch.unsqueeze(du_pool1,1)\n",
    "        f = du_pool1.shape[-1]\n",
    "        d_conv1_w = nn.Conv2d(1, 16, stride=1, padding=1,kernel_size=f, bias=False)\n",
    "        d_conv1_w.weight.data = du_pool1.type(torch.float)\n",
    "        dW = d_conv1_w(vgg.s_regs_inp[t].type(torch.float))\n",
    "        dW = torch.sum(dW,0)\n",
    "        dW = torch.unsqueeze(dW,1)\n",
    "\n",
    "        vgg.conv1.weight.data -= l_r*dW\n",
    "    \n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7adf32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_1(nn.Module):\n",
    "    def __init__(self,time_step,leak):\n",
    "        super(VGG_1, self).__init__()\n",
    "        \n",
    "        self.time_step = time_step\n",
    "        self.s_regs_inp = None\n",
    "        self.s_regs_conv = None\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1, bias=False)\n",
    "        \n",
    "#         self.deconv1 = nn.Conv2d()\n",
    "        self.lif_conv1 = LIF(time_step,leak)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,return_indices=True)\n",
    "        self.pool1_ind = []\n",
    "        self.unpool1 = nn.MaxUnpool2d(kernel_size=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(16 * 14 * 14, 512, bias=False)\n",
    "        self.lif_fc1 = LIF(time_step,leak)\n",
    "        self.fc_out = nn.Linear(512, 10, bias=False)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "\n",
    "        size = inp.shape\n",
    "        self.s_regs_inp = torch.zeros(self.time_step,*size, device=device)\n",
    "        self.pool1_ind = []\n",
    "\n",
    "        u_out = 0\n",
    "        for t in range(self.time_step):\n",
    "            spike_inp = PoissonGen(inp)\n",
    "            self.s_regs_inp[t] += spike_inp\n",
    "            x = self.conv1(spike_inp)\n",
    "            x = self.lif_conv1(x,t)\n",
    "            x, indices = self.pool1(x)\n",
    "            x= x.view(x.shape[0],-1)\n",
    "            \n",
    "            if t == 0:\n",
    "                self.s_regs_conv = torch.zeros(self.time_step,*x.shape, device=device)\n",
    "            self.pool1_ind.append(indices)\n",
    "            self.s_regs_conv[t] += x\n",
    "            \n",
    "            x = self.fc1(x)\n",
    "            x = self.lif_fc1(x,t)\n",
    "            \n",
    "            x = self.fc_out(x)\n",
    "            u_out = u_out + x\n",
    "\n",
    "        return u_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31ffe4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp_VGG1(vgg,leak,time_step,du_out,l_r,th):\n",
    "   \n",
    "    ## First fc\n",
    "    du_fc1 = torch.matmul(du_out,vgg.fc_out.weight)*de_func(vgg.lif_fc1.u_regs[-1],th)\n",
    "    vgg.lif_fc1.du_regs[-1] += du_fc1\n",
    "       \n",
    "    ## Update weight\n",
    "    w_conv_1 = torch.matmul(torch.transpose(du_fc1,0,1),vgg.s_regs_conv[-1])\n",
    "    vgg.fc1.weight.data -= l_r*w_conv_1\n",
    "     \n",
    "    w_1_out = torch.matmul(torch.transpose(du_out,0,1),vgg.lif_fc1.s_regs[-1])\n",
    "    vgg.fc_out.weight.data -= l_r*w_1_out\n",
    "    \n",
    "    dx_pool1 = torch.matmul(du_fc1,vgg.fc1.weight)\n",
    "    dx_pool1 = dx_pool1.view(dx_pool1.shape[0],16,14,14)\n",
    "    du_pool1 = vgg.unpool1(dx_pool1,vgg.pool1_ind[-1])\n",
    "    du_pool1 = torch.sum(du_pool1,0)\n",
    "    du_pool1 = torch.unsqueeze(du_pool1,1)\n",
    "    f = du_pool1.shape[-1]\n",
    "    d_conv1_w = nn.Conv2d(1, 16, stride=1, padding=1,kernel_size=f, bias=False)\n",
    "    d_conv1_w.weight.data = du_pool1.type(torch.float)\n",
    "    dW = d_conv1_w(vgg.s_regs_inp[-1].type(torch.float))\n",
    "    dW = torch.sum(dW,0)\n",
    "    dW = torch.unsqueeze(dW,1)\n",
    "\n",
    "    vgg.conv1.weight.data -= l_r*dW\n",
    "    \n",
    "    for t in range(time_step-2,-1,-1):\n",
    "        \n",
    "        ds_fc1 = torch.matmul(du_out,vgg.fc_out.weight)+vgg.lif_fc1.du_regs[t+1]*(-leak*vgg.lif_fc1.du_regs[t])\n",
    "        du_fc1 = (ds_fc1)*de_func(vgg.lif_fc1.du_regs[t],th) + vgg.lif_fc1.du_regs[t+1]*leak*(1-vgg.lif_fc1.s_regs[t])\n",
    "        vgg.lif_fc1.du_regs[t] += du_fc1\n",
    "        \n",
    "        w_conv_1 = torch.matmul(torch.transpose(du_fc1,0,1),vgg.s_regs_conv[t])\n",
    "        vgg.fc1.weight.data -= l_r*w_conv_1\n",
    "        \n",
    "        \n",
    "        dx_pool1 = torch.matmul(du_fc1,vgg.fc1.weight)\n",
    "        dx_pool1 = dx_pool1.view(dx_pool1.shape[0],16,14,14)\n",
    "        du_pool1 = vgg.unpool1(dx_pool1,vgg.pool1_ind[t])\n",
    "        du_pool1 = torch.sum(du_pool1,0)\n",
    "        du_pool1 = torch.unsqueeze(du_pool1,1)\n",
    "        f = du_pool1.shape[-1]\n",
    "        d_conv1_w = nn.Conv2d(1, 16, stride=1, padding=1,kernel_size=f, bias=False)\n",
    "        d_conv1_w.weight.data = du_pool1.type(torch.float)\n",
    "        dW = d_conv1_w(vgg.s_regs_inp[t].type(torch.float))\n",
    "        dW = torch.sum(dW,0)\n",
    "        dW = torch.unsqueeze(dW,1)\n",
    "\n",
    "        vgg.conv1.weight.data -= l_r*dW\n",
    "    \n",
    "    \n",
    "    return 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e6f78f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIF(nn.Module):\n",
    "    def __init__(self, time_step,leak):\n",
    "        super(LIF, self).__init__()\n",
    "        \n",
    "        self.u_regs = None\n",
    "        self.du_regs = None\n",
    "        self.s_regs = None\n",
    "        self.leak = leak\n",
    "        self.time_step = time_step\n",
    "        self.thresh = 0.5\n",
    "        \n",
    "    def forward(self,inp,t):\n",
    "        \n",
    "#         print(\"memory before clear\",torch.cuda.memory_allocated())\n",
    "        if t == 0:\n",
    "            size = inp.shape\n",
    "            self.u_regs = torch.zeros(self.time_step,*size, device=device)\n",
    "            self.du_regs = torch.zeros(self.time_step,*size, device=device)\n",
    "#             err = torch.normal(0, 0.1,(1,1)).cuda()\n",
    "#             inp = inp + err\n",
    "#             self.u_regs[0] = quant(inp,2**4)\n",
    "            self.u_regs[0] = inp\n",
    "            self.s_regs = torch.zeros(self.time_step,*size, device=device)\n",
    "\n",
    "            spike = inp.gt(self.thresh).float()\n",
    "\n",
    "            self.s_regs[0] = spike\n",
    "            \n",
    "        else:\n",
    "#             err = torch.normal(0, 0.1,(1,1))\n",
    "#             inp = inp + err\n",
    "#             self.u_regs[t] = quant(self.leak * self.u_regs[t-1] * (1 - self.s_regs[t-1]) + (1-self.leak)*inp, 2**4)\n",
    "            self.u_regs[t] = self.leak*self.u_regs[t-1]*(1-self.s_regs[t-1]) + inp\n",
    "\n",
    "            spike = self.u_regs[t].gt(self.thresh).float()\n",
    "\n",
    "            self.s_regs[t] = spike\n",
    "            \n",
    "#         print(\"memory after clear\",torch.cuda.memory_allocated())\n",
    "#         torch.cuda.empty_cache()\n",
    "#         gc.collect()\n",
    "        return spike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8fc2dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Back propagation for MLP\n",
    "def bp_MLP(toy,leak,time_step,du_out,s_regs_inp,l_r,th):\n",
    "    \n",
    "    ## First fc\n",
    "    du_fc1 = torch.matmul(du_out,toy.fc_out.weight)*de_func(toy.lif1.u_regs[-1],th)\n",
    "    toy.lif1.du_regs[-1] += du_fc1\n",
    "\n",
    "    ## Update weight\n",
    "    w_inp_1 = torch.matmul(torch.transpose(du_fc1,0,1),s_regs_inp[-1])\n",
    "#     toy.fc_1.weight.data -= l_r*quant(w_inp_1,2**4)\n",
    "    toy.fc_1.weight.data -= l_r*w_inp_1\n",
    "    \n",
    "    w_1_out = torch.matmul(torch.transpose(du_out,0,1),toy.lif1.s_regs[-1])\n",
    "#     toy.fc_out.weight.data -= l_r*quant(w_1_out,2**4)\n",
    "    toy.fc_out.weight.data -= l_r*w_1_out\n",
    "\n",
    "    for t in range(time_step-2,-1,-1):\n",
    "        \n",
    "        ## First fc\n",
    "        ds_fc1 = torch.matmul(du_out,toy.fc_out.weight)+toy.lif1.du_regs[t+1]*(-leak*toy.lif1.u_regs[t])\n",
    "        du_fc1 = (ds_fc1)*de_func(toy.lif1.u_regs[t],th) + toy.lif1.du_regs[t+1]*leak*(1-toy.lif1.s_regs[t])\n",
    "        toy.lif1.du_regs[t] += du_fc1\n",
    "\n",
    "        ## Update weight\n",
    "        w_inp_1 = torch.matmul(torch.transpose(du_fc1,0,1),s_regs_inp[t])\n",
    "#         toy.fc_1.weight.data -= l_r*quant(w_inp_1,2**4)\n",
    "#         print(\"du_size\",du_fc1.shape)\n",
    "#         print(\"s_size\",s_regs_inp[t].shape)\n",
    "#         print(\"dweight shape\",w_inp_1.shape)\n",
    "        toy.fc_1.weight.data -= l_r*w_inp_1\n",
    "\n",
    "        w_1_out = torch.matmul(torch.transpose(du_out,0,1),toy.lif1.s_regs[t])\n",
    "#         toy.fc_out.weight.data -= l_r*quant(w_1_out,2**4)\n",
    "        toy.fc_out.weight.data -= l_r*w_1_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b08084b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Back propagation\n",
    "def bp(toy,leak,time_step,du_out,s_regs_inp,l_r,th):\n",
    "    \n",
    "    ## Second fc    \n",
    "    du_fc2 = torch.matmul(du_out,toy.fc_out.weight)*de_func(toy.lif2.u_regs[-1],th)    \n",
    "    toy.lif2.du_regs[-1] = toy.lif2.du_regs[-1] + du_fc2\n",
    "    \n",
    "    ## First fc\n",
    "    du_fc1 = torch.matmul(du_fc2,toy.fc_2.weight)*de_func(toy.lif1.u_regs[-1],th)\n",
    "    toy.lif1.du_regs[-1] += du_fc1\n",
    "\n",
    "    \n",
    "    ## Update weight\n",
    "    w_inp_1 = torch.matmul(torch.transpose(du_fc1,0,1),s_regs_inp[-1])\n",
    "    toy.fc_1.weight.data -= l_r*quant(w_inp_1,2**4)\n",
    "    #toy.fc_1.weight.data -= l_r*w_inp_1\n",
    "\n",
    "    w_1_2 = torch.matmul(torch.transpose(du_fc2,0,1),toy.lif1.s_regs[-1])\n",
    "    toy.fc_2.weight.data -= l_r*quant(w_1_2,2**4)\n",
    "    #toy.fc_2.weight.data -= l_r*w_1_2\n",
    "\n",
    "    w_2_out = torch.matmul(torch.transpose(du_out,0,1),toy.lif2.s_regs[-1])\n",
    "    toy.fc_out.weight.data -= l_r*quant(w_2_out,2**4)\n",
    "    #toy.fc_out.weight.data -= l_r*w_2_out\n",
    "\n",
    "    for t in range(time_step-2,-1,-1):\n",
    "\n",
    "        ds_fc2 = torch.matmul(du_out,toy.fc_out.weight)+toy.lif2.du_regs[t+1]*(-leak*toy.lif2.u_regs[t])\n",
    "        du_fc2 = (ds_fc2)*de_func(toy.lif2.u_regs[t],th) + toy.lif2.du_regs[t+1]*leak*(1-toy.lif2.s_regs[t])\n",
    "        toy.lif2.du_regs[t] += du_fc2\n",
    "        \n",
    "        ## First fc\n",
    "        ds_fc1 = torch.matmul(du_fc2,toy.fc_2.weight)+toy.lif1.du_regs[t+1]*(-leak*toy.lif1.u_regs[t])\n",
    "        du_fc1 = (ds_fc1)*de_func(toy.lif1.u_regs[t],th) + toy.lif1.du_regs[t+1]*leak*(1-toy.lif1.s_regs[t])\n",
    "        toy.lif1.du_regs[t] += du_fc1\n",
    "\n",
    "        ## Update weight\n",
    "        w_inp_1 = torch.matmul(torch.transpose(du_fc1,0,1),s_regs_inp[t])\n",
    "        toy.fc_1.weight.data -= l_r*quant(w_inp_1,2**4)\n",
    "        \n",
    "        #toy.fc_1.weight.data -= l_r*w_inp_1\n",
    "\n",
    "        w_1_2 = torch.matmul(torch.transpose(du_fc2,0,1),toy.lif1.s_regs[t])\n",
    "        toy.fc_2.weight.data -= l_r*quant(w_1_2,2**4)\n",
    "        #toy.fc_2.weight.data -= l_r*w_1_2\n",
    "\n",
    "        w_2_out = torch.matmul(torch.transpose(du_out,0,1),toy.lif2.s_regs[t])\n",
    "        toy.fc_out.weight.data -= l_r*quant(w_2_out,2**4)\n",
    "        #toy.fc_out.weight.data -= l_r*w_2_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c3de0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size_test = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b70c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = []\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(5 + 1)]\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2ce9ca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruokai\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 3.6960, Accuracy: 888/10000 (9%)\n",
      "\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 3.510776\n",
      "Train Epoch: 0 [640/60000 (1%)]\tLoss: 1.608410\n",
      "Train Epoch: 0 [1280/60000 (2%)]\tLoss: 0.911238\n",
      "Train Epoch: 0 [1920/60000 (3%)]\tLoss: 0.861174\n",
      "Train Epoch: 0 [2560/60000 (4%)]\tLoss: 0.921257\n",
      "Train Epoch: 0 [3200/60000 (5%)]\tLoss: 0.639543\n",
      "Train Epoch: 0 [3840/60000 (6%)]\tLoss: 0.740028\n",
      "Train Epoch: 0 [4480/60000 (7%)]\tLoss: 0.362667\n",
      "Train Epoch: 0 [5120/60000 (9%)]\tLoss: 0.431609\n",
      "Train Epoch: 0 [5760/60000 (10%)]\tLoss: 0.511474\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.518321\n",
      "Train Epoch: 0 [7040/60000 (12%)]\tLoss: 0.299334\n",
      "Train Epoch: 0 [7680/60000 (13%)]\tLoss: 0.504087\n",
      "Train Epoch: 0 [8320/60000 (14%)]\tLoss: 0.491227\n",
      "Train Epoch: 0 [8960/60000 (15%)]\tLoss: 0.411877\n",
      "Train Epoch: 0 [9600/60000 (16%)]\tLoss: 0.511013\n",
      "Train Epoch: 0 [10240/60000 (17%)]\tLoss: 0.500305\n",
      "Train Epoch: 0 [10880/60000 (18%)]\tLoss: 0.576344\n",
      "Train Epoch: 0 [11520/60000 (19%)]\tLoss: 0.333058\n",
      "Train Epoch: 0 [12160/60000 (20%)]\tLoss: 0.429470\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.448670\n",
      "Train Epoch: 0 [13440/60000 (22%)]\tLoss: 0.510573\n",
      "Train Epoch: 0 [14080/60000 (23%)]\tLoss: 0.314190\n",
      "Train Epoch: 0 [14720/60000 (25%)]\tLoss: 0.340610\n",
      "Train Epoch: 0 [15360/60000 (26%)]\tLoss: 0.360921\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.418777\n",
      "Train Epoch: 0 [16640/60000 (28%)]\tLoss: 0.478663\n",
      "Train Epoch: 0 [17280/60000 (29%)]\tLoss: 0.456393\n",
      "Train Epoch: 0 [17920/60000 (30%)]\tLoss: 0.426949\n",
      "Train Epoch: 0 [18560/60000 (31%)]\tLoss: 0.265967\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.325073\n",
      "Train Epoch: 0 [19840/60000 (33%)]\tLoss: 0.389314\n",
      "Train Epoch: 0 [20480/60000 (34%)]\tLoss: 0.397687\n",
      "Train Epoch: 0 [21120/60000 (35%)]\tLoss: 0.424041\n",
      "Train Epoch: 0 [21760/60000 (36%)]\tLoss: 0.313240\n",
      "Train Epoch: 0 [22400/60000 (37%)]\tLoss: 0.268957\n",
      "Train Epoch: 0 [23040/60000 (38%)]\tLoss: 0.214363\n",
      "Train Epoch: 0 [23680/60000 (39%)]\tLoss: 0.353816\n",
      "Train Epoch: 0 [24320/60000 (41%)]\tLoss: 0.520861\n",
      "Train Epoch: 0 [24960/60000 (42%)]\tLoss: 0.428586\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.263822\n",
      "Train Epoch: 0 [26240/60000 (44%)]\tLoss: 0.343148\n",
      "Train Epoch: 0 [26880/60000 (45%)]\tLoss: 0.482672\n",
      "Train Epoch: 0 [27520/60000 (46%)]\tLoss: 0.294615\n",
      "Train Epoch: 0 [28160/60000 (47%)]\tLoss: 0.278037\n",
      "Train Epoch: 0 [28800/60000 (48%)]\tLoss: 0.201517\n",
      "Train Epoch: 0 [29440/60000 (49%)]\tLoss: 0.379522\n",
      "Train Epoch: 0 [30080/60000 (50%)]\tLoss: 0.208861\n",
      "Train Epoch: 0 [30720/60000 (51%)]\tLoss: 0.311978\n",
      "Train Epoch: 0 [31360/60000 (52%)]\tLoss: 0.223268\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.243765\n",
      "Train Epoch: 0 [32640/60000 (54%)]\tLoss: 0.290054\n",
      "Train Epoch: 0 [33280/60000 (55%)]\tLoss: 0.540110\n",
      "Train Epoch: 0 [33920/60000 (57%)]\tLoss: 0.401590\n",
      "Train Epoch: 0 [34560/60000 (58%)]\tLoss: 0.426307\n",
      "Train Epoch: 0 [35200/60000 (59%)]\tLoss: 0.404860\n",
      "Train Epoch: 0 [35840/60000 (60%)]\tLoss: 0.181152\n",
      "Train Epoch: 0 [36480/60000 (61%)]\tLoss: 0.296802\n",
      "Train Epoch: 0 [37120/60000 (62%)]\tLoss: 0.411415\n",
      "Train Epoch: 0 [37760/60000 (63%)]\tLoss: 0.180915\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.345740\n",
      "Train Epoch: 0 [39040/60000 (65%)]\tLoss: 0.327690\n",
      "Train Epoch: 0 [39680/60000 (66%)]\tLoss: 0.407998\n",
      "Train Epoch: 0 [40320/60000 (67%)]\tLoss: 0.272764\n",
      "Train Epoch: 0 [40960/60000 (68%)]\tLoss: 0.254992\n",
      "Train Epoch: 0 [41600/60000 (69%)]\tLoss: 0.166933\n",
      "Train Epoch: 0 [42240/60000 (70%)]\tLoss: 0.269286\n",
      "Train Epoch: 0 [42880/60000 (71%)]\tLoss: 0.296264\n",
      "Train Epoch: 0 [43520/60000 (72%)]\tLoss: 0.217269\n",
      "Train Epoch: 0 [44160/60000 (74%)]\tLoss: 0.236940\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.285946\n",
      "Train Epoch: 0 [45440/60000 (76%)]\tLoss: 0.170846\n",
      "Train Epoch: 0 [46080/60000 (77%)]\tLoss: 0.280832\n",
      "Train Epoch: 0 [46720/60000 (78%)]\tLoss: 0.375675\n",
      "Train Epoch: 0 [47360/60000 (79%)]\tLoss: 0.149384\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.153805\n",
      "Train Epoch: 0 [48640/60000 (81%)]\tLoss: 0.210338\n",
      "Train Epoch: 0 [49280/60000 (82%)]\tLoss: 0.102256\n",
      "Train Epoch: 0 [49920/60000 (83%)]\tLoss: 0.250966\n",
      "Train Epoch: 0 [50560/60000 (84%)]\tLoss: 0.330098\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.320379\n",
      "Train Epoch: 0 [51840/60000 (86%)]\tLoss: 0.374125\n",
      "Train Epoch: 0 [52480/60000 (87%)]\tLoss: 0.232852\n",
      "Train Epoch: 0 [53120/60000 (88%)]\tLoss: 0.346484\n",
      "Train Epoch: 0 [53760/60000 (90%)]\tLoss: 0.335384\n",
      "Train Epoch: 0 [54400/60000 (91%)]\tLoss: 0.398815\n",
      "Train Epoch: 0 [55040/60000 (92%)]\tLoss: 0.235430\n",
      "Train Epoch: 0 [55680/60000 (93%)]\tLoss: 0.253524\n",
      "Train Epoch: 0 [56320/60000 (94%)]\tLoss: 0.205168\n",
      "Train Epoch: 0 [56960/60000 (95%)]\tLoss: 0.207207\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.163725\n",
      "Train Epoch: 0 [58240/60000 (97%)]\tLoss: 0.180030\n",
      "Train Epoch: 0 [58880/60000 (98%)]\tLoss: 0.191417\n",
      "Train Epoch: 0 [59520/60000 (99%)]\tLoss: 0.319934\n",
      "\n",
      "Test set: Avg. loss: 0.2411, Accuracy: 9258/10000 (93%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.395279\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.273515\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.615881\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.402846\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.334238\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b966962041a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;31m#             print(\"memory after fwd\",torch.cuda.memory_allocated()/10000000)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-a871ad48de97>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inp)\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms_regs_conv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlif_fc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1372\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1373\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "time_step = 20\n",
    "leak = 0.99\n",
    "toy = VGG_1(time_step,leak).cuda()\n",
    "# vgg = VGG_5(time_step)\n",
    "# vgg =vgg.cuda()\n",
    "# print(\"weight\",toy.fc_1.weight)\n",
    "# torch.nn.init.normal_(toy.fc_1.weight, mean=0.0, std=0.1)\n",
    "# toy.fc_1.weight.data = quant(toy.fc_1.weight,2**4)\n",
    "# torch.nn.init.normal_(toy.fc_2.weight, mean=0.0, std=0.1)\n",
    "# toy.fc_2.weight.data = quant(toy.fc_2.weight,2**4)\n",
    "# torch.nn.init.normal_(toy.fc_out.weight, mean=0.0, std=0.1)\n",
    "# toy.fc_out.weight.data = quant(toy.fc_out.weight,2**4)\n",
    "# print(\"quantized weight\",toy.fc_1.weight)\n",
    "lr = 0.02\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "test(toy)\n",
    "with torch.no_grad():\n",
    "    for epoch in range(12):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            out = toy(data)\n",
    "#             print(\"memory after fwd\",torch.cuda.memory_allocated()/10000000)\n",
    "\n",
    "            err = loss(out,target)\n",
    "\n",
    "            exp = torch.exp(out)\n",
    "            exp_sum = torch.sum(torch.exp(out),1, keepdim=True)   \n",
    "            target = F.one_hot(target, num_classes=10)\n",
    "            #L = -1*torch.sum((target*torch.log((exp/exp_sum))),1, keepdim=True)\n",
    "            du_out = exp/exp_sum\n",
    "            du_out = (du_out - target)/batch_size_train\n",
    "\n",
    "\n",
    "\n",
    "    #         vgg_out = vgg(data)\n",
    "    #         exp_vgg = torch.exp(vgg_out)\n",
    "    #         exp_sum_vgg = torch.sum(torch.exp(vgg_out),1, keepdim=True)\n",
    "    #         du_out_vgg = exp_vgg/exp_sum_vgg\n",
    "    #         du_out_vgg = du_out_vgg - target\n",
    "    #         print(du_out_vgg)\n",
    "\n",
    "\n",
    "\n",
    "            bp_VGG1(toy,leak,time_step,du_out,lr,toy.lif_conv1.thresh)\n",
    "#             print(\"memory after bp\",torch.cuda.memory_allocated()/10000000)\n",
    "\n",
    "    #         bp_MLP(toy,leak,time_step,du_out,toy.s_regs_inp,lr,toy.lif1.thresh)\n",
    "\n",
    "\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), err.item()))\n",
    "\n",
    "#             del toy.lif_conv1.s_regs\n",
    "#             del toy.lif_conv1.u_regs\n",
    "#             del toy.lif_conv1.du_regs\n",
    "#             del toy.lif_fc1.du_regs\n",
    "#             del toy.lif_fc1.u_regs\n",
    "#             del toy.lif_fc1.s_regs\n",
    "#             del toy.s_regs_conv\n",
    "#             del toy.s_regs_inp\n",
    "#             del data\n",
    "#             del target\n",
    "#             torch.cuda.empty_cache()\n",
    "            \n",
    "#             gc.collect()\n",
    "#             print(\"memory after clear\",torch.cuda.memory_allocated()/10000000)\n",
    "\n",
    "        test(toy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfacae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.rand(16,1,3,3)\n",
    "# b = torch.rand(10,16,28,28)\n",
    "# a[:,:][:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebce317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# fig = plt.figure()\n",
    "# plt.plot(train_counter, train_losses, color='blue')\n",
    "# plt.scatter(test_counter, test_losses, color='red')\n",
    "# plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "# plt.xlabel('number of training examples seen')\n",
    "# plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "88d35d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 16, 28, 28])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W = torch.tensor([[1,2,3],[4,5,6],[7,8,9]], dtype = torch.float)\n",
    "# f = W.shape[-1]\n",
    "\n",
    "\n",
    "# n_W = dH.shape[-1]\n",
    "# n_H = dH.shape[-2]\n",
    "# X = torch.ones(5,5)\n",
    "# dX = torch.zeros(X.shape)\n",
    "# dW = torch.zeros(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a207aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for h in range(n_H):\n",
    "#     for w in range(n_W):\n",
    "#         dX[h:h+f, w:w+f] += W * dH[h][w]\n",
    "#         dW += X[h:h+f, w:w+f] * dH[h][w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2bf807fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ac45523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d3b423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a1899ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# d_conv1 = nn.Conv2d(16, 16, stride=1, kernel_size=3, padding=1, bias=False)\n",
    "d_conv2 = nn.Conv2d(16, 16, stride=1, kernel_size=3, padding =1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8a557ec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(d_conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "abd42905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W = torch.ones(16,16,3,3,dtype =torch.float)\n",
    "dH = torch.ones(10,16,7,7,dtype =torch.float)\n",
    "X = torch.ones(10,16,7,7,dtype =torch.float)\n",
    "\n",
    "# dH = torch.sum(dH,0)\n",
    "# dH = torch.unsqueeze(dH,1)\n",
    "# dH.shape\n",
    "\n",
    "# dH = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "# W = torch.unsqueeze(W,0)\n",
    "# W = torch.unsqueeze(W,1)\n",
    "# dH = torch.unsqueeze(dH,0)\n",
    "# dH = torch.unsqueeze(dH,1)\n",
    "# print(W.shape)\n",
    "# print(dH.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "de7a94a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_conv1.weight.data = torch.flip(W,[-1,-2])\n",
    "# ddx = d_conv1(dH)\n",
    "# # ddx\n",
    "# ddx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a6135722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 3, 3])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_conv2.weight.data = dH.type(torch.float)\n",
    "# print(d_conv2.weight.shape)\n",
    "\n",
    "# # X = torch.ones(1,1,5,5)\n",
    "\n",
    "ddx1 = d_conv2(X.type(torch.float))\n",
    "ddx1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f67d45d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "daconv2 = nn.Conv2d(1, 2, stride=1, kernel_size=3, padding ='same', bias=False)\n",
    "w = daconv2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f48ac94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(2,1,3,3)\n",
    "daconv2(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3100890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7f72ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(2,2,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee448974",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = nn.Conv2d(2,3,stride=1,kernel_size=2, padding = 'same', bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01be680f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c.weight.data = torch.ones(3,2,2,2)\n",
    "c.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0668c2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[8., 8., 4.],\n",
       "          [8., 8., 4.],\n",
       "          [4., 4., 2.]],\n",
       "\n",
       "         [[8., 8., 4.],\n",
       "          [8., 8., 4.],\n",
       "          [4., 4., 2.]],\n",
       "\n",
       "         [[8., 8., 4.],\n",
       "          [8., 8., 4.],\n",
       "          [4., 4., 2.]]],\n",
       "\n",
       "\n",
       "        [[[8., 8., 4.],\n",
       "          [8., 8., 4.],\n",
       "          [4., 4., 2.]],\n",
       "\n",
       "         [[8., 8., 4.],\n",
       "          [8., 8., 4.],\n",
       "          [4., 4., 2.]],\n",
       "\n",
       "         [[8., 8., 4.],\n",
       "          [8., 8., 4.],\n",
       "          [4., 4., 2.]]]], grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a3ae12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = nn.Conv1d(2,2,kernel_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ed64417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b9fac7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(2,2,3,3)\n",
    "w = torch.ones(2,2,3,3)\n",
    "c = torch.matmul(a,w)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc1357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
