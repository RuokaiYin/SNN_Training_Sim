{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "251e3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import gc\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b07e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e21ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PoissonGen(inp, rescale_fac=2.0):\n",
    "    rand_inp = torch.rand_like(inp)\n",
    "    return torch.mul(torch.le(rand_inp * rescale_fac, torch.abs(inp)).float(), torch.sign(inp))\n",
    "\n",
    "# def spike_function(x):\n",
    "#     x[x>0] = 1\n",
    "#     x[x<=0] = 0\n",
    "#     return x\n",
    "\n",
    "def de_func(U,th):\n",
    "    alpha = 0.3\n",
    "    U = alpha*(1.0 - abs((U-th)/th))\n",
    "    U[U<0]=0\n",
    "    return U\n",
    "\n",
    "def test(toy):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    toy = toy.cuda()\n",
    "    for data, target in test_loader_cifar10:\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "        output = toy(data)\n",
    "        test_loss +=F.cross_entropy(output, target, size_average=False).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader_cifar10.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader_cifar10.dataset),\n",
    "        100. * correct / len(test_loader_cifar10.dataset)))\n",
    "\n",
    "def quant(input, k):\n",
    "    size = input.size()\n",
    "    #mean = torch.mean(input.abs(), 1, keepdim=True)\n",
    "    x = input\n",
    "    #print(x)\n",
    "    xmax = x.abs().max()\n",
    "    num_bits=k\n",
    "    v0 = 1\n",
    "    v1 = 2\n",
    "    v2 = -0.5\n",
    "    y = k #2.**num_bits - 1.\n",
    "    #print(y)\n",
    "    x = x.add(v0).div(v1)\n",
    "    #print(x)\n",
    "    x = x.mul(y).round_()\n",
    "    #print(x)\n",
    "    x = x.div(y)\n",
    "    #print(x)\n",
    "    x = x.add(v2)\n",
    "    #print(x)\n",
    "    x = x.mul(v1)\n",
    "    #print(x)\n",
    "    input = x\n",
    "    return input\n",
    "\n",
    "def conv_weight_update(dH,X,pad):\n",
    "    shap = dH.shape[1]\n",
    "    dH = torch.sum(dH,0)\n",
    "    dH = torch.unsqueeze(dH,1)\n",
    "    dH = torch.repeat_interleave(dH,X.shape[1],0)\n",
    "    X = X.repeat(1,shap,1,1)\n",
    "    dw_conv = F.conv2d(X,dH,padding=pad,groups=X.shape[1])\n",
    "    return dw_conv\n",
    "\n",
    "def conv_dx_update(dH,W,pad):\n",
    "\n",
    "    W = torch.transpose(W,0,1)\n",
    "    W = torch.flip(W,[-1,-2]) # W = C*3*3\n",
    "    dx_conv = F.conv2d(dH,W,padding=1)\n",
    "    \n",
    "    return dx_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d766c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, time_step,leak):\n",
    "        super(model, self).__init__()\n",
    "        \n",
    "        self.fc_1 = nn.Linear(28*28,256,bias=False)\n",
    "        self.fc_2 = nn.Linear(256,256,bias=False)\n",
    "        self.fc_out = nn.Linear(256,10,bias=False)\n",
    "        \n",
    "        self.lif1 = LIF(time_step,leak)\n",
    "        self.lif2 = LIF(time_step,leak)\n",
    "        self.time_step = time_step\n",
    "        self.s_regs_inp = None\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        inp = inp.view(inp.shape[0],-1)\n",
    "        size = inp.shape\n",
    "        self.s_regs_inp = torch.zeros(self.time_step,*size, device=device)\n",
    "        u_out = 0\n",
    "        \n",
    "        for t in range(self.time_step):\n",
    "            \n",
    "            spike_inp = PoissonGen(inp)\n",
    "            self.s_regs_inp[t] += spike_inp \n",
    "            \n",
    "            x = self.fc_1(spike_inp)\n",
    "            #x = quant(x,2**4)\n",
    "            x = self.lif1(x, t)\n",
    "            x = self.fc_2(x)\n",
    "            #x = quant(x,2**4)\n",
    "            x = self.lif2(x, t)\n",
    "            x = self.fc_out(x)\n",
    "            u_out = u_out + x\n",
    "        return u_out/self.time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db8d72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,time_step,leak):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.fc_1 = nn.Linear(28*28,512,bias=False)\n",
    "        self.fc_out = nn.Linear(512,10,bias=False)\n",
    "        self.lif1 = LIF(time_step,leak)\n",
    "        self.time_step = time_step\n",
    "        self.s_regs_inp = None\n",
    "        \n",
    "    def forward(self, inp):\n",
    "#         print(\"size is:\", (inp.view(inp.shape[0],1,28,28)).shape)\n",
    "        inp = inp.view(inp.shape[0],-1)\n",
    "        size = inp.shape\n",
    "        \n",
    "        self.s_regs_inp = torch.zeros(self.time_step,*size, device=device)\n",
    "        u_out = 0\n",
    "        \n",
    "        for t in range(self.time_step):\n",
    "            spike_inp = PoissonGen(inp)\n",
    "            self.s_regs_inp[t] += spike_inp \n",
    "            x = self.fc_1(spike_inp)\n",
    "            #x = quant(x,2**4)\n",
    "            x = self.lif1(x, t)\n",
    "            x = self.fc_out(x)\n",
    "            u_out = u_out + x\n",
    "        return u_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28765ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_5(nn.Module):\n",
    "    def __init__(self,time_step, leak):\n",
    "        super(VGG_5, self).__init__()\n",
    "        \n",
    "        self.time_step = time_step\n",
    "        self.s_regs_inp = None\n",
    "        self.s_regs_conv = None\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv_lif1 = LIF(time_step, leak)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,return_indices=True)\n",
    "        self.pool1_ind = []\n",
    "        self.unpool1 = nn.MaxUnpool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv_lif2 = LIF(time_step, leak)\n",
    "        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv_lif3 = LIF(time_step, leak)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2,return_indices=True)\n",
    "        self.pool2_ind = []\n",
    "        self.unpool2 = nn.MaxUnpool2d(kernel_size=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 1024, bias=False)\n",
    "        self.fc_lif1 = LIF(time_step,leak)\n",
    "        self.fc_out = nn.Linear(1024, 10, bias=False)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "\n",
    "        size = inp.shape\n",
    "        self.s_regs_inp = torch.zeros(self.time_step,*size, device=device)\n",
    "        self.pool1_ind = []\n",
    "        self.pool2_ind = []\n",
    "        u_out = 0\n",
    "        \n",
    "        for t in range(self.time_step):\n",
    "            spike_inp = PoissonGen(inp)\n",
    "            self.s_regs_inp[t] += spike_inp \n",
    "            x = self.conv1(spike_inp)\n",
    "            x = self.conv_lif1(x,t)\n",
    "            x,indices = self.pool1(x)\n",
    "            self.pool1_ind.append(indices)\n",
    "            x = self.conv2(x)\n",
    "            x = self.conv_lif2(x,t)\n",
    "            x = self.conv3(x)\n",
    "            x = self.conv_lif3(x,t)\n",
    "            x,indices = self.pool2(x)\n",
    "            x = x.view(x.shape[0],-1)\n",
    "            \n",
    "            if t == 0:\n",
    "                self.s_regs_conv = torch.zeros(self.time_step,*x.shape, device=device)\n",
    "            self.pool2_ind.append(indices)\n",
    "            self.s_regs_conv[t] += x\n",
    "            \n",
    "            x = self.fc1(x)\n",
    "            x = self.fc_lif1(x,t)\n",
    "            x = self.fc_out(x)\n",
    "            u_out = u_out + x\n",
    "        return u_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37c149d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp_VGG5(vgg,leak,time_step,du_out,l_r,th):\n",
    "   \n",
    "    ## Update weight in FCs, time T\n",
    "    du_fc1 = torch.matmul(du_out,vgg.fc_out.weight)*de_func(vgg.fc_lif1.u_regs[-1],th)\n",
    "    vgg.fc_lif1.du_regs[-1] += du_fc1\n",
    "    w_conv_1 = torch.matmul(torch.transpose(du_fc1,0,1),vgg.s_regs_conv[-1])\n",
    "    vgg.fc1.weight.data -= l_r*w_conv_1   \n",
    "    w_1_out = torch.matmul(torch.transpose(du_out,0,1),vgg.fc_lif1.s_regs[-1])\n",
    "    vgg.fc_out.weight.data -= l_r*w_1_out\n",
    "    \n",
    "    ## Update du in pool2, time T\n",
    "    dx_pool2 = torch.matmul(du_fc1,vgg.fc1.weight)\n",
    "    dx_pool2 = dx_pool2.view(dx_pool2.shape[0],128,8,8)\n",
    "    du_pool2 = vgg.unpool2(dx_pool2,vgg.pool2_ind[-1])\n",
    "    \n",
    "    ## Update du and dw in conv3, time T\n",
    "    du_conv3 = du_pool2*de_func(toy.conv_lif3.u_regs[-1],th)\n",
    "    vgg.conv_lif3.du_regs[-1] += du_conv3 \n",
    "    dW_conv3 = conv_weight_update(du_pool2.type(torch.float),vgg.conv_lif2.s_regs[-1].type(torch.float),1)\n",
    "    dW_conv3 = torch.sum(dW_conv3,0)\n",
    "    dW_conv3 = dW_conv3.view(128,128,dW_conv3.shape[-1],dW_conv3.shape[-1])\n",
    "    vgg.conv3.weight.data -=l_r*dW_conv3\n",
    "    \n",
    "    ## Update du and dw in conv2, time T\n",
    "    \n",
    "    du_conv2 = conv_dx_update(du_conv3,vgg.conv3.weight,'same')*de_func(toy.conv_lif2.u_regs[-1],th)\n",
    "    vgg.conv_lif2.du_regs[-1] += du_conv2\n",
    "    dW_conv2 = conv_weight_update(du_conv2.type(torch.float),F.max_pool2d(vgg.conv_lif1.s_regs[-1].type(torch.float),kernel_size=2),1)\n",
    "    dW_conv2 = torch.sum(dW_conv2,0)\n",
    "    dW_conv2 = dW_conv2.view(128,64,dW_conv2.shape[-1],dW_conv2.shape[-1])\n",
    "    vgg.conv2.weight.data -=l_r*dW_conv2\n",
    "    \n",
    "    ## Update du in pool2, time t\n",
    "    du_pool1 = vgg.unpool1(conv_dx_update(du_conv2,vgg.conv2.weight,'same'),vgg.pool1_ind[-1])\n",
    "    \n",
    "    du_conv1 = du_pool1*de_func(toy.conv_lif1.u_regs[-1],th)\n",
    "    vgg.conv_lif1.du_regs[-1] += du_conv1\n",
    "    dW_conv1 = conv_weight_update(du_conv1.type(torch.float),vgg.s_regs_inp[-1].type(torch.float),1)\n",
    "    dW_conv1 = torch.sum(dW_conv1,0)\n",
    "    dW_conv1 = dW_conv1.view(64,3,dW_conv1.shape[-1],dW_conv1.shape[-1])\n",
    "    vgg.conv1.weight.data -=l_r*dW_conv1\n",
    "    \n",
    "\n",
    "\n",
    "    for t in range(time_step-2,-1,-1):\n",
    "        \n",
    "        ds_fc1 = torch.matmul(du_out,vgg.fc_out.weight)+vgg.fc_lif1.du_regs[t+1]*(-leak*vgg.fc_lif1.du_regs[t])\n",
    "        du_fc1 = (ds_fc1)*de_func(vgg.fc_lif1.du_regs[t],th) + vgg.fc_lif1.du_regs[t+1]*leak*(1-vgg.fc_lif1.s_regs[t])\n",
    "        vgg.fc_lif1.du_regs[t] += du_fc1\n",
    "        w_conv_1 = torch.matmul(torch.transpose(du_fc1,0,1),vgg.s_regs_conv[t])\n",
    "        vgg.fc1.weight.data -= l_r*w_conv_1   \n",
    "        w_1_out = torch.matmul(torch.transpose(du_out,0,1),vgg.fc_lif1.s_regs[t])\n",
    "        vgg.fc_out.weight.data -= l_r*w_1_out\n",
    "        \n",
    "        \n",
    "        dx_pool2 = torch.matmul(du_fc1,vgg.fc1.weight)\n",
    "        dx_pool2 = dx_pool2.view(dx_pool2.shape[0],128,8,8)\n",
    "        du_pool2 = vgg.unpool2(dx_pool2,vgg.pool2_ind[t])\n",
    "        ds_conv3 = du_pool2+vgg.conv_lif3.du_regs[t+1]*(-leak*vgg.conv_lif3.du_regs[t])\n",
    "        du_conv3 = ds_conv3*de_func(toy.conv_lif3.u_regs[t],th) + vgg.conv_lif3.du_regs[t+1]*leak*(1-vgg.conv_lif3.s_regs[t])\n",
    "        vgg.conv_lif3.du_regs[t] += du_conv3 \n",
    "        dW_conv3 = conv_weight_update(du_pool2.type(torch.float),vgg.conv_lif2.s_regs[t].type(torch.float),1)\n",
    "        dW_conv3 = torch.sum(dW_conv3,0)\n",
    "        dW_conv3 = dW_conv3.view(128,128,dW_conv3.shape[-1],dW_conv3.shape[-1])\n",
    "        vgg.conv3.weight.data -=l_r*dW_conv3\n",
    "        \n",
    "        ds_conv2 = conv_dx_update(du_conv3,vgg.conv3.weight,'same')+vgg.conv_lif2.du_regs[t+1]*(-leak*vgg.conv_lif2.du_regs[t])\n",
    "        du_conv2 = ds_conv2*de_func(toy.conv_lif2.u_regs[t],th) + vgg.conv_lif2.du_regs[t+1]*leak*(1-vgg.conv_lif2.s_regs[t])\n",
    "        vgg.conv_lif2.du_regs[t] += du_conv2 \n",
    "        dW_conv2 = conv_weight_update(du_conv2.type(torch.float),F.max_pool2d(vgg.conv_lif1.s_regs[t].type(torch.float),kernel_size=2),1)\n",
    "        dW_conv2 = torch.sum(dW_conv2,0)\n",
    "        dW_conv2 = dW_conv2.view(128,64,dW_conv2.shape[-1],dW_conv2.shape[-1])\n",
    "        vgg.conv2.weight.data -=l_r*dW_conv2\n",
    "        \n",
    "        \n",
    "        du_pool1 = vgg.unpool1(conv_dx_update(du_conv2,vgg.conv2.weight,'same'),vgg.pool1_ind[t])\n",
    "        ds_conv1 = du_pool1 + vgg.conv_lif1.du_regs[t+1]*(-leak*vgg.conv_lif1.du_regs[t])\n",
    "        du_conv1 = ds_conv1*de_func(toy.conv_lif1.u_regs[t],th) + vgg.conv_lif1.du_regs[t+1]*leak*(1-vgg.conv_lif1.s_regs[t])\n",
    "        vgg.conv_lif1.du_regs[t] += du_conv1\n",
    "        dW_conv1 = conv_weight_update(du_conv1.type(torch.float),vgg.s_regs_inp[t].type(torch.float),1)\n",
    "        dW_conv1 = torch.sum(dW_conv1,0)\n",
    "        dW_conv1 = dW_conv1.view(64,3,dW_conv1.shape[-1],dW_conv1.shape[-1])\n",
    "        vgg.conv1.weight.data -=l_r*dW_conv1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5802d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     du_pool2 = torch.sum(du_pool2,0)\n",
    "#     du_pool2 = torch.unsqueeze(du_pool2,1)\n",
    "    \n",
    "    ## Update du in conv3, time T\n",
    "#     d_conv3 = nn.Conv2d(128, 128, stride=1, kernel_size=f, padding=f-1, bias=False)\n",
    "    \n",
    "    ## Update weight in Conv3, time T\n",
    "#     f = du_pool2.shape[-1]\n",
    "#     d_conv3 = nn.Conv2d(128, 128, stride=1, padding=1, kernel_size=f, bias=False)\n",
    "#     d_conv3.weight.data = du_pool2.type(torch.float)\n",
    "#     dW_conv3 = d_conv3(vgg.conv_lif2.s_regs[-1].type(torch.float))\n",
    "#     dW_conv3 = torch.sum(dW_conv3,0)\n",
    "#     dW_conv3 = torch.unsqueeze(dW_conv3,1)\n",
    "#     vgg.conv3.weight.data -= l_r*dW_conv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7adf32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_1(nn.Module):\n",
    "    def __init__(self,time_step,leak):\n",
    "        super(VGG_1, self).__init__()\n",
    "        \n",
    "        self.time_step = time_step\n",
    "        self.s_regs_inp = None\n",
    "        self.s_regs_conv = None\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1, bias=False)\n",
    "        \n",
    "#         self.deconv1 = nn.Conv2d()\n",
    "        self.lif_conv1 = LIF(time_step,leak)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,return_indices=True)\n",
    "        self.pool1_ind = []\n",
    "        self.unpool1 = nn.MaxUnpool2d(kernel_size=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(16 * 14 * 14, 512, bias=False)\n",
    "        self.lif_fc1 = LIF(time_step,leak)\n",
    "        self.fc_out = nn.Linear(512, 10, bias=False)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "\n",
    "        size = inp.shape\n",
    "        self.s_regs_inp = torch.zeros(self.time_step,*size, device=device)\n",
    "        self.pool1_ind = []\n",
    "\n",
    "        u_out = 0\n",
    "        for t in range(self.time_step):\n",
    "            spike_inp = PoissonGen(inp)\n",
    "            self.s_regs_inp[t] += spike_inp\n",
    "            x = self.conv1(spike_inp)\n",
    "            x = self.lif_conv1(x,t)\n",
    "            x, indices = self.pool1(x)\n",
    "            x= x.view(x.shape[0],-1)\n",
    "            \n",
    "            if t == 0:\n",
    "                self.s_regs_conv = torch.zeros(self.time_step,*x.shape, device=device)\n",
    "            self.pool1_ind.append(indices)\n",
    "            self.s_regs_conv[t] += x\n",
    "            \n",
    "            x = self.fc1(x)\n",
    "            x = self.lif_fc1(x,t)\n",
    "            \n",
    "            x = self.fc_out(x)\n",
    "            u_out = u_out + x\n",
    "\n",
    "        return u_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31ffe4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp_VGG1(vgg,leak,time_step,du_out,l_r,th):\n",
    "   \n",
    "    ## First fc\n",
    "    du_fc1 = torch.matmul(du_out,vgg.fc_out.weight)*de_func(vgg.lif_fc1.u_regs[-1],th)\n",
    "    vgg.lif_fc1.du_regs[-1] += du_fc1\n",
    "       \n",
    "    ## Update weight\n",
    "    w_conv_1 = torch.matmul(torch.transpose(du_fc1,0,1),vgg.s_regs_conv[-1])\n",
    "    vgg.fc1.weight.data -= l_r*w_conv_1\n",
    "     \n",
    "    w_1_out = torch.matmul(torch.transpose(du_out,0,1),vgg.lif_fc1.s_regs[-1])\n",
    "    vgg.fc_out.weight.data -= l_r*w_1_out\n",
    "    \n",
    "    dx_pool1 = torch.matmul(du_fc1,vgg.fc1.weight)\n",
    "    dx_pool1 = dx_pool1.view(dx_pool1.shape[0],16,14,14)\n",
    "    du_pool1 = vgg.unpool1(dx_pool1,vgg.pool1_ind[-1])\n",
    "    du_pool1 = torch.sum(du_pool1,0)\n",
    "    du_pool1 = torch.unsqueeze(du_pool1,1)\n",
    "    f = du_pool1.shape[-1]\n",
    "    d_conv1_w = nn.Conv2d(1, 16, stride=1, padding=1,kernel_size=f, bias=False)\n",
    "    d_conv1_w.weight.data = du_pool1.type(torch.float)\n",
    "    dW = d_conv1_w(vgg.s_regs_inp[-1].type(torch.float))\n",
    "    dW = torch.sum(dW,0)\n",
    "    dW = torch.unsqueeze(dW,1)\n",
    "\n",
    "    vgg.conv1.weight.data -= l_r*dW\n",
    "    \n",
    "    for t in range(time_step-2,-1,-1):\n",
    "        \n",
    "        ds_fc1 = torch.matmul(du_out,vgg.fc_out.weight)+vgg.lif_fc1.du_regs[t+1]*(-leak*vgg.lif_fc1.du_regs[t])\n",
    "        du_fc1 = (ds_fc1)*de_func(vgg.lif_fc1.du_regs[t],th) + vgg.lif_fc1.du_regs[t+1]*leak*(1-vgg.lif_fc1.s_regs[t])\n",
    "        vgg.lif_fc1.du_regs[t] += du_fc1\n",
    "        \n",
    "        w_conv_1 = torch.matmul(torch.transpose(du_fc1,0,1),vgg.s_regs_conv[t])\n",
    "        vgg.fc1.weight.data -= l_r*w_conv_1\n",
    "        \n",
    "        \n",
    "        dx_pool1 = torch.matmul(du_fc1,vgg.fc1.weight)\n",
    "        dx_pool1 = dx_pool1.view(dx_pool1.shape[0],16,14,14)\n",
    "        du_pool1 = vgg.unpool1(dx_pool1,vgg.pool1_ind[t])\n",
    "        du_pool1 = torch.sum(du_pool1,0)\n",
    "        du_pool1 = torch.unsqueeze(du_pool1,1)\n",
    "        f = du_pool1.shape[-1]\n",
    "        d_conv1_w = nn.Conv2d(1, 16, stride=1, padding=1,kernel_size=f, bias=False)\n",
    "        d_conv1_w.weight.data = du_pool1.type(torch.float)\n",
    "        dW = d_conv1_w(vgg.s_regs_inp[t].type(torch.float))\n",
    "        dW = torch.sum(dW,0)\n",
    "        dW = torch.unsqueeze(dW,1)\n",
    "\n",
    "        vgg.conv1.weight.data -= l_r*dW\n",
    "    \n",
    "    \n",
    "    return 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e6f78f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIF(nn.Module):\n",
    "    def __init__(self, time_step,leak):\n",
    "        super(LIF, self).__init__()\n",
    "        \n",
    "        self.u_regs = None\n",
    "        self.du_regs = None\n",
    "        self.s_regs = None\n",
    "        self.leak = leak\n",
    "        self.time_step = time_step\n",
    "        self.thresh = 0.7\n",
    "        \n",
    "    def forward(self,inp,t):\n",
    "        \n",
    "#         print(\"memory before clear\",torch.cuda.memory_allocated())\n",
    "        if t == 0:\n",
    "            size = inp.shape\n",
    "            self.u_regs = torch.zeros(self.time_step,*size, device=device)\n",
    "            self.du_regs = torch.zeros(self.time_step,*size, device=device)\n",
    "#             err = torch.normal(0, 0.1,(1,1)).cuda()\n",
    "#             inp = inp + err\n",
    "#             self.u_regs[0] = quant(inp,2**4)\n",
    "            self.u_regs[0] = inp\n",
    "            self.s_regs = torch.zeros(self.time_step,*size, device=device)\n",
    "\n",
    "            spike = inp.gt(self.thresh).float()\n",
    "\n",
    "            self.s_regs[0] = spike\n",
    "            \n",
    "        else:\n",
    "#             err = torch.normal(0, 0.1,(1,1))\n",
    "#             inp = inp + err\n",
    "#             self.u_regs[t] = quant(self.leak * self.u_regs[t-1] * (1 - self.s_regs[t-1]) + (1-self.leak)*inp, 2**4)\n",
    "            self.u_regs[t] = self.leak*self.u_regs[t-1]*(1-self.s_regs[t-1]) + inp\n",
    "\n",
    "            spike = self.u_regs[t].gt(self.thresh).float()\n",
    "\n",
    "            self.s_regs[t] = spike\n",
    "            \n",
    "#         print(\"memory after clear\",torch.cuda.memory_allocated())\n",
    "#         torch.cuda.empty_cache()\n",
    "#         gc.collect()\n",
    "        return spike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8fc2dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Back propagation for MLP\n",
    "def bp_MLP(toy,leak,time_step,du_out,s_regs_inp,l_r,th):\n",
    "    \n",
    "    ## First fc\n",
    "    du_fc1 = torch.matmul(du_out,toy.fc_out.weight)*de_func(toy.lif1.u_regs[-1],th)\n",
    "    toy.lif1.du_regs[-1] += du_fc1\n",
    "\n",
    "    ## Update weight\n",
    "    w_inp_1 = torch.matmul(torch.transpose(du_fc1,0,1),s_regs_inp[-1])\n",
    "#     toy.fc_1.weight.data -= l_r*quant(w_inp_1,2**4)\n",
    "    toy.fc_1.weight.data -= l_r*w_inp_1\n",
    "    \n",
    "    w_1_out = torch.matmul(torch.transpose(du_out,0,1),toy.lif1.s_regs[-1])\n",
    "#     toy.fc_out.weight.data -= l_r*quant(w_1_out,2**4)\n",
    "    toy.fc_out.weight.data -= l_r*w_1_out\n",
    "\n",
    "    for t in range(time_step-2,-1,-1):\n",
    "        \n",
    "        ## First fc\n",
    "        ds_fc1 = torch.matmul(du_out,toy.fc_out.weight)+toy.lif1.du_regs[t+1]*(-leak*toy.lif1.u_regs[t])\n",
    "        du_fc1 = (ds_fc1)*de_func(toy.lif1.u_regs[t],th) + toy.lif1.du_regs[t+1]*leak*(1-toy.lif1.s_regs[t])\n",
    "        toy.lif1.du_regs[t] += du_fc1\n",
    "\n",
    "        ## Update weight\n",
    "        w_inp_1 = torch.matmul(torch.transpose(du_fc1,0,1),s_regs_inp[t])\n",
    "#         toy.fc_1.weight.data -= l_r*quant(w_inp_1,2**4)\n",
    "#         print(\"du_size\",du_fc1.shape)\n",
    "#         print(\"s_size\",s_regs_inp[t].shape)\n",
    "#         print(\"dweight shape\",w_inp_1.shape)\n",
    "        toy.fc_1.weight.data -= l_r*w_inp_1\n",
    "\n",
    "        w_1_out = torch.matmul(torch.transpose(du_out,0,1),toy.lif1.s_regs[t])\n",
    "#         toy.fc_out.weight.data -= l_r*quant(w_1_out,2**4)\n",
    "        toy.fc_out.weight.data -= l_r*w_1_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b08084b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Back propagation\n",
    "def bp(toy,leak,time_step,du_out,s_regs_inp,l_r,th):\n",
    "    \n",
    "    ## Second fc    \n",
    "    du_fc2 = torch.matmul(du_out,toy.fc_out.weight)*de_func(toy.lif2.u_regs[-1],th)    \n",
    "    toy.lif2.du_regs[-1] = toy.lif2.du_regs[-1] + du_fc2\n",
    "    \n",
    "    ## First fc\n",
    "    du_fc1 = torch.matmul(du_fc2,toy.fc_2.weight)*de_func(toy.lif1.u_regs[-1],th)\n",
    "    toy.lif1.du_regs[-1] += du_fc1\n",
    "\n",
    "    \n",
    "    ## Update weight\n",
    "    w_inp_1 = torch.matmul(torch.transpose(du_fc1,0,1),s_regs_inp[-1])\n",
    "    toy.fc_1.weight.data -= l_r*quant(w_inp_1,2**4)\n",
    "    #toy.fc_1.weight.data -= l_r*w_inp_1\n",
    "\n",
    "    w_1_2 = torch.matmul(torch.transpose(du_fc2,0,1),toy.lif1.s_regs[-1])\n",
    "    toy.fc_2.weight.data -= l_r*quant(w_1_2,2**4)\n",
    "    #toy.fc_2.weight.data -= l_r*w_1_2\n",
    "\n",
    "    w_2_out = torch.matmul(torch.transpose(du_out,0,1),toy.lif2.s_regs[-1])\n",
    "    toy.fc_out.weight.data -= l_r*quant(w_2_out,2**4)\n",
    "    #toy.fc_out.weight.data -= l_r*w_2_out\n",
    "\n",
    "    for t in range(time_step-2,-1,-1):\n",
    "\n",
    "        ds_fc2 = torch.matmul(du_out,toy.fc_out.weight)+toy.lif2.du_regs[t+1]*(-leak*toy.lif2.u_regs[t])\n",
    "        du_fc2 = (ds_fc2)*de_func(toy.lif2.u_regs[t],th) + toy.lif2.du_regs[t+1]*leak*(1-toy.lif2.s_regs[t])\n",
    "        toy.lif2.du_regs[t] += du_fc2\n",
    "        \n",
    "        ## First fc\n",
    "        ds_fc1 = torch.matmul(du_fc2,toy.fc_2.weight)+toy.lif1.du_regs[t+1]*(-leak*toy.lif1.u_regs[t])\n",
    "        du_fc1 = (ds_fc1)*de_func(toy.lif1.u_regs[t],th) + toy.lif1.du_regs[t+1]*leak*(1-toy.lif1.s_regs[t])\n",
    "        toy.lif1.du_regs[t] += du_fc1\n",
    "\n",
    "        ## Update weight\n",
    "        w_inp_1 = torch.matmul(torch.transpose(du_fc1,0,1),s_regs_inp[t])\n",
    "        toy.fc_1.weight.data -= l_r*quant(w_inp_1,2**4)\n",
    "        \n",
    "        #toy.fc_1.weight.data -= l_r*w_inp_1\n",
    "\n",
    "        w_1_2 = torch.matmul(torch.transpose(du_fc2,0,1),toy.lif1.s_regs[t])\n",
    "        toy.fc_2.weight.data -= l_r*quant(w_1_2,2**4)\n",
    "        #toy.fc_2.weight.data -= l_r*w_1_2\n",
    "\n",
    "        w_2_out = torch.matmul(torch.transpose(du_out,0,1),toy.lif2.s_regs[t])\n",
    "        toy.fc_out.weight.data -= l_r*quant(w_2_out,2**4)\n",
    "        #toy.fc_out.weight.data -= l_r*w_2_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c3de0fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruokai\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size_test = 100\n",
    "\n",
    "train_loader_mnist = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./mnist', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader_mnist = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./mnist', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edee34dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<!--[if lt IE 7]>   <html class=\"no-js ie6 lt-ie7 lt-ie8 lt-ie9\">   <![endif]-->\n",
      "<!--[if IE 7]>      <html class=\"no-js ie7 lt-ie8 lt-ie9\">          <![endif]-->\n",
      "<!--[if IE 8]>      <html class=\"no-js ie8 lt-ie9\">                 <![endif]-->\n",
      "<!--[if gt IE 8]><!--><html class=\"no-js\" lang=\"en\" dir=\"ltr\">  <!--<![endif]-->\n",
      "\n",
      "<head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "\n",
      "    <link rel=\"prefetch\" href=\"//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js\">\n",
      "    <link rel=\"prefetch\" href=\"//ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js\">\n",
      "\n",
      "    <meta name=\"application-name\" content=\"Python.org\">\n",
      "    <meta name=\"msapplication-tooltip\" content=\"The official home of the Python Programming Language\">\n",
      "    <meta name=\"apple-mobile-web-app-title\" content=\"Python.org\">\n",
      "    <meta name=\"apple-mobile-web-app-capable\" content=\"yes\">\n",
      "    <meta name=\"apple-mobile-web-app-status-bar-style\" content=\"black\">\n",
      "\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <meta name=\"HandheldFriendly\" content=\"True\">\n",
      "    <meta name=\"format-detection\" content=\"telephone=no\">\n",
      "    <meta http-equiv=\"cleartype\" content=\"on\">\n",
      "    <meta http-equiv=\"imagetoolbar\" content=\"false\">\n",
      "\n",
      "    <script src=\"/static/js/libs/modernizr.js\"></script>\n",
      "\n",
      "    <link href=\"/static/stylesheets/style.15ff3dddc9c3.css\" rel=\"stylesheet\" type=\"text/css\" media=\"all\" title=\"default\" />\n",
      "    <link href=\"/static/stylesheets/mq.f9187444a4a1.css\" rel=\"stylesheet\" type=\"text/css\" media=\"not print, braille, embossed, speech, tty\" />\n",
      "    \n",
      "\n",
      "    <!--[if (lte IE 8)&(!IEMobile)]>\n",
      "    <link href=\"/static/stylesheets/no-mq.bf0c425cdb73.css\" rel=\"stylesheet\" type=\"text/css\" media=\"screen\" />\n",
      "    \n",
      "    \n",
      "    <![endif]-->\n",
      "    <link rel=\"stylesheet\" href=\"//ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/themes/smoothness/jquery-ui.css\">\n",
      "\n",
      "    \n",
      "    <link rel=\"icon\" type=\"image/x-icon\" href=\"/static/favicon.ico\">\n",
      "    <link rel=\"apple-touch-icon-precomposed\" sizes=\"144x144\" href=\"/static/apple-touch-icon-144x144-precomposed.png\">\n",
      "    <link rel=\"apple-touch-icon-precomposed\" sizes=\"114x114\" href=\"/static/apple-touch-icon-114x114-precomposed.png\">\n",
      "    <link rel=\"apple-touch-icon-precomposed\" sizes=\"72x72\" href=\"/static/apple-touch-icon-72x72-precomposed.png\">\n",
      "    <link rel=\"apple-touch-icon-precomposed\" href=\"/static/apple-touch-icon-precomposed.png\">\n",
      "    <link rel=\"apple-touch-icon\" href=\"/static/apple-touch-icon-precomposed.png\">\n",
      "\n",
      "    \n",
      "    <meta name=\"msapplication-TileImage\" content=\"/static/metro-icon-144x144-precomposed.png\"><!-- white shape -->\n",
      "    <meta name=\"msapplication-TileColor\" content=\"#3673a5\"><!-- python blue -->\n",
      "    <meta name=\"msapplication-navbutton-color\" content=\"#3673a5\">\n",
      "\n",
      "    <title>Welcome to Python.org</title>\n",
      "\n",
      "    <meta name=\"description\" content=\"The official home of the Python Programming Language\">\n",
      "    <meta name=\"keywords\" content=\"Python programming language object oriented web free open source software license documentation download community\">\n",
      "\n",
      "    \n",
      "    <meta property=\"og:type\" content=\"website\">\n",
      "    <meta property=\"og:site_name\" content=\"Python.org\">\n",
      "    <meta property=\"og:title\" content=\"Welcome to Python.org\">\n",
      "    <meta property=\"og:description\" content=\"The official home of the Python Programming Language\">\n",
      "    \n",
      "    <meta property=\"og:image\" content=\"https://www.python.org/static/opengraph-icon-200x200.png\">\n",
      "    <meta property=\"og:image:secure_url\" content=\"https://www.python.org/static/opengraph-icon-200x200.png\">\n",
      "    \n",
      "    <meta property=\"og:url\" content=\"https://www.python.org/\">\n",
      "\n",
      "    <link rel=\"author\" href=\"/static/humans.txt\">\n",
      "\n",
      "    <link rel=\"alternate\" type=\"application/rss+xml\" title=\"Python Enhancement Proposals\"\n",
      "          href=\"https://www.python.org/dev/peps/peps.rss/\">\n",
      "    <link rel=\"alternate\" type=\"application/rss+xml\" title=\"Python Job Opportunities\"\n",
      "          href=\"https://www.python.org/jobs/feed/rss/\">\n",
      "    <link rel=\"alternate\" type=\"application/rss+xml\" title=\"Python Software Foundation News\"\n",
      "          href=\"https://feeds.feedburner.com/PythonSoftwareFoundationNews\">\n",
      "    <link rel=\"alternate\" type=\"application/rss+xml\" title=\"Python Insider\"\n",
      "          href=\"https://feeds.feedburner.com/PythonInsider\">\n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "    <script type=\"application/ld+json\">\n",
      "     {\n",
      "       \"@context\": \"https://schema.org\",\n",
      "       \"@type\": \"WebSite\",\n",
      "       \"url\": \"https://www.python.org/\",\n",
      "       \"potentialAction\": {\n",
      "         \"@type\": \"SearchAction\",\n",
      "         \"target\": \"https://www.python.org/search/?q={search_term_string}\",\n",
      "         \"query-input\": \"required name=search_term_string\"\n",
      "       }\n",
      "     }\n",
      "    </script>\n",
      "\n",
      "    \n",
      "    <script type=\"text/javascript\">\n",
      "    var _gaq = _gaq || [];\n",
      "    _gaq.push(['_setAccount', 'UA-39055973-1']);\n",
      "    _gaq.push(['_trackPageview']);\n",
      "\n",
      "    (function() {\n",
      "        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;\n",
      "        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';\n",
      "        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);\n",
      "    })();\n",
      "    </script>\n",
      "    \n",
      "</head>\n",
      "\n",
      "<body class=\"python home\" id=\"homepage\">\n",
      "\n",
      "    <div id=\"touchnav-wrapper\">\n",
      "\n",
      "        <div id=\"nojs\" class=\"do-not-print\">\n",
      "            <p><strong>Notice:</strong> While JavaScript is not essential for this website, your interaction with the content will be limited. Please turn JavaScript on for the full experience. </p>\n",
      "        </div>\n",
      "\n",
      "        <!--[if lte IE 8]>\n",
      "        <div id=\"oldie-warning\" class=\"do-not-print\">\n",
      "            <p>\n",
      "                <strong>Notice:</strong> Your browser is <em>ancient</em>. Please\n",
      "                <a href=\"http://browsehappy.com/\">upgrade to a different browser</a> to experience a better web.\n",
      "            </p>\n",
      "        </div>\n",
      "        <![endif]-->\n",
      "\n",
      "        <!-- Sister Site Links -->\n",
      "        <div id=\"top\" class=\"top-bar do-not-print\">\n",
      "\n",
      "            <nav class=\"meta-navigation container\" role=\"navigation\">\n",
      "\n",
      "                \n",
      "                <div class=\"skip-link screen-reader-text\">\n",
      "                    <a href=\"#content\" title=\"Skip to content\">Skip to content</a>\n",
      "                </div>\n",
      "\n",
      "                \n",
      "                <a id=\"close-python-network\" class=\"jump-link\" href=\"#python-network\" aria-hidden=\"true\">\n",
      "                    <span aria-hidden=\"true\" class=\"icon-arrow-down\"><span>&#9660;</span></span> Close\n",
      "                </a>\n",
      "\n",
      "                \n",
      "\n",
      "<ul class=\"menu\" role=\"tree\">\n",
      "    \n",
      "    <li class=\"python-meta current_item selectedcurrent_branch selected\">\n",
      "        <a href=\"/\" title=\"The Python Programming Language\" class=\"current_item selectedcurrent_branch selected\">Python</a>\n",
      "    </li>\n",
      "    \n",
      "    <li class=\"psf-meta \">\n",
      "        <a href=\"/psf-landing/\" title=\"The Python Software Foundation\" >PSF</a>\n",
      "    </li>\n",
      "    \n",
      "    <li class=\"docs-meta \">\n",
      "        <a href=\"https://docs.python.org\" title=\"Python Documentation\" >Docs</a>\n",
      "    </li>\n",
      "    \n",
      "    <li class=\"pypi-meta \">\n",
      "        <a href=\"https://pypi.org/\" title=\"Python Package Index\" >PyPI</a>\n",
      "    </li>\n",
      "    \n",
      "    <li class=\"jobs-meta \">\n",
      "        <a href=\"/jobs/\" title=\"Python Job Board\" >Jobs</a>\n",
      "    </li>\n",
      "    \n",
      "    <li class=\"shop-meta \">\n",
      "        <a href=\"/community-landing/\"  >Community</a>\n",
      "    </li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "\n",
      "                <a id=\"python-network\" class=\"jump-link\" href=\"#top\" aria-hidden=\"true\">\n",
      "                    <span aria-hidden=\"true\" class=\"icon-arrow-up\"><span>&#9650;</span></span> The Python Network\n",
      "                </a>\n",
      "\n",
      "            </nav>\n",
      "\n",
      "        </div>\n",
      "\n",
      "        <!-- Header elements -->\n",
      "        <header class=\"main-header\" role=\"banner\">\n",
      "            <div class=\"container\">\n",
      "\n",
      "                <h1 class=\"site-headline\">\n",
      "                    <a href=\"/\"><img class=\"python-logo\" src=\"/static/img/python-logo.png\" alt=\"python&trade;\"></a>\n",
      "                </h1>\n",
      "\n",
      "                <div class=\"options-bar-container do-not-print\">\n",
      "                    <a href=\"https://psfmember.org/civicrm/contribute/transact?reset=1&id=2\" class=\"donate-button\">Donate</a>\n",
      "                    <div class=\"options-bar\">\n",
      "                        \n",
      "                        <a id=\"site-map-link\" class=\"jump-to-menu\" href=\"#site-map\"><span class=\"menu-icon\">&equiv;</span> Menu</a><form class=\"search-the-site\" action=\"/search/\" method=\"get\">\n",
      "                            <fieldset title=\"Search Python.org\">\n",
      "\n",
      "                                <span aria-hidden=\"true\" class=\"icon-search\"></span>\n",
      "\n",
      "                                <label class=\"screen-reader-text\" for=\"id-search-field\">Search This Site</label>\n",
      "                                <input id=\"id-search-field\" name=\"q\" type=\"search\" role=\"textbox\" class=\"search-field\" placeholder=\"Search\" value=\"\" tabindex=\"1\">\n",
      "\n",
      "                                <button type=\"submit\" name=\"submit\" id=\"submit\" class=\"search-button\" title=\"Submit this Search\" tabindex=\"3\">\n",
      "                                    GO\n",
      "                                </button>\n",
      "\n",
      "                                \n",
      "                                <!--[if IE]><input type=\"text\" style=\"display: none;\" disabled=\"disabled\" size=\"1\" tabindex=\"4\"><![endif]-->\n",
      "\n",
      "                            </fieldset>\n",
      "                        </form><span class=\"breaker\"></span><div class=\"adjust-font-size\" aria-hidden=\"true\">\n",
      "                            <ul class=\"navigation menu\" aria-label=\"Adjust Text Size on Page\">\n",
      "                                <li class=\"tier-1 last\" aria-haspopup=\"true\">\n",
      "                                    <a href=\"#\" class=\"action-trigger\"><strong><small>A</small> A</strong></a>\n",
      "                                    <ul class=\"subnav menu\">\n",
      "                                        <li class=\"tier-2 element-1\" role=\"treeitem\"><a class=\"text-shrink\" title=\"Make Text Smaller\" href=\"javascript:;\">Smaller</a></li>\n",
      "                                        <li class=\"tier-2 element-2\" role=\"treeitem\"><a class=\"text-grow\" title=\"Make Text Larger\" href=\"javascript:;\">Larger</a></li>\n",
      "                                        <li class=\"tier-2 element-3\" role=\"treeitem\"><a class=\"text-reset\" title=\"Reset any font size changes I have made\" href=\"javascript:;\">Reset</a></li>\n",
      "                                    </ul>\n",
      "                                </li>\n",
      "                            </ul>\n",
      "                        </div><div class=\"winkwink-nudgenudge\">\n",
      "                            <ul class=\"navigation menu\" aria-label=\"Social Media Navigation\">\n",
      "                                <li class=\"tier-1 last\" aria-haspopup=\"true\">\n",
      "                                    <a href=\"#\" class=\"action-trigger\">Socialize</a>\n",
      "                                    <ul class=\"subnav menu\">\n",
      "                                        <li class=\"tier-2 element-1\" role=\"treeitem\"><a href=\"https://www.facebook.com/pythonlang?fref=ts\"><span aria-hidden=\"true\" class=\"icon-facebook\"></span>Facebook</a></li>\n",
      "                                        <li class=\"tier-2 element-2\" role=\"treeitem\"><a href=\"https://twitter.com/ThePSF\"><span aria-hidden=\"true\" class=\"icon-twitter\"></span>Twitter</a></li>\n",
      "                                        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"/community/irc/\"><span aria-hidden=\"true\" class=\"icon-freenode\"></span>Chat on IRC</a></li>\n",
      "                                    </ul>\n",
      "                                </li>\n",
      "                            </ul>\n",
      "                        </div>\n",
      "                        <span data-html-include=\"/authenticated\"></span>\n",
      "                    </div><!-- end options-bar -->\n",
      "                </div>\n",
      "\n",
      "                <nav id=\"mainnav\" class=\"python-navigation main-navigation do-not-print\" role=\"navigation\">\n",
      "                    \n",
      "                        \n",
      "<ul class=\"navigation menu\" role=\"menubar\" aria-label=\"Main Navigation\">\n",
      "  \n",
      "    \n",
      "    \n",
      "    <li id=\"about\" class=\"tier-1 element-1  \" aria-haspopup=\"true\">\n",
      "        <a href=\"/about/\" title=\"\" class=\"\">About</a>\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\" role=\"menu\" aria-hidden=\"true\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeitem\"><a href=\"/about/apps/\" title=\"\">Applications</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-2\" role=\"treeitem\"><a href=\"/about/quotes/\" title=\"\">Quotes</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"/about/gettingstarted/\" title=\"\">Getting Started</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-4\" role=\"treeitem\"><a href=\"/about/help/\" title=\"\">Help</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-5\" role=\"treeitem\"><a href=\"http://brochure.getpython.info/\" title=\"\">Python Brochure</a></li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "        \n",
      "    </li>\n",
      "    \n",
      "    \n",
      "    \n",
      "    <li id=\"downloads\" class=\"tier-1 element-2  \" aria-haspopup=\"true\">\n",
      "        <a href=\"/downloads/\" title=\"\" class=\"\">Downloads</a>\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\" role=\"menu\" aria-hidden=\"true\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeitem\"><a href=\"/downloads/\" title=\"\">All releases</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-2\" role=\"treeitem\"><a href=\"/downloads/source/\" title=\"\">Source code</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"/downloads/windows/\" title=\"\">Windows</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-4\" role=\"treeitem\"><a href=\"/downloads/macos/\" title=\"\">macOS</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-5\" role=\"treeitem\"><a href=\"/download/other/\" title=\"\">Other Platforms</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-6\" role=\"treeitem\"><a href=\"https://docs.python.org/3/license.html\" title=\"\">License</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-7\" role=\"treeitem\"><a href=\"/download/alternatives\" title=\"\">Alternative Implementations</a></li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "        \n",
      "    </li>\n",
      "    \n",
      "    \n",
      "    \n",
      "    <li id=\"documentation\" class=\"tier-1 element-3  \" aria-haspopup=\"true\">\n",
      "        <a href=\"/doc/\" title=\"\" class=\"\">Documentation</a>\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\" role=\"menu\" aria-hidden=\"true\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeitem\"><a href=\"/doc/\" title=\"\">Docs</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-2\" role=\"treeitem\"><a href=\"/doc/av\" title=\"\">Audio/Visual Talks</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"https://wiki.python.org/moin/BeginnersGuide\" title=\"\">Beginner&#39;s Guide</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-4\" role=\"treeitem\"><a href=\"https://devguide.python.org/\" title=\"\">Developer&#39;s Guide</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-5\" role=\"treeitem\"><a href=\"https://docs.python.org/faq/\" title=\"\">FAQ</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-6\" role=\"treeitem\"><a href=\"http://wiki.python.org/moin/Languages\" title=\"\">Non-English Docs</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-7\" role=\"treeitem\"><a href=\"http://python.org/dev/peps/\" title=\"\">PEP Index</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-8\" role=\"treeitem\"><a href=\"https://wiki.python.org/moin/PythonBooks\" title=\"\">Python Books</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-9\" role=\"treeitem\"><a href=\"/doc/essays/\" title=\"\">Python Essays</a></li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "        \n",
      "    </li>\n",
      "    \n",
      "    \n",
      "    \n",
      "    <li id=\"community\" class=\"tier-1 element-4  \" aria-haspopup=\"true\">\n",
      "        <a href=\"/community/\" title=\"\" class=\"\">Community</a>\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\" role=\"menu\" aria-hidden=\"true\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeitem\"><a href=\"/community/survey\" title=\"\">Community Survey</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-2\" role=\"treeitem\"><a href=\"/community/diversity/\" title=\"\">Diversity</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"/community/lists/\" title=\"\">Mailing Lists</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-4\" role=\"treeitem\"><a href=\"/community/irc/\" title=\"\">IRC</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-5\" role=\"treeitem\"><a href=\"/community/forums/\" title=\"\">Forums</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-6\" role=\"treeitem\"><a href=\"/psf/annual-report/2021/\" title=\"\">PSF Annual Impact Report</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-7\" role=\"treeitem\"><a href=\"/community/workshops/\" title=\"\">Python Conferences</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-8\" role=\"treeitem\"><a href=\"/community/sigs/\" title=\"\">Special Interest Groups</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-9\" role=\"treeitem\"><a href=\"/community/logos/\" title=\"\">Python Logo</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-10\" role=\"treeitem\"><a href=\"https://wiki.python.org/moin/\" title=\"\">Python Wiki</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-11\" role=\"treeitem\"><a href=\"/community/merchandise/\" title=\"\">Merchandise</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-12\" role=\"treeitem\"><a href=\"/community/awards\" title=\"\">Community Awards</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-13\" role=\"treeitem\"><a href=\"/psf/conduct/\" title=\"\">Code of Conduct</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-14\" role=\"treeitem\"><a href=\"/psf/get-involved/\" title=\"\">Get Involved</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-15\" role=\"treeitem\"><a href=\"/psf/community-stories/\" title=\"\">Shared Stories</a></li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "        \n",
      "    </li>\n",
      "    \n",
      "    \n",
      "    \n",
      "    <li id=\"success-stories\" class=\"tier-1 element-5  \" aria-haspopup=\"true\">\n",
      "        <a href=\"/success-stories/\" title=\"success-stories\" class=\"\">Success Stories</a>\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\" role=\"menu\" aria-hidden=\"true\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeitem\"><a href=\"/success-stories/category/arts/\" title=\"\">Arts</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-2\" role=\"treeitem\"><a href=\"/success-stories/category/business/\" title=\"\">Business</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"/success-stories/category/education/\" title=\"\">Education</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-4\" role=\"treeitem\"><a href=\"/success-stories/category/engineering/\" title=\"\">Engineering</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-5\" role=\"treeitem\"><a href=\"/success-stories/category/government/\" title=\"\">Government</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-6\" role=\"treeitem\"><a href=\"/success-stories/category/scientific/\" title=\"\">Scientific</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-7\" role=\"treeitem\"><a href=\"/success-stories/category/software-development/\" title=\"\">Software Development</a></li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "        \n",
      "    </li>\n",
      "    \n",
      "    \n",
      "    \n",
      "    <li id=\"news\" class=\"tier-1 element-6  \" aria-haspopup=\"true\">\n",
      "        <a href=\"/blogs/\" title=\"News from around the Python world\" class=\"\">News</a>\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\" role=\"menu\" aria-hidden=\"true\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeitem\"><a href=\"/blogs/\" title=\"Python Insider Blog Posts\">Python News</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-2\" role=\"treeitem\"><a href=\"/psf/newsletter/\" title=\"Python Software Foundation Newsletter\">PSF Newsletter</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"http://planetpython.org/\" title=\"Planet Python\">Community News</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-4\" role=\"treeitem\"><a href=\"http://pyfound.blogspot.com/\" title=\"PSF Blog\">PSF News</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-5\" role=\"treeitem\"><a href=\"http://pycon.blogspot.com/\" title=\"PyCon Blog\">PyCon News</a></li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "        \n",
      "    </li>\n",
      "    \n",
      "    \n",
      "    \n",
      "    <li id=\"events\" class=\"tier-1 element-7  \" aria-haspopup=\"true\">\n",
      "        <a href=\"/events/\" title=\"\" class=\"\">Events</a>\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\" role=\"menu\" aria-hidden=\"true\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeitem\"><a href=\"/events/python-events/\" title=\"\">Python Events</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-2\" role=\"treeitem\"><a href=\"/events/python-user-group/\" title=\"\">User Group Events</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"/events/python-events/past/\" title=\"\">Python Events Archive</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-4\" role=\"treeitem\"><a href=\"/events/python-user-group/past/\" title=\"\">User Group Events Archive</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-5\" role=\"treeitem\"><a href=\"https://wiki.python.org/moin/PythonEventsCalendar#Submitting_an_Event\" title=\"\">Submit an Event</a></li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "        \n",
      "    </li>\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "  \n",
      "</ul>\n",
      "\n",
      "                    \n",
      "                </nav>\n",
      "\n",
      "                <div class=\"header-banner \"> <!-- for optional \"do-not-print\" class -->\n",
      "                    \n",
      "        <div id=\"dive-into-python\" class=\"flex-slideshow slideshow\">\n",
      "\n",
      "            <ul class=\"launch-shell menu\" id=\"launch-shell\">\n",
      "                <li>\n",
      "                    <a class=\"button prompt\" id=\"start-shell\" data-shell-container=\"#dive-into-python\" href=\"/shell/\">&gt;_\n",
      "                        <span class=\"message\">Launch Interactive Shell</span>\n",
      "                    </a>\n",
      "                </li>\n",
      "            </ul>\n",
      "\n",
      "            <ul class=\"slides menu\">\n",
      "                \n",
      "                <li>\n",
      "                    <div class=\"slide-code\"><pre><code><span class=\"comment\"># Python 3: Fibonacci series up to n</span>\r\n",
      ">>> def fib(n):\r\n",
      ">>>     a, b = 0, 1\r\n",
      ">>>     while a &lt; n:\r\n",
      ">>>         print(a, end=' ')\r\n",
      ">>>         a, b = b, a+b\r\n",
      ">>>     print()\r\n",
      ">>> fib(1000)\r\n",
      "<span class=\"output\">0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987</span></code></pre></div>\n",
      "                    <div class=\"slide-copy\"><h1>Functions Defined</h1>\r\n",
      "<p>The core of extensible programming is defining functions. Python allows mandatory and optional arguments, keyword arguments, and even arbitrary argument lists. <a href=\"//docs.python.org/3/tutorial/controlflow.html#defining-functions\">More about defining functions in Python&nbsp;3</a></p></div>\n",
      "                </li>\n",
      "                \n",
      "                <li>\n",
      "                    <div class=\"slide-code\"><pre><code><span class=\"comment\"># Python 3: List comprehensions</span>\r\n",
      ">>> fruits = ['Banana', 'Apple', 'Lime']\r\n",
      ">>> loud_fruits = [fruit.upper() for fruit in fruits]\r\n",
      ">>> print(loud_fruits)\r\n",
      "<span class=\"output\">['BANANA', 'APPLE', 'LIME']</span>\r\n",
      "\r\n",
      "<span class=\"comment\"># List and the enumerate function</span>\r\n",
      ">>> list(enumerate(fruits))\r\n",
      "<span class=\"output\">[(0, 'Banana'), (1, 'Apple'), (2, 'Lime')]</span></code></pre></div>\n",
      "                    <div class=\"slide-copy\"><h1>Compound Data Types</h1>\r\n",
      "<p>Lists (known as arrays in other languages) are one of the compound data types that Python understands. Lists can be indexed, sliced and manipulated with other built-in functions. <a href=\"//docs.python.org/3/tutorial/introduction.html#lists\">More about lists in Python&nbsp;3</a></p></div>\n",
      "                </li>\n",
      "                \n",
      "                <li>\n",
      "                    <div class=\"slide-code\"><pre><code><span class=\"comment\"># Python 3: Simple arithmetic</span>\r\n",
      ">>> 1 / 2\r\n",
      "<span class=\"output\">0.5</span>\r\n",
      ">>> 2 ** 3\r\n",
      "<span class=\"output\">8</span>\r\n",
      ">>> 17 / 3  <span class=\"comment\"># classic division returns a float</span>\r\n",
      "<span class=\"output\">5.666666666666667</span>\r\n",
      ">>> 17 // 3  <span class=\"comment\"># floor division</span>\r\n",
      "<span class=\"output\">5</span></code></pre></div>\n",
      "                    <div class=\"slide-copy\"><h1>Intuitive Interpretation</h1>\r\n",
      "<p>Calculations are simple with Python, and expression syntax is straightforward: the operators <code>+</code>, <code>-</code>, <code>*</code> and <code>/</code> work as expected; parentheses <code>()</code> can be used for grouping. <a href=\"http://docs.python.org/3/tutorial/introduction.html#using-python-as-a-calculator\">More about simple math functions in Python&nbsp;3</a>.</p></div>\n",
      "                </li>\n",
      "                \n",
      "                <li>\n",
      "                    <div class=\"slide-code\"><pre><code><span class=\"comment\"># Python 3: Simple output (with Unicode)</span>\r\n",
      ">>> print(\"Hello, I'm Python!\")\r\n",
      "<span class=\"output\">Hello, I'm Python!</span>\r\n",
      "\r\n",
      "<span class=\"comment\"># Input, assignment</span>\r\n",
      ">>> name = input('What is your name?\\n')\r\n",
      ">>> print('Hi, %s.' % name)\r\n",
      "<span class=\"output\">What is your name?\r\n",
      "Python\r\n",
      "Hi, Python.</span></code></pre></div>\n",
      "                    <div class=\"slide-copy\"><h1>Quick &amp; Easy to Learn</h1>\r\n",
      "<p>Experienced programmers in any other language can pick up Python very quickly, and beginners find the clean syntax and indentation structure easy to learn. <a href=\"//docs.python.org/3/tutorial/\">Whet your appetite</a> with our Python&nbsp;3 overview.</p>\r\n",
      "                   </div>\n",
      "                </li>\n",
      "                \n",
      "                <li>\n",
      "                    <div class=\"slide-code\"><pre><code><span class=\"comment\"># For loop on a list</span>\r\n",
      ">>> numbers = [2, 4, 6, 8]\r\n",
      ">>> product = 1\r\n",
      ">>> for number in numbers:\r\n",
      "...    product = product * number\r\n",
      "... \r\n",
      ">>> print('The product is:', product)\r\n",
      "<span class=\"output\">The product is: 384</span></code></pre></div>\n",
      "                    <div class=\"slide-copy\"><h1>All the Flow You&rsquo;d Expect</h1>\r\n",
      "<p>Python knows the usual control flow statements that other languages speak &mdash; <code>if</code>, <code>for</code>, <code>while</code> and <code>range</code> &mdash; with some of its own twists, of course. <a href=\"//docs.python.org/3/tutorial/controlflow.html\">More control flow tools in Python&nbsp;3</a></p></div>\n",
      "                </li>\n",
      "                \n",
      "            </ul>\n",
      "        </div>\n",
      "\n",
      "\n",
      "                </div>\n",
      "\n",
      "                \n",
      "        <div class=\"introduction\">\n",
      "            <p>Python is a programming language that lets you work quickly <span class=\"breaker\"></span>and integrate systems more effectively. <a class=\"readmore\" href=\"/doc/\">Learn More</a></p>\n",
      "        </div>\n",
      "\n",
      "\n",
      "             </div><!-- end .container -->\n",
      "        </header>\n",
      "\n",
      "        <div id=\"content\" class=\"content-wrapper\">\n",
      "            <!-- Main Content Column -->\n",
      "            <div class=\"container\">\n",
      "\n",
      "                <section class=\"main-content \" role=\"main\">\n",
      "\n",
      "                    \n",
      "                    \n",
      "\n",
      "                    \n",
      "\n",
      "                    \n",
      "\n",
      "                \n",
      "\n",
      "                <div class=\"row\">\n",
      "\n",
      "                    <div class=\"small-widget get-started-widget\">\n",
      "                        <h2 class=\"widget-title\"><span aria-hidden=\"true\" class=\"icon-get-started\"></span>Get Started</h2>\r\n",
      "<p>Whether you're new to programming or an experienced developer, it's easy to learn and use Python.</p>\r\n",
      "<p><a href=\"/about/gettingstarted/\">Start with our Beginner&rsquo;s Guide</a></p>\n",
      "                    </div>\n",
      "\n",
      "                    <div class=\"small-widget download-widget\">\n",
      "                        <h2 class=\"widget-title\"><span aria-hidden=\"true\" class=\"icon-download\"></span>Download</h2>\n",
      "<p>Python source code and installers are available for download for all versions!</p>\n",
      "<p>Latest: <a href=\"/downloads/release/python-3100/\">Python 3.10.0</a></p>\n",
      "                    </div>\n",
      "\n",
      "                    <div class=\"small-widget documentation-widget\">\n",
      "                        <h2 class=\"widget-title\"><span aria-hidden=\"true\" class=\"icon-documentation\"></span>Docs</h2>\r\n",
      "<p>Documentation for Python's standard library, along with tutorials and guides, are available online.</p>\r\n",
      "<p><a href=\"https://docs.python.org\">docs.python.org</a></p>\n",
      "                    </div>\n",
      "\n",
      "                    <div class=\"small-widget jobs-widget last\">\n",
      "                        <h2 class=\"widget-title\"><span aria-hidden=\"true\" class=\"icon-jobs\"></span>Jobs</h2>\r\n",
      "<p>Looking for work or have a Python related position that you're trying to hire for? Our <strong>relaunched community-run job board</strong> is the place to go.</p>\r\n",
      "<p><a href=\"//jobs.python.org\">jobs.python.org</a></p>\n",
      "                    </div>\n",
      "\n",
      "                </div>\n",
      "\n",
      "                <div class=\"list-widgets row\">\n",
      "\n",
      "                    <div class=\"medium-widget blog-widget\">\n",
      "                        \n",
      "                        <div class=\"shrubbery\">\n",
      "                        \n",
      "                            <h2 class=\"widget-title\"><span aria-hidden=\"true\" class=\"icon-news\"></span>Latest News</h2>\n",
      "                            <p class=\"give-me-more\"><a href=\"https://blog.python.org\" title=\"More News\">More</a></p>\n",
      "                            \n",
      "                            <ul class=\"menu\">\n",
      "                                \n",
      "                                \n",
      "                                <li>\n",
      "<time datetime=\"2021-10-07T12:03:00.000003+00:00\"><span class=\"say-no-more\">2021-</span>10-07</time>\n",
      " <a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/rfZ4c8nXGdk/python-3110a1-is-available.html\">Python 3.11.0a1 is available</a></li>\n",
      "                                \n",
      "                                <li>\n",
      "<time datetime=\"2021-10-04T21:07:00+00:00\"><span class=\"say-no-more\">2021-</span>10-04</time>\n",
      " <a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/ojK529j7CAQ/python-3100-is-available.html\">Python 3.10.0 is available</a></li>\n",
      "                                \n",
      "                                <li>\n",
      "<time datetime=\"2021-09-23T08:41:00.000003+00:00\"><span class=\"say-no-more\">2021-</span>09-23</time>\n",
      " <a href=\"http://feedproxy.google.com/~r/PythonSoftwareFoundationNews/~3/qwHz7RZ7wBQ/katia-lira-awarded-psf-community.html\">Katia Lira Awarded the PSF Community Service Award for Q2 2020</a></li>\n",
      "                                \n",
      "                                <li>\n",
      "<time datetime=\"2021-09-17T17:19:00.000004+00:00\"><span class=\"say-no-more\">2021-</span>09-17</time>\n",
      " <a href=\"http://feedproxy.google.com/~r/PythonSoftwareFoundationNews/~3/QQwpt6e2N-w/tereza-iofciu-awarded-psf-community.html\">Tereza Iofciu Awarded the PSF Community Service Award for Q1 2021</a></li>\n",
      "                                \n",
      "                                <li>\n",
      "<time datetime=\"2021-09-07T23:33:00.000001+00:00\"><span class=\"say-no-more\">2021-</span>09-07</time>\n",
      " <a href=\"http://feedproxy.google.com/~r/PythonInsider/~3/MNLSuW5j-cI/python-3100rc2-is-available.html\">Python 3.10.0rc2 is available</a></li>\n",
      "                                \n",
      "                            </ul>\n",
      "                        </div><!-- end .shrubbery -->\n",
      "\n",
      "                    </div>\n",
      "\n",
      "                    <div class=\"medium-widget event-widget last\">\n",
      "                        \n",
      "                        <div class=\"shrubbery\">\n",
      "                        \n",
      "                            <h2 class=\"widget-title\"><span aria-hidden=\"true\" class=\"icon-calendar\"></span>Upcoming Events</h2>\n",
      "                            <p class=\"give-me-more\"><a href=\"/events/calendars/\" title=\"More Events\">More</a></p>\n",
      "                            \n",
      "                            <ul class=\"menu\">\n",
      "                                \n",
      "                                \n",
      "                                \n",
      "                                <li>\n",
      "<time datetime=\"2021-10-21T00:00:00+00:00\"><span class=\"say-no-more\">2021-</span>10-21</time>\n",
      " <a href=\"/events/python-events/1093/\">PyCon Sweden 2021</a></li>\n",
      "                                \n",
      "                                \n",
      "                                \n",
      "                                <li>\n",
      "<time datetime=\"2021-10-23T00:00:00+00:00\"><span class=\"say-no-more\">2021-</span>10-23</time>\n",
      " <a href=\"/events/python-events/1144/\">Plone Conference 2021 Online</a></li>\n",
      "                                \n",
      "                                \n",
      "                                \n",
      "                                <li>\n",
      "<time datetime=\"2021-10-28T00:00:00+00:00\"><span class=\"say-no-more\">2021-</span>10-28</time>\n",
      " <a href=\"/events/python-events/1143/\">PyData Global 2021</a></li>\n",
      "                                \n",
      "                                \n",
      "                                \n",
      "                                <li>\n",
      "<time datetime=\"2021-11-05T00:00:00+00:00\"><span class=\"say-no-more\">2021-</span>11-05</time>\n",
      " <a href=\"/events/python-events/1140/\">PyCon Chile</a></li>\n",
      "                                \n",
      "                                \n",
      "                                \n",
      "                                <li>\n",
      "<time datetime=\"2021-11-13T09:00:00+00:00\"><span class=\"say-no-more\">2021-</span>11-13</time>\n",
      " <a href=\"/events/python-user-group/1148/\">Django Girls Groningen</a></li>\n",
      "                                \n",
      "                                \n",
      "                            </ul>\n",
      "                        </div>\n",
      "\n",
      "                    </div>\n",
      "\n",
      "                </div>\n",
      "\n",
      "                <div class=\"row\">\n",
      "\n",
      "                    <div class=\"medium-widget success-stories-widget\">\n",
      "                        \n",
      "\n",
      "\n",
      "\n",
      "                        <div class=\"shrubbery\">\n",
      "                            \n",
      "\n",
      "                            <h2 class=\"widget-title\"><span aria-hidden=\"true\" class=\"icon-success-stories\"></span>Success Stories</h2>\n",
      "                            <p class=\"give-me-more\"><a href=\"/success-stories/\" title=\"More Success Stories\">More</a></p>\n",
      "\n",
      "                            \n",
      "                            <div class=\"success-story-item\" id=\"success-story-932\">\n",
      "\n",
      "                            <blockquote>\n",
      "                                <a href=\"/success-stories/abridging-clinical-conversations-using-python/\">Python powers major aspects of Abridges ML lifecycle, including data annotation,  research and experimentation, and ML model deployment to production.</a>\n",
      "                            </blockquote>\n",
      "\n",
      "                            <table cellpadding=\"0\" cellspacing=\"0\" border=\"0\" width=\"100%\" class=\"quote-from\">\n",
      "                                <tbody>\n",
      "                                    <tr>\n",
      "                                        \n",
      "                                        <td><p><a href=\"/success-stories/abridging-clinical-conversations-using-python/\">Abridging clinical conversations using Python</a> <em>by Nimshi Venkat and Sandeep Konam</em></p></td>\n",
      "                                    </tr>\n",
      "                                </tbody>\n",
      "                            </table>\n",
      "                            </div>\n",
      "                            \n",
      "\n",
      "                        </div><!-- end .shrubbery -->\n",
      "\n",
      "                    </div>\n",
      "\n",
      "                    <div class=\"medium-widget applications-widget last\">\n",
      "                        <div class=\"shrubbery\">\n",
      "                            <h2 class=\"widget-title\"><span aria-hidden=\"true\" class=\"icon-python\"></span>Use Python for&hellip;</h2>\r\n",
      "<p class=\"give-me-more\"><a href=\"/about/apps\" title=\"More Applications\">More</a></p>\r\n",
      "\r\n",
      "<ul class=\"menu\">\r\n",
      "    <li><b>Web Development</b>:\r\n",
      "        <span class=\"tag-wrapper\"><a class=\"tag\" href=\"http://www.djangoproject.com/\">Django</a>, <a class=\"tag\" href=\"http://www.pylonsproject.org/\">Pyramid</a>, <a class=\"tag\" href=\"http://bottlepy.org\">Bottle</a>, <a class=\"tag\" href=\"http://tornadoweb.org\">Tornado</a>, <a href=\"http://flask.pocoo.org/\" class=\"tag\">Flask</a>, <a class=\"tag\" href=\"http://www.web2py.com/\">web2py</a></span></li>\r\n",
      "    <li><b>GUI Development</b>:\r\n",
      "        <span class=\"tag-wrapper\"><a class=\"tag\" href=\"http://wiki.python.org/moin/TkInter\">tkInter</a>, <a class=\"tag\" href=\"https://wiki.gnome.org/Projects/PyGObject\">PyGObject</a>, <a class=\"tag\" href=\"http://www.riverbankcomputing.co.uk/software/pyqt/intro\">PyQt</a>, <a class=\"tag\" href=\"https://wiki.qt.io/PySide\">PySide</a>, <a class=\"tag\" href=\"https://kivy.org/\">Kivy</a>, <a class=\"tag\" href=\"http://www.wxpython.org/\">wxPython</a></span></li>\r\n",
      "    <li><b>Scientific and Numeric</b>:\r\n",
      "        <span class=\"tag-wrapper\">\r\n",
      "<a class=\"tag\" href=\"http://www.scipy.org\">SciPy</a>, <a class=\"tag\" href=\"http://pandas.pydata.org/\">Pandas</a>, <a href=\"http://ipython.org\" class=\"tag\">IPython</a></span></li>\r\n",
      "    <li><b>Software Development</b>:\r\n",
      "        <span class=\"tag-wrapper\"><a class=\"tag\" href=\"http://buildbot.net/\">Buildbot</a>, <a class=\"tag\" href=\"http://trac.edgewall.org/\">Trac</a>, <a class=\"tag\" href=\"http://roundup.sourceforge.net/\">Roundup</a></span></li>\r\n",
      "    <li><b>System Administration</b>:\r\n",
      "        <span class=\"tag-wrapper\"><a class=\"tag\" href=\"http://www.ansible.com\">Ansible</a>, <a class=\"tag\" href=\"http://www.saltstack.com\">Salt</a>, <a class=\"tag\" href=\"https://www.openstack.org\">OpenStack</a>, <a class=\"tag\" href=\"https://xon.sh\">xonsh</a></span></li>\r\n",
      "</ul>\n",
      "                        </div><!-- end .shrubbery -->\n",
      "                    </div>\n",
      "\n",
      "                </div>\n",
      "\n",
      "                \n",
      "                <div class=\"pep-widget\">\n",
      "\n",
      "                    <h2 class=\"widget-title\">\n",
      "                        <span class=\"prompt\">&gt;&gt;&gt;</span> <a href=\"/dev/peps/\">Python Enhancement Proposals<span class=\"say-no-more\"> (PEPs)</span></a>: The future of Python<span class=\"say-no-more\"> is discussed here.</span>\n",
      "                        <a aria-hidden=\"true\" class=\"rss-link\" href=\"/dev/peps/peps.rss\"><span class=\"icon-feed\"></span> RSS</a>\n",
      "                    </h2>\n",
      "\n",
      "\n",
      "                    \n",
      "                    \n",
      "                </div>\n",
      "\n",
      "                                <div class=\"psf-widget\">\n",
      "\n",
      "                    <div class=\"python-logo\"></div>\n",
      "                    \n",
      "                    <h2 class=\"widget-title\">\r\n",
      "    <span class=\"prompt\">&gt;&gt;&gt;</span> <a href=\"/psf/\">Python Software Foundation</a>\r\n",
      "</h2>\r\n",
      "<p>The mission of the Python Software Foundation is to promote, protect, and advance the Python programming language, and to support and facilitate the growth of a diverse and international community of Python programmers. <a class=\"readmore\" href=\"/psf/\">Learn more</a> </p>\r\n",
      "<p class=\"click-these\">\r\n",
      "    <a class=\"button\" href=\"/users/membership/\">Become a Member</a>\r\n",
      "    <a class=\"button\" href=\"/psf/donations/\">Donate to the PSF</a>\r\n",
      "</p>\n",
      "                </div>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                </section>\n",
      "\n",
      "                \n",
      "                \n",
      "\n",
      "                \n",
      "                \n",
      "\n",
      "\n",
      "            </div><!-- end .container -->\n",
      "        </div><!-- end #content .content-wrapper -->\n",
      "\n",
      "        <!-- Footer and social media list -->\n",
      "        \n",
      "        <footer id=\"site-map\" class=\"main-footer\" role=\"contentinfo\">\n",
      "            <div class=\"main-footer-links\">\n",
      "                <div class=\"container\">\n",
      "\n",
      "                    \n",
      "                    <a id=\"back-to-top-1\" class=\"jump-link\" href=\"#python-network\"><span aria-hidden=\"true\" class=\"icon-arrow-up\"><span>&#9650;</span></span> Back to Top</a>\n",
      "\n",
      "                    \n",
      "\n",
      "<ul class=\"sitemap navigation menu do-not-print\" role=\"tree\" id=\"container\">\n",
      "    \n",
      "    <li class=\"tier-1 element-1\">\n",
      "        <a href=\"/about/\" >About</a>\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeitem\"><a href=\"/about/apps/\" title=\"\">Applications</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-2\" role=\"treeitem\"><a href=\"/about/quotes/\" title=\"\">Quotes</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"/about/gettingstarted/\" title=\"\">Getting Started</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-4\" role=\"treeitem\"><a href=\"/about/help/\" title=\"\">Help</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-5\" role=\"treeitem\"><a href=\"http://brochure.getpython.info/\" title=\"\">Python Brochure</a></li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "        \n",
      "    </li>\n",
      "    \n",
      "    <li class=\"tier-1 element-2\">\n",
      "        <a href=\"/downloads/\" >Downloads</a>\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeitem\"><a href=\"/downloads/\" title=\"\">All releases</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-2\" role=\"treeitem\"><a href=\"/downloads/source/\" title=\"\">Source code</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"/downloads/windows/\" title=\"\">Windows</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-4\" role=\"treeitem\"><a href=\"/downloads/macos/\" title=\"\">macOS</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-5\" role=\"treeitem\"><a href=\"/download/other/\" title=\"\">Other Platforms</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-6\" role=\"treeitem\"><a href=\"https://docs.python.org/3/license.html\" title=\"\">License</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-7\" role=\"treeitem\"><a href=\"/download/alternatives\" title=\"\">Alternative Implementations</a></li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "        \n",
      "    </li>\n",
      "    \n",
      "    <li class=\"tier-1 element-3\">\n",
      "        <a href=\"/doc/\" >Documentation</a>\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeitem\"><a href=\"/doc/\" title=\"\">Docs</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-2\" role=\"treeitem\"><a href=\"/doc/av\" title=\"\">Audio/Visual Talks</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"https://wiki.python.org/moin/BeginnersGuide\" title=\"\">Beginner&#39;s Guide</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-4\" role=\"treeitem\"><a href=\"https://devguide.python.org/\" title=\"\">Developer&#39;s Guide</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-5\" role=\"treeitem\"><a href=\"https://docs.python.org/faq/\" title=\"\">FAQ</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-6\" role=\"treeitem\"><a href=\"http://wiki.python.org/moin/Languages\" title=\"\">Non-English Docs</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-7\" role=\"treeitem\"><a href=\"http://python.org/dev/peps/\" title=\"\">PEP Index</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-8\" role=\"treeitem\"><a href=\"https://wiki.python.org/moin/PythonBooks\" title=\"\">Python Books</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-9\" role=\"treeitem\"><a href=\"/doc/essays/\" title=\"\">Python Essays</a></li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "        \n",
      "    </li>\n",
      "    \n",
      "    <li class=\"tier-1 element-4\">\n",
      "        <a href=\"/community/\" >Community</a>\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeitem\"><a href=\"/community/survey\" title=\"\">Community Survey</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-2\" role=\"treeitem\"><a href=\"/community/diversity/\" title=\"\">Diversity</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"/community/lists/\" title=\"\">Mailing Lists</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-4\" role=\"treeitem\"><a href=\"/community/irc/\" title=\"\">IRC</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-5\" role=\"treeitem\"><a href=\"/community/forums/\" title=\"\">Forums</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-6\" role=\"treeitem\"><a href=\"/psf/annual-report/2021/\" title=\"\">PSF Annual Impact Report</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-7\" role=\"treeitem\"><a href=\"/community/workshops/\" title=\"\">Python Conferences</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-8\" role=\"treeitem\"><a href=\"/community/sigs/\" title=\"\">Special Interest Groups</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-9\" role=\"treeitem\"><a href=\"/community/logos/\" title=\"\">Python Logo</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-10\" role=\"treeitem\"><a href=\"https://wiki.python.org/moin/\" title=\"\">Python Wiki</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-11\" role=\"treeitem\"><a href=\"/community/merchandise/\" title=\"\">Merchandise</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-12\" role=\"treeitem\"><a href=\"/community/awards\" title=\"\">Community Awards</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-13\" role=\"treeitem\"><a href=\"/psf/conduct/\" title=\"\">Code of Conduct</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-14\" role=\"treeitem\"><a href=\"/psf/get-involved/\" title=\"\">Get Involved</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-15\" role=\"treeitem\"><a href=\"/psf/community-stories/\" title=\"\">Shared Stories</a></li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "        \n",
      "    </li>\n",
      "    \n",
      "    <li class=\"tier-1 element-5\">\n",
      "        <a href=\"/success-stories/\" title=\"success-stories\">Success Stories</a>\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeitem\"><a href=\"/success-stories/category/arts/\" title=\"\">Arts</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-2\" role=\"treeitem\"><a href=\"/success-stories/category/business/\" title=\"\">Business</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"/success-stories/category/education/\" title=\"\">Education</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-4\" role=\"treeitem\"><a href=\"/success-stories/category/engineering/\" title=\"\">Engineering</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-5\" role=\"treeitem\"><a href=\"/success-stories/category/government/\" title=\"\">Government</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-6\" role=\"treeitem\"><a href=\"/success-stories/category/scientific/\" title=\"\">Scientific</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-7\" role=\"treeitem\"><a href=\"/success-stories/category/software-development/\" title=\"\">Software Development</a></li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "        \n",
      "    </li>\n",
      "    \n",
      "    <li class=\"tier-1 element-6\">\n",
      "        <a href=\"/blogs/\" title=\"News from around the Python world\">News</a>\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeitem\"><a href=\"/blogs/\" title=\"Python Insider Blog Posts\">Python News</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-2\" role=\"treeitem\"><a href=\"/psf/newsletter/\" title=\"Python Software Foundation Newsletter\">PSF Newsletter</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"http://planetpython.org/\" title=\"Planet Python\">Community News</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-4\" role=\"treeitem\"><a href=\"http://pyfound.blogspot.com/\" title=\"PSF Blog\">PSF News</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-5\" role=\"treeitem\"><a href=\"http://pycon.blogspot.com/\" title=\"PyCon Blog\">PyCon News</a></li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "        \n",
      "    </li>\n",
      "    \n",
      "    <li class=\"tier-1 element-7\">\n",
      "        <a href=\"/events/\" >Events</a>\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeitem\"><a href=\"/events/python-events/\" title=\"\">Python Events</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-2\" role=\"treeitem\"><a href=\"/events/python-user-group/\" title=\"\">User Group Events</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"/events/python-events/past/\" title=\"\">Python Events Archive</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-4\" role=\"treeitem\"><a href=\"/events/python-user-group/past/\" title=\"\">User Group Events Archive</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-5\" role=\"treeitem\"><a href=\"https://wiki.python.org/moin/PythonEventsCalendar#Submitting_an_Event\" title=\"\">Submit an Event</a></li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "        \n",
      "    </li>\n",
      "    \n",
      "    <li class=\"tier-1 element-8\">\n",
      "        <a href=\"/dev/\" >Contributing</a>\n",
      "        \n",
      "            \n",
      "\n",
      "<ul class=\"subnav menu\">\n",
      "    \n",
      "        <li class=\"tier-2 element-1\" role=\"treeitem\"><a href=\"https://devguide.python.org/\" title=\"\">Developer&#39;s Guide</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-2\" role=\"treeitem\"><a href=\"https://bugs.python.org/\" title=\"\">Issue Tracker</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-3\" role=\"treeitem\"><a href=\"https://mail.python.org/mailman/listinfo/python-dev\" title=\"\">python-dev list</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-4\" role=\"treeitem\"><a href=\"/dev/core-mentorship/\" title=\"\">Core Mentorship</a></li>\n",
      "    \n",
      "        <li class=\"tier-2 element-5\" role=\"treeitem\"><a href=\"/dev/security/\" title=\"\">Report a Security Issue</a></li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "        \n",
      "    </li>\n",
      "    \n",
      "</ul>\n",
      "\n",
      "\n",
      "                    <a id=\"back-to-top-2\" class=\"jump-link\" href=\"#python-network\"><span aria-hidden=\"true\" class=\"icon-arrow-up\"><span>&#9650;</span></span> Back to Top</a>\n",
      "                    \n",
      "\n",
      "                </div><!-- end .container -->\n",
      "            </div> <!-- end .main-footer-links -->\n",
      "\n",
      "            <div class=\"site-base\">\n",
      "                <div class=\"container\">\n",
      "                    \n",
      "                    <ul class=\"footer-links navigation menu do-not-print\" role=\"tree\">\n",
      "                        <li class=\"tier-1 element-1\"><a href=\"/about/help/\">Help &amp; <span class=\"say-no-more\">General</span> Contact</a></li>\n",
      "                        <li class=\"tier-1 element-2\"><a href=\"/community/diversity/\">Diversity <span class=\"say-no-more\">Initiatives</span></a></li>\n",
      "                        <li class=\"tier-1 element-3\"><a href=\"https://github.com/python/pythondotorg/issues\">Submit Website Bug</a></li>\n",
      "                        <li class=\"tier-1 element-4\">\n",
      "                            <a href=\"https://status.python.org/\">Status <span class=\"python-status-indicator-default\" id=\"python-status-indicator\"></span></a>\n",
      "                        </li>\n",
      "                    </ul>\n",
      "\n",
      "                    <div class=\"copyright\">\n",
      "                        <p><small>\n",
      "                            <span class=\"pre\">Copyright &copy;2001-2021.</span>\n",
      "                            &nbsp;<span class=\"pre\"><a href=\"/psf-landing/\">Python Software Foundation</a></span>\n",
      "                            &nbsp;<span class=\"pre\"><a href=\"/about/legal/\">Legal Statements</a></span>\n",
      "                            &nbsp;<span class=\"pre\"><a href=\"/privacy/\">Privacy Policy</a></span>\n",
      "                            &nbsp;<span class=\"pre\"><a href=\"/psf/sponsorship/sponsors/#heroku\">Powered by Heroku</a></span>\n",
      "                        </small></p>\n",
      "                    </div>\n",
      "\n",
      "                </div><!-- end .container -->\n",
      "            </div><!-- end .site-base -->\n",
      "\n",
      "        </footer>\n",
      "        \n",
      "\n",
      "    </div><!-- end #touchnav-wrapper -->\n",
      "\n",
      "    \n",
      "    <script src=\"//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js\"></script>\n",
      "    <script>window.jQuery || document.write('<script src=\"/static/js/libs/jquery-1.8.2.min.js\"><\\/script>')</script>\n",
      "    <script src=\"//ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js\"></script>\n",
      "    <script>window.jQuery || document.write('<script src=\"/static/js/libs/jquery-ui-1.12.1.min.js\"><\\/script>')</script>\n",
      "\n",
      "    <script src=\"/static/js/libs/masonry.pkgd.min.js\"></script>\n",
      "    <script src=\"/static/js/libs/html-includes.js\"></script>\n",
      "\n",
      "    <script type=\"text/javascript\" src=\"/static/js/main-min.dd72c1659644.js\" charset=\"utf-8\"></script>\n",
      "    \n",
      "\n",
      "    <!--[if lte IE 7]>\n",
      "    <script type=\"text/javascript\" src=\"/static/js/plugins/IE8-min.8af6e26c7a3b.js\" charset=\"utf-8\"></script>\n",
      "    \n",
      "    \n",
      "    <![endif]-->\n",
      "\n",
      "    <!--[if lte IE 8]>\n",
      "    <script type=\"text/javascript\" src=\"/static/js/plugins/getComputedStyle-min.d41d8cd98f00.js\" charset=\"utf-8\"></script>\n",
      "    \n",
      "    \n",
      "    <![endif]-->\n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "response = urllib.request.urlopen('https://www.python.org')\n",
    "print(response.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6839e4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_loader_cifar10 = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=4,pin_memory=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "test_loader_cifar10 = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=4,pin_memory=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b70c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = []\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2ce9ca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruokai\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:693: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch._C._nn.max_pool2d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "C:\\Users\\Ruokai\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.4026, Accuracy: 1103/10000 (11%)\n",
      "\n",
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.512688\n",
      "Train Epoch: 0 [320/50000 (1%)]\tLoss: 2.506984\n",
      "Train Epoch: 0 [640/50000 (1%)]\tLoss: 2.330268\n",
      "Train Epoch: 0 [960/50000 (2%)]\tLoss: 2.355562\n",
      "Train Epoch: 0 [1280/50000 (3%)]\tLoss: 2.219333\n",
      "Train Epoch: 0 [1600/50000 (3%)]\tLoss: 2.286567\n",
      "Train Epoch: 0 [1920/50000 (4%)]\tLoss: 2.224273\n",
      "Train Epoch: 0 [2240/50000 (4%)]\tLoss: 2.263476\n",
      "Train Epoch: 0 [2560/50000 (5%)]\tLoss: 2.251234\n",
      "Train Epoch: 0 [2880/50000 (6%)]\tLoss: 2.239772\n",
      "Train Epoch: 0 [3200/50000 (6%)]\tLoss: 2.343350\n",
      "Train Epoch: 0 [3520/50000 (7%)]\tLoss: 2.286649\n",
      "Train Epoch: 0 [3840/50000 (8%)]\tLoss: 2.286069\n",
      "Train Epoch: 0 [4160/50000 (8%)]\tLoss: 2.237209\n",
      "Train Epoch: 0 [4480/50000 (9%)]\tLoss: 2.208657\n",
      "Train Epoch: 0 [4800/50000 (10%)]\tLoss: 2.220046\n",
      "Train Epoch: 0 [5120/50000 (10%)]\tLoss: 2.363691\n",
      "Train Epoch: 0 [5440/50000 (11%)]\tLoss: 2.225754\n",
      "Train Epoch: 0 [5760/50000 (12%)]\tLoss: 2.212921\n",
      "Train Epoch: 0 [6080/50000 (12%)]\tLoss: 2.225331\n",
      "Train Epoch: 0 [6400/50000 (13%)]\tLoss: 2.242662\n",
      "Train Epoch: 0 [6720/50000 (13%)]\tLoss: 2.127224\n",
      "Train Epoch: 0 [7040/50000 (14%)]\tLoss: 2.194152\n",
      "Train Epoch: 0 [7360/50000 (15%)]\tLoss: 2.238768\n",
      "Train Epoch: 0 [7680/50000 (15%)]\tLoss: 2.228297\n",
      "Train Epoch: 0 [8000/50000 (16%)]\tLoss: 2.056313\n",
      "Train Epoch: 0 [8320/50000 (17%)]\tLoss: 2.212684\n",
      "Train Epoch: 0 [8640/50000 (17%)]\tLoss: 2.100085\n",
      "Train Epoch: 0 [8960/50000 (18%)]\tLoss: 2.104410\n",
      "Train Epoch: 0 [9280/50000 (19%)]\tLoss: 2.130744\n",
      "Train Epoch: 0 [9600/50000 (19%)]\tLoss: 2.091976\n",
      "Train Epoch: 0 [9920/50000 (20%)]\tLoss: 2.226590\n",
      "Train Epoch: 0 [10240/50000 (20%)]\tLoss: 2.181804\n",
      "Train Epoch: 0 [10560/50000 (21%)]\tLoss: 2.356048\n",
      "Train Epoch: 0 [10880/50000 (22%)]\tLoss: 2.306079\n",
      "Train Epoch: 0 [11200/50000 (22%)]\tLoss: 2.163830\n",
      "Train Epoch: 0 [11520/50000 (23%)]\tLoss: 2.097364\n",
      "Train Epoch: 0 [11840/50000 (24%)]\tLoss: 2.136143\n",
      "Train Epoch: 0 [12160/50000 (24%)]\tLoss: 2.212703\n",
      "Train Epoch: 0 [12480/50000 (25%)]\tLoss: 2.157557\n",
      "Train Epoch: 0 [12800/50000 (26%)]\tLoss: 2.150935\n",
      "Train Epoch: 0 [13120/50000 (26%)]\tLoss: 2.110233\n",
      "Train Epoch: 0 [13440/50000 (27%)]\tLoss: 2.061278\n",
      "Train Epoch: 0 [13760/50000 (28%)]\tLoss: 2.103951\n",
      "Train Epoch: 0 [14080/50000 (28%)]\tLoss: 2.129510\n",
      "Train Epoch: 0 [14400/50000 (29%)]\tLoss: 2.130846\n",
      "Train Epoch: 0 [14720/50000 (29%)]\tLoss: 2.092546\n",
      "Train Epoch: 0 [15040/50000 (30%)]\tLoss: 2.314629\n",
      "Train Epoch: 0 [15360/50000 (31%)]\tLoss: 2.050055\n",
      "Train Epoch: 0 [15680/50000 (31%)]\tLoss: 2.021305\n",
      "Train Epoch: 0 [16000/50000 (32%)]\tLoss: 2.032925\n",
      "Train Epoch: 0 [16320/50000 (33%)]\tLoss: 2.275731\n",
      "Train Epoch: 0 [16640/50000 (33%)]\tLoss: 2.142421\n",
      "Train Epoch: 0 [16960/50000 (34%)]\tLoss: 2.130529\n",
      "Train Epoch: 0 [17280/50000 (35%)]\tLoss: 2.192534\n",
      "Train Epoch: 0 [17600/50000 (35%)]\tLoss: 2.224905\n",
      "Train Epoch: 0 [17920/50000 (36%)]\tLoss: 2.205355\n",
      "Train Epoch: 0 [18240/50000 (36%)]\tLoss: 2.187427\n",
      "Train Epoch: 0 [18560/50000 (37%)]\tLoss: 2.183757\n",
      "Train Epoch: 0 [18880/50000 (38%)]\tLoss: 2.062224\n",
      "Train Epoch: 0 [19200/50000 (38%)]\tLoss: 2.067707\n",
      "Train Epoch: 0 [19520/50000 (39%)]\tLoss: 2.055574\n",
      "Train Epoch: 0 [19840/50000 (40%)]\tLoss: 2.216417\n",
      "Train Epoch: 0 [20160/50000 (40%)]\tLoss: 2.103344\n",
      "Train Epoch: 0 [20480/50000 (41%)]\tLoss: 2.095711\n",
      "Train Epoch: 0 [20800/50000 (42%)]\tLoss: 2.137197\n",
      "Train Epoch: 0 [21120/50000 (42%)]\tLoss: 2.077576\n",
      "Train Epoch: 0 [21440/50000 (43%)]\tLoss: 1.981591\n",
      "Train Epoch: 0 [21760/50000 (44%)]\tLoss: 2.148230\n",
      "Train Epoch: 0 [22080/50000 (44%)]\tLoss: 2.085801\n",
      "Train Epoch: 0 [22400/50000 (45%)]\tLoss: 2.051905\n",
      "Train Epoch: 0 [22720/50000 (45%)]\tLoss: 1.951559\n",
      "Train Epoch: 0 [23040/50000 (46%)]\tLoss: 2.032731\n",
      "Train Epoch: 0 [23360/50000 (47%)]\tLoss: 2.191550\n",
      "Train Epoch: 0 [23680/50000 (47%)]\tLoss: 2.118817\n",
      "Train Epoch: 0 [24000/50000 (48%)]\tLoss: 2.066192\n",
      "Train Epoch: 0 [24320/50000 (49%)]\tLoss: 2.022121\n",
      "Train Epoch: 0 [24640/50000 (49%)]\tLoss: 2.025938\n",
      "Train Epoch: 0 [24960/50000 (50%)]\tLoss: 2.117374\n",
      "Train Epoch: 0 [25280/50000 (51%)]\tLoss: 2.054322\n",
      "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 2.130140\n",
      "Train Epoch: 0 [25920/50000 (52%)]\tLoss: 2.107299\n",
      "Train Epoch: 0 [26240/50000 (52%)]\tLoss: 2.118436\n",
      "Train Epoch: 0 [26560/50000 (53%)]\tLoss: 2.085493\n",
      "Train Epoch: 0 [26880/50000 (54%)]\tLoss: 1.933557\n",
      "Train Epoch: 0 [27200/50000 (54%)]\tLoss: 2.249107\n",
      "Train Epoch: 0 [27520/50000 (55%)]\tLoss: 1.957746\n",
      "Train Epoch: 0 [27840/50000 (56%)]\tLoss: 2.020863\n",
      "Train Epoch: 0 [28160/50000 (56%)]\tLoss: 2.018794\n",
      "Train Epoch: 0 [28480/50000 (57%)]\tLoss: 2.005691\n",
      "Train Epoch: 0 [28800/50000 (58%)]\tLoss: 2.263753\n",
      "Train Epoch: 0 [29120/50000 (58%)]\tLoss: 2.152166\n",
      "Train Epoch: 0 [29440/50000 (59%)]\tLoss: 1.979005\n",
      "Train Epoch: 0 [29760/50000 (60%)]\tLoss: 1.921168\n",
      "Train Epoch: 0 [30080/50000 (60%)]\tLoss: 2.079245\n",
      "Train Epoch: 0 [30400/50000 (61%)]\tLoss: 2.020095\n",
      "Train Epoch: 0 [30720/50000 (61%)]\tLoss: 2.067051\n",
      "Train Epoch: 0 [31040/50000 (62%)]\tLoss: 1.805586\n",
      "Train Epoch: 0 [31360/50000 (63%)]\tLoss: 1.921074\n",
      "Train Epoch: 0 [31680/50000 (63%)]\tLoss: 2.154759\n",
      "Train Epoch: 0 [32000/50000 (64%)]\tLoss: 1.982311\n",
      "Train Epoch: 0 [32320/50000 (65%)]\tLoss: 1.962374\n",
      "Train Epoch: 0 [32640/50000 (65%)]\tLoss: 2.141121\n",
      "Train Epoch: 0 [32960/50000 (66%)]\tLoss: 2.128622\n",
      "Train Epoch: 0 [33280/50000 (67%)]\tLoss: 2.150833\n",
      "Train Epoch: 0 [33600/50000 (67%)]\tLoss: 1.982811\n",
      "Train Epoch: 0 [33920/50000 (68%)]\tLoss: 1.849982\n",
      "Train Epoch: 0 [34240/50000 (68%)]\tLoss: 2.103044\n",
      "Train Epoch: 0 [34560/50000 (69%)]\tLoss: 1.856376\n",
      "Train Epoch: 0 [34880/50000 (70%)]\tLoss: 2.036330\n",
      "Train Epoch: 0 [35200/50000 (70%)]\tLoss: 2.003294\n",
      "Train Epoch: 0 [35520/50000 (71%)]\tLoss: 1.923638\n",
      "Train Epoch: 0 [35840/50000 (72%)]\tLoss: 2.076530\n",
      "Train Epoch: 0 [36160/50000 (72%)]\tLoss: 2.086102\n",
      "Train Epoch: 0 [36480/50000 (73%)]\tLoss: 2.072113\n",
      "Train Epoch: 0 [36800/50000 (74%)]\tLoss: 1.999116\n",
      "Train Epoch: 0 [37120/50000 (74%)]\tLoss: 2.016706\n",
      "Train Epoch: 0 [37440/50000 (75%)]\tLoss: 1.707016\n",
      "Train Epoch: 0 [37760/50000 (75%)]\tLoss: 1.936104\n",
      "Train Epoch: 0 [38080/50000 (76%)]\tLoss: 1.995844\n",
      "Train Epoch: 0 [38400/50000 (77%)]\tLoss: 2.175133\n",
      "Train Epoch: 0 [38720/50000 (77%)]\tLoss: 2.166981\n",
      "Train Epoch: 0 [39040/50000 (78%)]\tLoss: 1.960192\n",
      "Train Epoch: 0 [39360/50000 (79%)]\tLoss: 1.915613\n",
      "Train Epoch: 0 [39680/50000 (79%)]\tLoss: 2.101733\n",
      "Train Epoch: 0 [40000/50000 (80%)]\tLoss: 1.957345\n",
      "Train Epoch: 0 [40320/50000 (81%)]\tLoss: 2.125466\n",
      "Train Epoch: 0 [40640/50000 (81%)]\tLoss: 1.927485\n",
      "Train Epoch: 0 [40960/50000 (82%)]\tLoss: 1.997268\n",
      "Train Epoch: 0 [41280/50000 (83%)]\tLoss: 1.886550\n",
      "Train Epoch: 0 [41600/50000 (83%)]\tLoss: 1.969873\n",
      "Train Epoch: 0 [41920/50000 (84%)]\tLoss: 1.653226\n",
      "Train Epoch: 0 [42240/50000 (84%)]\tLoss: 2.134737\n",
      "Train Epoch: 0 [42560/50000 (85%)]\tLoss: 1.999250\n",
      "Train Epoch: 0 [42880/50000 (86%)]\tLoss: 2.174494\n",
      "Train Epoch: 0 [43200/50000 (86%)]\tLoss: 2.103406\n",
      "Train Epoch: 0 [43520/50000 (87%)]\tLoss: 2.133974\n",
      "Train Epoch: 0 [43840/50000 (88%)]\tLoss: 1.844092\n",
      "Train Epoch: 0 [44160/50000 (88%)]\tLoss: 2.082429\n",
      "Train Epoch: 0 [44480/50000 (89%)]\tLoss: 1.884410\n",
      "Train Epoch: 0 [44800/50000 (90%)]\tLoss: 1.977730\n",
      "Train Epoch: 0 [45120/50000 (90%)]\tLoss: 1.936969\n",
      "Train Epoch: 0 [45440/50000 (91%)]\tLoss: 1.987386\n",
      "Train Epoch: 0 [45760/50000 (91%)]\tLoss: 2.125857\n",
      "Train Epoch: 0 [46080/50000 (92%)]\tLoss: 1.900166\n",
      "Train Epoch: 0 [46400/50000 (93%)]\tLoss: 2.107429\n",
      "Train Epoch: 0 [46720/50000 (93%)]\tLoss: 2.154615\n",
      "Train Epoch: 0 [47040/50000 (94%)]\tLoss: 2.009606\n",
      "Train Epoch: 0 [47360/50000 (95%)]\tLoss: 2.130094\n",
      "Train Epoch: 0 [47680/50000 (95%)]\tLoss: 1.895061\n",
      "Train Epoch: 0 [48000/50000 (96%)]\tLoss: 1.786319\n",
      "Train Epoch: 0 [48320/50000 (97%)]\tLoss: 2.106567\n",
      "Train Epoch: 0 [48640/50000 (97%)]\tLoss: 2.012729\n",
      "Train Epoch: 0 [48960/50000 (98%)]\tLoss: 1.874864\n",
      "Train Epoch: 0 [49280/50000 (99%)]\tLoss: 1.993787\n",
      "Train Epoch: 0 [49600/50000 (99%)]\tLoss: 2.099530\n",
      "Train Epoch: 0 [49920/50000 (100%)]\tLoss: 2.034564\n",
      "\n",
      "Test set: Avg. loss: 1.9650, Accuracy: 3100/10000 (31%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.000941\n",
      "Train Epoch: 1 [320/50000 (1%)]\tLoss: 2.003158\n",
      "Train Epoch: 1 [640/50000 (1%)]\tLoss: 1.816201\n",
      "Train Epoch: 1 [960/50000 (2%)]\tLoss: 1.964750\n",
      "Train Epoch: 1 [1280/50000 (3%)]\tLoss: 2.190925\n",
      "Train Epoch: 1 [1600/50000 (3%)]\tLoss: 1.908528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1920/50000 (4%)]\tLoss: 1.926830\n",
      "Train Epoch: 1 [2240/50000 (4%)]\tLoss: 1.946218\n",
      "Train Epoch: 1 [2560/50000 (5%)]\tLoss: 2.088883\n",
      "Train Epoch: 1 [2880/50000 (6%)]\tLoss: 1.863091\n",
      "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 1.969249\n",
      "Train Epoch: 1 [3520/50000 (7%)]\tLoss: 2.156210\n",
      "Train Epoch: 1 [3840/50000 (8%)]\tLoss: 1.845936\n",
      "Train Epoch: 1 [4160/50000 (8%)]\tLoss: 1.947160\n",
      "Train Epoch: 1 [4480/50000 (9%)]\tLoss: 1.936581\n",
      "Train Epoch: 1 [4800/50000 (10%)]\tLoss: 1.805771\n",
      "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 2.272000\n",
      "Train Epoch: 1 [5440/50000 (11%)]\tLoss: 1.967933\n",
      "Train Epoch: 1 [5760/50000 (12%)]\tLoss: 1.975758\n",
      "Train Epoch: 1 [6080/50000 (12%)]\tLoss: 1.979412\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.790987\n",
      "Train Epoch: 1 [6720/50000 (13%)]\tLoss: 2.087777\n",
      "Train Epoch: 1 [7040/50000 (14%)]\tLoss: 2.094913\n",
      "Train Epoch: 1 [7360/50000 (15%)]\tLoss: 1.924516\n",
      "Train Epoch: 1 [7680/50000 (15%)]\tLoss: 1.794707\n",
      "Train Epoch: 1 [8000/50000 (16%)]\tLoss: 2.008805\n",
      "Train Epoch: 1 [8320/50000 (17%)]\tLoss: 2.015486\n",
      "Train Epoch: 1 [8640/50000 (17%)]\tLoss: 2.077794\n",
      "Train Epoch: 1 [8960/50000 (18%)]\tLoss: 1.815762\n",
      "Train Epoch: 1 [9280/50000 (19%)]\tLoss: 1.897647\n",
      "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 1.875992\n",
      "Train Epoch: 1 [9920/50000 (20%)]\tLoss: 1.964518\n",
      "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 1.965025\n",
      "Train Epoch: 1 [10560/50000 (21%)]\tLoss: 1.888231\n",
      "Train Epoch: 1 [10880/50000 (22%)]\tLoss: 2.137092\n",
      "Train Epoch: 1 [11200/50000 (22%)]\tLoss: 1.886367\n",
      "Train Epoch: 1 [11520/50000 (23%)]\tLoss: 1.979903\n",
      "Train Epoch: 1 [11840/50000 (24%)]\tLoss: 1.940954\n",
      "Train Epoch: 1 [12160/50000 (24%)]\tLoss: 1.850366\n",
      "Train Epoch: 1 [12480/50000 (25%)]\tLoss: 1.885820\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.925617\n",
      "Train Epoch: 1 [13120/50000 (26%)]\tLoss: 2.285420\n",
      "Train Epoch: 1 [13440/50000 (27%)]\tLoss: 2.031969\n",
      "Train Epoch: 1 [13760/50000 (28%)]\tLoss: 1.949420\n",
      "Train Epoch: 1 [14080/50000 (28%)]\tLoss: 2.091567\n",
      "Train Epoch: 1 [14400/50000 (29%)]\tLoss: 1.902345\n",
      "Train Epoch: 1 [14720/50000 (29%)]\tLoss: 1.858501\n",
      "Train Epoch: 1 [15040/50000 (30%)]\tLoss: 1.881748\n",
      "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 1.790263\n",
      "Train Epoch: 1 [15680/50000 (31%)]\tLoss: 1.902039\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 2.117679\n",
      "Train Epoch: 1 [16320/50000 (33%)]\tLoss: 2.019811\n",
      "Train Epoch: 1 [16640/50000 (33%)]\tLoss: 1.939715\n",
      "Train Epoch: 1 [16960/50000 (34%)]\tLoss: 1.870248\n",
      "Train Epoch: 1 [17280/50000 (35%)]\tLoss: 1.907037\n",
      "Train Epoch: 1 [17600/50000 (35%)]\tLoss: 1.692946\n",
      "Train Epoch: 1 [17920/50000 (36%)]\tLoss: 1.972265\n",
      "Train Epoch: 1 [18240/50000 (36%)]\tLoss: 1.958987\n",
      "Train Epoch: 1 [18560/50000 (37%)]\tLoss: 1.961143\n",
      "Train Epoch: 1 [18880/50000 (38%)]\tLoss: 1.863040\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.955105\n",
      "Train Epoch: 1 [19520/50000 (39%)]\tLoss: 1.893115\n",
      "Train Epoch: 1 [19840/50000 (40%)]\tLoss: 2.000015\n",
      "Train Epoch: 1 [20160/50000 (40%)]\tLoss: 1.842430\n",
      "Train Epoch: 1 [20480/50000 (41%)]\tLoss: 1.890880\n",
      "Train Epoch: 1 [20800/50000 (42%)]\tLoss: 1.984643\n",
      "Train Epoch: 1 [21120/50000 (42%)]\tLoss: 1.980509\n",
      "Train Epoch: 1 [21440/50000 (43%)]\tLoss: 2.056121\n",
      "Train Epoch: 1 [21760/50000 (44%)]\tLoss: 1.815201\n",
      "Train Epoch: 1 [22080/50000 (44%)]\tLoss: 2.079299\n",
      "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 1.952876\n",
      "Train Epoch: 1 [22720/50000 (45%)]\tLoss: 1.769892\n",
      "Train Epoch: 1 [23040/50000 (46%)]\tLoss: 1.967814\n",
      "Train Epoch: 1 [23360/50000 (47%)]\tLoss: 1.954471\n",
      "Train Epoch: 1 [23680/50000 (47%)]\tLoss: 1.818502\n",
      "Train Epoch: 1 [24000/50000 (48%)]\tLoss: 1.980393\n",
      "Train Epoch: 1 [24320/50000 (49%)]\tLoss: 1.858810\n",
      "Train Epoch: 1 [24640/50000 (49%)]\tLoss: 2.066058\n",
      "Train Epoch: 1 [24960/50000 (50%)]\tLoss: 2.016458\n",
      "Train Epoch: 1 [25280/50000 (51%)]\tLoss: 1.997612\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.877463\n",
      "Train Epoch: 1 [25920/50000 (52%)]\tLoss: 2.138597\n",
      "Train Epoch: 1 [26240/50000 (52%)]\tLoss: 1.949712\n",
      "Train Epoch: 1 [26560/50000 (53%)]\tLoss: 1.916446\n",
      "Train Epoch: 1 [26880/50000 (54%)]\tLoss: 2.089375\n",
      "Train Epoch: 1 [27200/50000 (54%)]\tLoss: 1.924818\n",
      "Train Epoch: 1 [27520/50000 (55%)]\tLoss: 1.952278\n",
      "Train Epoch: 1 [27840/50000 (56%)]\tLoss: 1.968408\n",
      "Train Epoch: 1 [28160/50000 (56%)]\tLoss: 2.171888\n",
      "Train Epoch: 1 [28480/50000 (57%)]\tLoss: 1.880871\n",
      "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 1.948607\n",
      "Train Epoch: 1 [29120/50000 (58%)]\tLoss: 2.081268\n",
      "Train Epoch: 1 [29440/50000 (59%)]\tLoss: 1.869956\n",
      "Train Epoch: 1 [29760/50000 (60%)]\tLoss: 1.904298\n",
      "Train Epoch: 1 [30080/50000 (60%)]\tLoss: 1.959979\n",
      "Train Epoch: 1 [30400/50000 (61%)]\tLoss: 1.797176\n",
      "Train Epoch: 1 [30720/50000 (61%)]\tLoss: 1.926605\n",
      "Train Epoch: 1 [31040/50000 (62%)]\tLoss: 1.731760\n",
      "Train Epoch: 1 [31360/50000 (63%)]\tLoss: 1.834148\n",
      "Train Epoch: 1 [31680/50000 (63%)]\tLoss: 1.923123\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.216970\n",
      "Train Epoch: 1 [32320/50000 (65%)]\tLoss: 1.816334\n",
      "Train Epoch: 1 [32640/50000 (65%)]\tLoss: 2.036711\n",
      "Train Epoch: 1 [32960/50000 (66%)]\tLoss: 1.867213\n",
      "Train Epoch: 1 [33280/50000 (67%)]\tLoss: 1.891083\n",
      "Train Epoch: 1 [33600/50000 (67%)]\tLoss: 1.837931\n",
      "Train Epoch: 1 [33920/50000 (68%)]\tLoss: 1.869751\n",
      "Train Epoch: 1 [34240/50000 (68%)]\tLoss: 2.043199\n",
      "Train Epoch: 1 [34560/50000 (69%)]\tLoss: 1.888484\n",
      "Train Epoch: 1 [34880/50000 (70%)]\tLoss: 1.963247\n",
      "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 1.850395\n",
      "Train Epoch: 1 [35520/50000 (71%)]\tLoss: 1.851405\n",
      "Train Epoch: 1 [35840/50000 (72%)]\tLoss: 1.890215\n",
      "Train Epoch: 1 [36160/50000 (72%)]\tLoss: 1.845417\n",
      "Train Epoch: 1 [36480/50000 (73%)]\tLoss: 1.933845\n",
      "Train Epoch: 1 [36800/50000 (74%)]\tLoss: 1.983433\n",
      "Train Epoch: 1 [37120/50000 (74%)]\tLoss: 1.772937\n",
      "Train Epoch: 1 [37440/50000 (75%)]\tLoss: 2.120450\n",
      "Train Epoch: 1 [37760/50000 (75%)]\tLoss: 1.873662\n",
      "Train Epoch: 1 [38080/50000 (76%)]\tLoss: 1.929432\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.801036\n",
      "Train Epoch: 1 [38720/50000 (77%)]\tLoss: 1.940518\n",
      "Train Epoch: 1 [39040/50000 (78%)]\tLoss: 1.991776\n",
      "Train Epoch: 1 [39360/50000 (79%)]\tLoss: 2.109310\n",
      "Train Epoch: 1 [39680/50000 (79%)]\tLoss: 1.983356\n",
      "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 1.786791\n",
      "Train Epoch: 1 [40320/50000 (81%)]\tLoss: 2.063937\n",
      "Train Epoch: 1 [40640/50000 (81%)]\tLoss: 2.062743\n",
      "Train Epoch: 1 [40960/50000 (82%)]\tLoss: 1.750429\n",
      "Train Epoch: 1 [41280/50000 (83%)]\tLoss: 1.747735\n",
      "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 1.927478\n",
      "Train Epoch: 1 [41920/50000 (84%)]\tLoss: 1.982650\n",
      "Train Epoch: 1 [42240/50000 (84%)]\tLoss: 1.672797\n",
      "Train Epoch: 1 [42560/50000 (85%)]\tLoss: 1.945821\n",
      "Train Epoch: 1 [42880/50000 (86%)]\tLoss: 1.854239\n",
      "Train Epoch: 1 [43200/50000 (86%)]\tLoss: 1.912116\n",
      "Train Epoch: 1 [43520/50000 (87%)]\tLoss: 1.950126\n",
      "Train Epoch: 1 [43840/50000 (88%)]\tLoss: 1.863420\n",
      "Train Epoch: 1 [44160/50000 (88%)]\tLoss: 1.813523\n",
      "Train Epoch: 1 [44480/50000 (89%)]\tLoss: 1.800689\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.902412\n",
      "Train Epoch: 1 [45120/50000 (90%)]\tLoss: 1.764754\n",
      "Train Epoch: 1 [45440/50000 (91%)]\tLoss: 2.019127\n",
      "Train Epoch: 1 [45760/50000 (91%)]\tLoss: 1.929686\n",
      "Train Epoch: 1 [46080/50000 (92%)]\tLoss: 1.789549\n",
      "Train Epoch: 1 [46400/50000 (93%)]\tLoss: 2.055269\n",
      "Train Epoch: 1 [46720/50000 (93%)]\tLoss: 1.797435\n",
      "Train Epoch: 1 [47040/50000 (94%)]\tLoss: 1.930150\n",
      "Train Epoch: 1 [47360/50000 (95%)]\tLoss: 2.072278\n",
      "Train Epoch: 1 [47680/50000 (95%)]\tLoss: 1.990400\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 2.068942\n",
      "Train Epoch: 1 [48320/50000 (97%)]\tLoss: 1.774273\n",
      "Train Epoch: 1 [48640/50000 (97%)]\tLoss: 2.116072\n",
      "Train Epoch: 1 [48960/50000 (98%)]\tLoss: 1.927464\n",
      "Train Epoch: 1 [49280/50000 (99%)]\tLoss: 1.805820\n",
      "Train Epoch: 1 [49600/50000 (99%)]\tLoss: 2.017300\n",
      "Train Epoch: 1 [49920/50000 (100%)]\tLoss: 1.708246\n",
      "\n",
      "Test set: Avg. loss: 1.8907, Accuracy: 3333/10000 (33%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.993851\n",
      "Train Epoch: 2 [320/50000 (1%)]\tLoss: 1.688134\n",
      "Train Epoch: 2 [640/50000 (1%)]\tLoss: 1.844489\n",
      "Train Epoch: 2 [960/50000 (2%)]\tLoss: 1.816551\n",
      "Train Epoch: 2 [1280/50000 (3%)]\tLoss: 1.822027\n",
      "Train Epoch: 2 [1600/50000 (3%)]\tLoss: 1.934070\n",
      "Train Epoch: 2 [1920/50000 (4%)]\tLoss: 1.751786\n",
      "Train Epoch: 2 [2240/50000 (4%)]\tLoss: 1.932701\n",
      "Train Epoch: 2 [2560/50000 (5%)]\tLoss: 1.747273\n",
      "Train Epoch: 2 [2880/50000 (6%)]\tLoss: 1.751119\n",
      "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 1.854478\n",
      "Train Epoch: 2 [3520/50000 (7%)]\tLoss: 1.788873\n",
      "Train Epoch: 2 [3840/50000 (8%)]\tLoss: 1.711542\n",
      "Train Epoch: 2 [4160/50000 (8%)]\tLoss: 1.831517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [4480/50000 (9%)]\tLoss: 1.753031\n",
      "Train Epoch: 2 [4800/50000 (10%)]\tLoss: 1.848121\n",
      "Train Epoch: 2 [5120/50000 (10%)]\tLoss: 1.752219\n",
      "Train Epoch: 2 [5440/50000 (11%)]\tLoss: 1.927463\n",
      "Train Epoch: 2 [5760/50000 (12%)]\tLoss: 1.933768\n",
      "Train Epoch: 2 [6080/50000 (12%)]\tLoss: 1.705509\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.721266\n",
      "Train Epoch: 2 [6720/50000 (13%)]\tLoss: 2.169960\n",
      "Train Epoch: 2 [7040/50000 (14%)]\tLoss: 1.864570\n",
      "Train Epoch: 2 [7360/50000 (15%)]\tLoss: 1.762724\n",
      "Train Epoch: 2 [7680/50000 (15%)]\tLoss: 1.880111\n",
      "Train Epoch: 2 [8000/50000 (16%)]\tLoss: 1.875964\n",
      "Train Epoch: 2 [8320/50000 (17%)]\tLoss: 1.886298\n",
      "Train Epoch: 2 [8640/50000 (17%)]\tLoss: 1.742773\n",
      "Train Epoch: 2 [8960/50000 (18%)]\tLoss: 1.843654\n",
      "Train Epoch: 2 [9280/50000 (19%)]\tLoss: 1.651989\n",
      "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 1.833954\n",
      "Train Epoch: 2 [9920/50000 (20%)]\tLoss: 1.937297\n",
      "Train Epoch: 2 [10240/50000 (20%)]\tLoss: 1.846593\n",
      "Train Epoch: 2 [10560/50000 (21%)]\tLoss: 1.844962\n",
      "Train Epoch: 2 [10880/50000 (22%)]\tLoss: 1.876605\n",
      "Train Epoch: 2 [11200/50000 (22%)]\tLoss: 1.796280\n",
      "Train Epoch: 2 [11520/50000 (23%)]\tLoss: 1.958613\n",
      "Train Epoch: 2 [11840/50000 (24%)]\tLoss: 2.068822\n",
      "Train Epoch: 2 [12160/50000 (24%)]\tLoss: 2.064700\n",
      "Train Epoch: 2 [12480/50000 (25%)]\tLoss: 1.891809\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.830796\n",
      "Train Epoch: 2 [13120/50000 (26%)]\tLoss: 1.976472\n",
      "Train Epoch: 2 [13440/50000 (27%)]\tLoss: 1.900558\n",
      "Train Epoch: 2 [13760/50000 (28%)]\tLoss: 1.860417\n",
      "Train Epoch: 2 [14080/50000 (28%)]\tLoss: 1.768339\n",
      "Train Epoch: 2 [14400/50000 (29%)]\tLoss: 1.792781\n",
      "Train Epoch: 2 [14720/50000 (29%)]\tLoss: 1.875688\n",
      "Train Epoch: 2 [15040/50000 (30%)]\tLoss: 1.853552\n",
      "Train Epoch: 2 [15360/50000 (31%)]\tLoss: 1.967731\n",
      "Train Epoch: 2 [15680/50000 (31%)]\tLoss: 1.807664\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 2.000198\n",
      "Train Epoch: 2 [16320/50000 (33%)]\tLoss: 1.762174\n",
      "Train Epoch: 2 [16640/50000 (33%)]\tLoss: 2.168538\n",
      "Train Epoch: 2 [16960/50000 (34%)]\tLoss: 1.705922\n",
      "Train Epoch: 2 [17280/50000 (35%)]\tLoss: 1.690130\n",
      "Train Epoch: 2 [17600/50000 (35%)]\tLoss: 1.812122\n",
      "Train Epoch: 2 [17920/50000 (36%)]\tLoss: 1.965837\n",
      "Train Epoch: 2 [18240/50000 (36%)]\tLoss: 1.768011\n",
      "Train Epoch: 2 [18560/50000 (37%)]\tLoss: 1.725160\n",
      "Train Epoch: 2 [18880/50000 (38%)]\tLoss: 1.698815\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.985942\n",
      "Train Epoch: 2 [19520/50000 (39%)]\tLoss: 1.798573\n",
      "Train Epoch: 2 [19840/50000 (40%)]\tLoss: 1.973332\n",
      "Train Epoch: 2 [20160/50000 (40%)]\tLoss: 1.917268\n",
      "Train Epoch: 2 [20480/50000 (41%)]\tLoss: 2.184853\n",
      "Train Epoch: 2 [20800/50000 (42%)]\tLoss: 2.142678\n",
      "Train Epoch: 2 [21120/50000 (42%)]\tLoss: 1.971391\n",
      "Train Epoch: 2 [21440/50000 (43%)]\tLoss: 1.942389\n",
      "Train Epoch: 2 [21760/50000 (44%)]\tLoss: 1.811838\n",
      "Train Epoch: 2 [22080/50000 (44%)]\tLoss: 1.889809\n",
      "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 1.815310\n",
      "Train Epoch: 2 [22720/50000 (45%)]\tLoss: 1.784990\n",
      "Train Epoch: 2 [23040/50000 (46%)]\tLoss: 1.942060\n",
      "Train Epoch: 2 [23360/50000 (47%)]\tLoss: 1.912074\n",
      "Train Epoch: 2 [23680/50000 (47%)]\tLoss: 1.776530\n",
      "Train Epoch: 2 [24000/50000 (48%)]\tLoss: 1.905820\n",
      "Train Epoch: 2 [24320/50000 (49%)]\tLoss: 2.140183\n",
      "Train Epoch: 2 [24640/50000 (49%)]\tLoss: 1.974207\n",
      "Train Epoch: 2 [24960/50000 (50%)]\tLoss: 1.708710\n",
      "Train Epoch: 2 [25280/50000 (51%)]\tLoss: 1.972610\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.786640\n",
      "Train Epoch: 2 [25920/50000 (52%)]\tLoss: 1.674622\n",
      "Train Epoch: 2 [26240/50000 (52%)]\tLoss: 1.863228\n",
      "Train Epoch: 2 [26560/50000 (53%)]\tLoss: 1.909972\n",
      "Train Epoch: 2 [26880/50000 (54%)]\tLoss: 1.983986\n",
      "Train Epoch: 2 [27200/50000 (54%)]\tLoss: 1.714755\n",
      "Train Epoch: 2 [27520/50000 (55%)]\tLoss: 1.857978\n",
      "Train Epoch: 2 [27840/50000 (56%)]\tLoss: 1.813849\n",
      "Train Epoch: 2 [28160/50000 (56%)]\tLoss: 1.749356\n",
      "Train Epoch: 2 [28480/50000 (57%)]\tLoss: 1.743315\n",
      "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 1.837680\n",
      "Train Epoch: 2 [29120/50000 (58%)]\tLoss: 2.020572\n",
      "Train Epoch: 2 [29440/50000 (59%)]\tLoss: 1.985491\n",
      "Train Epoch: 2 [29760/50000 (60%)]\tLoss: 1.914520\n",
      "Train Epoch: 2 [30080/50000 (60%)]\tLoss: 1.653203\n",
      "Train Epoch: 2 [30400/50000 (61%)]\tLoss: 1.948702\n",
      "Train Epoch: 2 [30720/50000 (61%)]\tLoss: 1.952506\n",
      "Train Epoch: 2 [31040/50000 (62%)]\tLoss: 1.687578\n",
      "Train Epoch: 2 [31360/50000 (63%)]\tLoss: 1.870926\n",
      "Train Epoch: 2 [31680/50000 (63%)]\tLoss: 1.685374\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.727409\n",
      "Train Epoch: 2 [32320/50000 (65%)]\tLoss: 1.972543\n",
      "Train Epoch: 2 [32640/50000 (65%)]\tLoss: 1.964119\n",
      "Train Epoch: 2 [32960/50000 (66%)]\tLoss: 1.923373\n",
      "Train Epoch: 2 [33280/50000 (67%)]\tLoss: 1.700947\n",
      "Train Epoch: 2 [33600/50000 (67%)]\tLoss: 1.816916\n",
      "Train Epoch: 2 [33920/50000 (68%)]\tLoss: 1.673414\n",
      "Train Epoch: 2 [34240/50000 (68%)]\tLoss: 1.901150\n",
      "Train Epoch: 2 [34560/50000 (69%)]\tLoss: 2.228166\n",
      "Train Epoch: 2 [34880/50000 (70%)]\tLoss: 1.918523\n",
      "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 1.918519\n",
      "Train Epoch: 2 [35520/50000 (71%)]\tLoss: 1.574588\n",
      "Train Epoch: 2 [35840/50000 (72%)]\tLoss: 1.902764\n",
      "Train Epoch: 2 [36160/50000 (72%)]\tLoss: 1.801266\n",
      "Train Epoch: 2 [36480/50000 (73%)]\tLoss: 1.832503\n",
      "Train Epoch: 2 [36800/50000 (74%)]\tLoss: 1.897180\n",
      "Train Epoch: 2 [37120/50000 (74%)]\tLoss: 1.643772\n",
      "Train Epoch: 2 [37440/50000 (75%)]\tLoss: 1.940415\n",
      "Train Epoch: 2 [37760/50000 (75%)]\tLoss: 1.626805\n",
      "Train Epoch: 2 [38080/50000 (76%)]\tLoss: 1.892883\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.780167\n",
      "Train Epoch: 2 [38720/50000 (77%)]\tLoss: 1.872800\n",
      "Train Epoch: 2 [39040/50000 (78%)]\tLoss: 1.929272\n",
      "Train Epoch: 2 [39360/50000 (79%)]\tLoss: 1.894660\n",
      "Train Epoch: 2 [39680/50000 (79%)]\tLoss: 1.646905\n",
      "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 1.685917\n",
      "Train Epoch: 2 [40320/50000 (81%)]\tLoss: 1.944444\n",
      "Train Epoch: 2 [40640/50000 (81%)]\tLoss: 1.971237\n",
      "Train Epoch: 2 [40960/50000 (82%)]\tLoss: 1.777422\n",
      "Train Epoch: 2 [41280/50000 (83%)]\tLoss: 1.981601\n",
      "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 1.653532\n",
      "Train Epoch: 2 [41920/50000 (84%)]\tLoss: 1.538004\n",
      "Train Epoch: 2 [42240/50000 (84%)]\tLoss: 2.018114\n",
      "Train Epoch: 2 [42560/50000 (85%)]\tLoss: 1.968469\n",
      "Train Epoch: 2 [42880/50000 (86%)]\tLoss: 1.996730\n",
      "Train Epoch: 2 [43200/50000 (86%)]\tLoss: 2.016589\n",
      "Train Epoch: 2 [43520/50000 (87%)]\tLoss: 1.972390\n",
      "Train Epoch: 2 [43840/50000 (88%)]\tLoss: 1.706092\n",
      "Train Epoch: 2 [44160/50000 (88%)]\tLoss: 1.864393\n",
      "Train Epoch: 2 [44480/50000 (89%)]\tLoss: 1.929311\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.976855\n",
      "Train Epoch: 2 [45120/50000 (90%)]\tLoss: 1.795676\n",
      "Train Epoch: 2 [45440/50000 (91%)]\tLoss: 1.616241\n",
      "Train Epoch: 2 [45760/50000 (91%)]\tLoss: 1.702663\n",
      "Train Epoch: 2 [46080/50000 (92%)]\tLoss: 1.856538\n",
      "Train Epoch: 2 [46400/50000 (93%)]\tLoss: 1.954267\n",
      "Train Epoch: 2 [46720/50000 (93%)]\tLoss: 1.967507\n",
      "Train Epoch: 2 [47040/50000 (94%)]\tLoss: 1.675983\n",
      "Train Epoch: 2 [47360/50000 (95%)]\tLoss: 1.883939\n",
      "Train Epoch: 2 [47680/50000 (95%)]\tLoss: 1.751780\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 1.730800\n",
      "Train Epoch: 2 [48320/50000 (97%)]\tLoss: 2.028478\n",
      "Train Epoch: 2 [48640/50000 (97%)]\tLoss: 1.827062\n",
      "Train Epoch: 2 [48960/50000 (98%)]\tLoss: 1.815897\n",
      "Train Epoch: 2 [49280/50000 (99%)]\tLoss: 1.892011\n",
      "Train Epoch: 2 [49600/50000 (99%)]\tLoss: 1.806596\n",
      "Train Epoch: 2 [49920/50000 (100%)]\tLoss: 1.681307\n",
      "\n",
      "Test set: Avg. loss: 1.8458, Accuracy: 3494/10000 (35%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.824991\n",
      "Train Epoch: 3 [320/50000 (1%)]\tLoss: 1.640396\n",
      "Train Epoch: 3 [640/50000 (1%)]\tLoss: 1.730694\n",
      "Train Epoch: 3 [960/50000 (2%)]\tLoss: 1.814010\n",
      "Train Epoch: 3 [1280/50000 (3%)]\tLoss: 1.879191\n",
      "Train Epoch: 3 [1600/50000 (3%)]\tLoss: 2.024903\n",
      "Train Epoch: 3 [1920/50000 (4%)]\tLoss: 1.773538\n",
      "Train Epoch: 3 [2240/50000 (4%)]\tLoss: 2.008151\n",
      "Train Epoch: 3 [2560/50000 (5%)]\tLoss: 2.017708\n",
      "Train Epoch: 3 [2880/50000 (6%)]\tLoss: 1.692309\n",
      "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 1.905814\n",
      "Train Epoch: 3 [3520/50000 (7%)]\tLoss: 1.586122\n",
      "Train Epoch: 3 [3840/50000 (8%)]\tLoss: 1.769047\n",
      "Train Epoch: 3 [4160/50000 (8%)]\tLoss: 1.706130\n",
      "Train Epoch: 3 [4480/50000 (9%)]\tLoss: 1.932027\n",
      "Train Epoch: 3 [4800/50000 (10%)]\tLoss: 2.088412\n",
      "Train Epoch: 3 [5120/50000 (10%)]\tLoss: 1.939562\n",
      "Train Epoch: 3 [5440/50000 (11%)]\tLoss: 1.762246\n",
      "Train Epoch: 3 [5760/50000 (12%)]\tLoss: 1.750716\n",
      "Train Epoch: 3 [6080/50000 (12%)]\tLoss: 1.646809\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.774630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [6720/50000 (13%)]\tLoss: 1.760059\n",
      "Train Epoch: 3 [7040/50000 (14%)]\tLoss: 2.159623\n",
      "Train Epoch: 3 [7360/50000 (15%)]\tLoss: 1.800922\n",
      "Train Epoch: 3 [7680/50000 (15%)]\tLoss: 2.089542\n",
      "Train Epoch: 3 [8000/50000 (16%)]\tLoss: 1.794388\n",
      "Train Epoch: 3 [8320/50000 (17%)]\tLoss: 1.855988\n",
      "Train Epoch: 3 [8640/50000 (17%)]\tLoss: 1.733113\n",
      "Train Epoch: 3 [8960/50000 (18%)]\tLoss: 1.850222\n",
      "Train Epoch: 3 [9280/50000 (19%)]\tLoss: 1.929007\n",
      "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 1.985541\n",
      "Train Epoch: 3 [9920/50000 (20%)]\tLoss: 1.750042\n",
      "Train Epoch: 3 [10240/50000 (20%)]\tLoss: 1.723560\n",
      "Train Epoch: 3 [10560/50000 (21%)]\tLoss: 1.711757\n",
      "Train Epoch: 3 [10880/50000 (22%)]\tLoss: 1.842379\n",
      "Train Epoch: 3 [11200/50000 (22%)]\tLoss: 1.900071\n",
      "Train Epoch: 3 [11520/50000 (23%)]\tLoss: 1.992029\n",
      "Train Epoch: 3 [11840/50000 (24%)]\tLoss: 1.835711\n",
      "Train Epoch: 3 [12160/50000 (24%)]\tLoss: 1.912574\n",
      "Train Epoch: 3 [12480/50000 (25%)]\tLoss: 1.952109\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.931376\n",
      "Train Epoch: 3 [13120/50000 (26%)]\tLoss: 1.695136\n",
      "Train Epoch: 3 [13440/50000 (27%)]\tLoss: 1.905498\n",
      "Train Epoch: 3 [13760/50000 (28%)]\tLoss: 1.875960\n",
      "Train Epoch: 3 [14080/50000 (28%)]\tLoss: 1.967044\n",
      "Train Epoch: 3 [14400/50000 (29%)]\tLoss: 1.753210\n",
      "Train Epoch: 3 [14720/50000 (29%)]\tLoss: 1.812237\n",
      "Train Epoch: 3 [15040/50000 (30%)]\tLoss: 1.899047\n",
      "Train Epoch: 3 [15360/50000 (31%)]\tLoss: 1.641531\n",
      "Train Epoch: 3 [15680/50000 (31%)]\tLoss: 2.011620\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 1.979876\n",
      "Train Epoch: 3 [16320/50000 (33%)]\tLoss: 1.981256\n",
      "Train Epoch: 3 [16640/50000 (33%)]\tLoss: 1.733603\n",
      "Train Epoch: 3 [16960/50000 (34%)]\tLoss: 1.770288\n",
      "Train Epoch: 3 [17280/50000 (35%)]\tLoss: 1.908088\n",
      "Train Epoch: 3 [17600/50000 (35%)]\tLoss: 2.016671\n",
      "Train Epoch: 3 [17920/50000 (36%)]\tLoss: 1.793616\n",
      "Train Epoch: 3 [18240/50000 (36%)]\tLoss: 1.933318\n",
      "Train Epoch: 3 [18560/50000 (37%)]\tLoss: 1.966990\n",
      "Train Epoch: 3 [18880/50000 (38%)]\tLoss: 1.871125\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.707307\n",
      "Train Epoch: 3 [19520/50000 (39%)]\tLoss: 1.650755\n",
      "Train Epoch: 3 [19840/50000 (40%)]\tLoss: 1.812359\n",
      "Train Epoch: 3 [20160/50000 (40%)]\tLoss: 1.649813\n",
      "Train Epoch: 3 [20480/50000 (41%)]\tLoss: 1.774527\n",
      "Train Epoch: 3 [20800/50000 (42%)]\tLoss: 1.784546\n",
      "Train Epoch: 3 [21120/50000 (42%)]\tLoss: 2.239763\n",
      "Train Epoch: 3 [21440/50000 (43%)]\tLoss: 1.816738\n",
      "Train Epoch: 3 [21760/50000 (44%)]\tLoss: 1.898362\n",
      "Train Epoch: 3 [22080/50000 (44%)]\tLoss: 1.489640\n",
      "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 2.045079\n",
      "Train Epoch: 3 [22720/50000 (45%)]\tLoss: 2.015087\n",
      "Train Epoch: 3 [23040/50000 (46%)]\tLoss: 1.883616\n",
      "Train Epoch: 3 [23360/50000 (47%)]\tLoss: 1.778565\n",
      "Train Epoch: 3 [23680/50000 (47%)]\tLoss: 1.656356\n",
      "Train Epoch: 3 [24000/50000 (48%)]\tLoss: 1.904865\n",
      "Train Epoch: 3 [24320/50000 (49%)]\tLoss: 1.899265\n",
      "Train Epoch: 3 [24640/50000 (49%)]\tLoss: 1.674109\n",
      "Train Epoch: 3 [24960/50000 (50%)]\tLoss: 1.846810\n",
      "Train Epoch: 3 [25280/50000 (51%)]\tLoss: 1.858847\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.892087\n",
      "Train Epoch: 3 [25920/50000 (52%)]\tLoss: 1.854441\n",
      "Train Epoch: 3 [26240/50000 (52%)]\tLoss: 2.016034\n",
      "Train Epoch: 3 [26560/50000 (53%)]\tLoss: 1.785225\n",
      "Train Epoch: 3 [26880/50000 (54%)]\tLoss: 1.942563\n",
      "Train Epoch: 3 [27200/50000 (54%)]\tLoss: 2.025440\n",
      "Train Epoch: 3 [27520/50000 (55%)]\tLoss: 1.714928\n",
      "Train Epoch: 3 [27840/50000 (56%)]\tLoss: 1.989814\n",
      "Train Epoch: 3 [28160/50000 (56%)]\tLoss: 1.787877\n",
      "Train Epoch: 3 [28480/50000 (57%)]\tLoss: 1.826553\n",
      "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 1.898477\n",
      "Train Epoch: 3 [29120/50000 (58%)]\tLoss: 1.732227\n",
      "Train Epoch: 3 [29440/50000 (59%)]\tLoss: 1.900115\n",
      "Train Epoch: 3 [29760/50000 (60%)]\tLoss: 1.559769\n",
      "Train Epoch: 3 [30080/50000 (60%)]\tLoss: 1.954556\n",
      "Train Epoch: 3 [30400/50000 (61%)]\tLoss: 1.722385\n",
      "Train Epoch: 3 [30720/50000 (61%)]\tLoss: 1.713049\n",
      "Train Epoch: 3 [31040/50000 (62%)]\tLoss: 1.617727\n",
      "Train Epoch: 3 [31360/50000 (63%)]\tLoss: 2.123066\n",
      "Train Epoch: 3 [31680/50000 (63%)]\tLoss: 1.761537\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.796902\n",
      "Train Epoch: 3 [32320/50000 (65%)]\tLoss: 1.826822\n",
      "Train Epoch: 3 [32640/50000 (65%)]\tLoss: 1.689464\n",
      "Train Epoch: 3 [32960/50000 (66%)]\tLoss: 1.981340\n",
      "Train Epoch: 3 [33280/50000 (67%)]\tLoss: 1.899247\n",
      "Train Epoch: 3 [33600/50000 (67%)]\tLoss: 1.839146\n",
      "Train Epoch: 3 [33920/50000 (68%)]\tLoss: 1.807148\n",
      "Train Epoch: 3 [34240/50000 (68%)]\tLoss: 1.831500\n",
      "Train Epoch: 3 [34560/50000 (69%)]\tLoss: 1.943287\n",
      "Train Epoch: 3 [34880/50000 (70%)]\tLoss: 1.859433\n",
      "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 1.897920\n",
      "Train Epoch: 3 [35520/50000 (71%)]\tLoss: 1.776077\n",
      "Train Epoch: 3 [35840/50000 (72%)]\tLoss: 1.799975\n",
      "Train Epoch: 3 [36160/50000 (72%)]\tLoss: 1.927819\n",
      "Train Epoch: 3 [36480/50000 (73%)]\tLoss: 1.747910\n",
      "Train Epoch: 3 [36800/50000 (74%)]\tLoss: 1.828107\n",
      "Train Epoch: 3 [37120/50000 (74%)]\tLoss: 1.921985\n",
      "Train Epoch: 3 [37440/50000 (75%)]\tLoss: 1.691484\n",
      "Train Epoch: 3 [37760/50000 (75%)]\tLoss: 1.801104\n",
      "Train Epoch: 3 [38080/50000 (76%)]\tLoss: 1.842789\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.774478\n",
      "Train Epoch: 3 [38720/50000 (77%)]\tLoss: 1.710511\n",
      "Train Epoch: 3 [39040/50000 (78%)]\tLoss: 1.569871\n",
      "Train Epoch: 3 [39360/50000 (79%)]\tLoss: 1.549853\n",
      "Train Epoch: 3 [39680/50000 (79%)]\tLoss: 1.930858\n",
      "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 1.920292\n",
      "Train Epoch: 3 [40320/50000 (81%)]\tLoss: 1.945858\n",
      "Train Epoch: 3 [40640/50000 (81%)]\tLoss: 1.876728\n",
      "Train Epoch: 3 [40960/50000 (82%)]\tLoss: 1.780629\n",
      "Train Epoch: 3 [41280/50000 (83%)]\tLoss: 1.570727\n",
      "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 1.922235\n",
      "Train Epoch: 3 [41920/50000 (84%)]\tLoss: 1.756436\n",
      "Train Epoch: 3 [42240/50000 (84%)]\tLoss: 1.922978\n",
      "Train Epoch: 3 [42560/50000 (85%)]\tLoss: 1.939520\n",
      "Train Epoch: 3 [42880/50000 (86%)]\tLoss: 1.847271\n",
      "Train Epoch: 3 [43200/50000 (86%)]\tLoss: 1.698613\n",
      "Train Epoch: 3 [43520/50000 (87%)]\tLoss: 1.644722\n",
      "Train Epoch: 3 [43840/50000 (88%)]\tLoss: 1.852952\n",
      "Train Epoch: 3 [44160/50000 (88%)]\tLoss: 1.974987\n",
      "Train Epoch: 3 [44480/50000 (89%)]\tLoss: 1.619015\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 2.049615\n",
      "Train Epoch: 3 [45120/50000 (90%)]\tLoss: 1.779211\n",
      "Train Epoch: 3 [45440/50000 (91%)]\tLoss: 1.746389\n",
      "Train Epoch: 3 [45760/50000 (91%)]\tLoss: 1.886648\n",
      "Train Epoch: 3 [46080/50000 (92%)]\tLoss: 1.979332\n",
      "Train Epoch: 3 [46400/50000 (93%)]\tLoss: 1.803427\n",
      "Train Epoch: 3 [46720/50000 (93%)]\tLoss: 1.972213\n",
      "Train Epoch: 3 [47040/50000 (94%)]\tLoss: 1.769774\n",
      "Train Epoch: 3 [47360/50000 (95%)]\tLoss: 1.816813\n",
      "Train Epoch: 3 [47680/50000 (95%)]\tLoss: 2.138780\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 1.873674\n",
      "Train Epoch: 3 [48320/50000 (97%)]\tLoss: 1.713491\n",
      "Train Epoch: 3 [48640/50000 (97%)]\tLoss: 1.751434\n",
      "Train Epoch: 3 [48960/50000 (98%)]\tLoss: 1.696989\n",
      "Train Epoch: 3 [49280/50000 (99%)]\tLoss: 1.604294\n",
      "Train Epoch: 3 [49600/50000 (99%)]\tLoss: 1.772849\n",
      "Train Epoch: 3 [49920/50000 (100%)]\tLoss: 1.888636\n",
      "\n",
      "Test set: Avg. loss: 1.8266, Accuracy: 3540/10000 (35%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.722588\n",
      "Train Epoch: 4 [320/50000 (1%)]\tLoss: 1.956282\n",
      "Train Epoch: 4 [640/50000 (1%)]\tLoss: 1.938081\n",
      "Train Epoch: 4 [960/50000 (2%)]\tLoss: 1.781316\n",
      "Train Epoch: 4 [1280/50000 (3%)]\tLoss: 1.842482\n",
      "Train Epoch: 4 [1600/50000 (3%)]\tLoss: 1.768519\n",
      "Train Epoch: 4 [1920/50000 (4%)]\tLoss: 1.848302\n",
      "Train Epoch: 4 [2240/50000 (4%)]\tLoss: 1.825161\n",
      "Train Epoch: 4 [2560/50000 (5%)]\tLoss: 2.032842\n",
      "Train Epoch: 4 [2880/50000 (6%)]\tLoss: 1.733753\n",
      "Train Epoch: 4 [3200/50000 (6%)]\tLoss: 1.685248\n",
      "Train Epoch: 4 [3520/50000 (7%)]\tLoss: 1.902675\n",
      "Train Epoch: 4 [3840/50000 (8%)]\tLoss: 1.943025\n",
      "Train Epoch: 4 [4160/50000 (8%)]\tLoss: 1.826188\n",
      "Train Epoch: 4 [4480/50000 (9%)]\tLoss: 1.695352\n",
      "Train Epoch: 4 [4800/50000 (10%)]\tLoss: 1.850747\n",
      "Train Epoch: 4 [5120/50000 (10%)]\tLoss: 1.855729\n",
      "Train Epoch: 4 [5440/50000 (11%)]\tLoss: 1.767836\n",
      "Train Epoch: 4 [5760/50000 (12%)]\tLoss: 2.015555\n",
      "Train Epoch: 4 [6080/50000 (12%)]\tLoss: 1.706130\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.634417\n",
      "Train Epoch: 4 [6720/50000 (13%)]\tLoss: 1.861175\n",
      "Train Epoch: 4 [7040/50000 (14%)]\tLoss: 2.025915\n",
      "Train Epoch: 4 [7360/50000 (15%)]\tLoss: 1.565695\n",
      "Train Epoch: 4 [7680/50000 (15%)]\tLoss: 1.758874\n",
      "Train Epoch: 4 [8000/50000 (16%)]\tLoss: 1.833553\n",
      "Train Epoch: 4 [8320/50000 (17%)]\tLoss: 1.845259\n",
      "Train Epoch: 4 [8640/50000 (17%)]\tLoss: 1.957850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [8960/50000 (18%)]\tLoss: 1.814336\n",
      "Train Epoch: 4 [9280/50000 (19%)]\tLoss: 2.041853\n",
      "Train Epoch: 4 [9600/50000 (19%)]\tLoss: 1.848240\n",
      "Train Epoch: 4 [9920/50000 (20%)]\tLoss: 1.836654\n",
      "Train Epoch: 4 [10240/50000 (20%)]\tLoss: 1.807689\n",
      "Train Epoch: 4 [10560/50000 (21%)]\tLoss: 1.816464\n",
      "Train Epoch: 4 [10880/50000 (22%)]\tLoss: 1.751378\n",
      "Train Epoch: 4 [11200/50000 (22%)]\tLoss: 1.872334\n",
      "Train Epoch: 4 [11520/50000 (23%)]\tLoss: 1.913375\n",
      "Train Epoch: 4 [11840/50000 (24%)]\tLoss: 1.934407\n",
      "Train Epoch: 4 [12160/50000 (24%)]\tLoss: 1.852543\n",
      "Train Epoch: 4 [12480/50000 (25%)]\tLoss: 1.850769\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.753243\n",
      "Train Epoch: 4 [13120/50000 (26%)]\tLoss: 1.816702\n",
      "Train Epoch: 4 [13440/50000 (27%)]\tLoss: 1.853896\n",
      "Train Epoch: 4 [13760/50000 (28%)]\tLoss: 1.775591\n",
      "Train Epoch: 4 [14080/50000 (28%)]\tLoss: 1.937145\n",
      "Train Epoch: 4 [14400/50000 (29%)]\tLoss: 1.844877\n",
      "Train Epoch: 4 [14720/50000 (29%)]\tLoss: 1.749787\n",
      "Train Epoch: 4 [15040/50000 (30%)]\tLoss: 1.769358\n",
      "Train Epoch: 4 [15360/50000 (31%)]\tLoss: 1.918459\n",
      "Train Epoch: 4 [15680/50000 (31%)]\tLoss: 1.776312\n",
      "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 1.654010\n",
      "Train Epoch: 4 [16320/50000 (33%)]\tLoss: 1.810097\n",
      "Train Epoch: 4 [16640/50000 (33%)]\tLoss: 1.716843\n",
      "Train Epoch: 4 [16960/50000 (34%)]\tLoss: 1.931737\n",
      "Train Epoch: 4 [17280/50000 (35%)]\tLoss: 1.724459\n",
      "Train Epoch: 4 [17600/50000 (35%)]\tLoss: 1.778228\n",
      "Train Epoch: 4 [17920/50000 (36%)]\tLoss: 1.755410\n",
      "Train Epoch: 4 [18240/50000 (36%)]\tLoss: 1.701822\n",
      "Train Epoch: 4 [18560/50000 (37%)]\tLoss: 1.714497\n",
      "Train Epoch: 4 [18880/50000 (38%)]\tLoss: 1.850195\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.764889\n",
      "Train Epoch: 4 [19520/50000 (39%)]\tLoss: 1.905860\n",
      "Train Epoch: 4 [19840/50000 (40%)]\tLoss: 2.009106\n",
      "Train Epoch: 4 [20160/50000 (40%)]\tLoss: 1.851713\n",
      "Train Epoch: 4 [20480/50000 (41%)]\tLoss: 1.574588\n",
      "Train Epoch: 4 [20800/50000 (42%)]\tLoss: 1.756185\n",
      "Train Epoch: 4 [21120/50000 (42%)]\tLoss: 1.954437\n",
      "Train Epoch: 4 [21440/50000 (43%)]\tLoss: 1.764823\n",
      "Train Epoch: 4 [21760/50000 (44%)]\tLoss: 1.745492\n",
      "Train Epoch: 4 [22080/50000 (44%)]\tLoss: 1.798471\n",
      "Train Epoch: 4 [22400/50000 (45%)]\tLoss: 1.872262\n",
      "Train Epoch: 4 [22720/50000 (45%)]\tLoss: 1.877298\n",
      "Train Epoch: 4 [23040/50000 (46%)]\tLoss: 1.882999\n",
      "Train Epoch: 4 [23360/50000 (47%)]\tLoss: 1.819507\n",
      "Train Epoch: 4 [23680/50000 (47%)]\tLoss: 1.966570\n",
      "Train Epoch: 4 [24000/50000 (48%)]\tLoss: 1.842464\n",
      "Train Epoch: 4 [24320/50000 (49%)]\tLoss: 2.066629\n",
      "Train Epoch: 4 [24640/50000 (49%)]\tLoss: 1.879388\n",
      "Train Epoch: 4 [24960/50000 (50%)]\tLoss: 1.493402\n",
      "Train Epoch: 4 [25280/50000 (51%)]\tLoss: 1.699144\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.735558\n",
      "Train Epoch: 4 [25920/50000 (52%)]\tLoss: 1.746981\n",
      "Train Epoch: 4 [26240/50000 (52%)]\tLoss: 2.007066\n",
      "Train Epoch: 4 [26560/50000 (53%)]\tLoss: 1.898600\n",
      "Train Epoch: 4 [26880/50000 (54%)]\tLoss: 1.883031\n",
      "Train Epoch: 4 [27200/50000 (54%)]\tLoss: 1.930037\n",
      "Train Epoch: 4 [27520/50000 (55%)]\tLoss: 1.998411\n",
      "Train Epoch: 4 [27840/50000 (56%)]\tLoss: 1.715891\n",
      "Train Epoch: 4 [28160/50000 (56%)]\tLoss: 1.991591\n",
      "Train Epoch: 4 [28480/50000 (57%)]\tLoss: 1.852058\n",
      "Train Epoch: 4 [28800/50000 (58%)]\tLoss: 1.974789\n",
      "Train Epoch: 4 [29120/50000 (58%)]\tLoss: 1.732038\n",
      "Train Epoch: 4 [29440/50000 (59%)]\tLoss: 1.787798\n",
      "Train Epoch: 4 [29760/50000 (60%)]\tLoss: 1.883518\n",
      "Train Epoch: 4 [30080/50000 (60%)]\tLoss: 2.073821\n",
      "Train Epoch: 4 [30400/50000 (61%)]\tLoss: 1.705011\n",
      "Train Epoch: 4 [30720/50000 (61%)]\tLoss: 1.978008\n",
      "Train Epoch: 4 [31040/50000 (62%)]\tLoss: 1.884290\n",
      "Train Epoch: 4 [31360/50000 (63%)]\tLoss: 1.953906\n",
      "Train Epoch: 4 [31680/50000 (63%)]\tLoss: 1.921081\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.775756\n",
      "Train Epoch: 4 [32320/50000 (65%)]\tLoss: 1.779105\n",
      "Train Epoch: 4 [32640/50000 (65%)]\tLoss: 1.778053\n",
      "Train Epoch: 4 [32960/50000 (66%)]\tLoss: 1.593253\n",
      "Train Epoch: 4 [33280/50000 (67%)]\tLoss: 1.893208\n",
      "Train Epoch: 4 [33600/50000 (67%)]\tLoss: 1.804539\n",
      "Train Epoch: 4 [33920/50000 (68%)]\tLoss: 1.703066\n",
      "Train Epoch: 4 [34240/50000 (68%)]\tLoss: 1.924778\n",
      "Train Epoch: 4 [34560/50000 (69%)]\tLoss: 1.809518\n",
      "Train Epoch: 4 [34880/50000 (70%)]\tLoss: 2.049378\n",
      "Train Epoch: 4 [35200/50000 (70%)]\tLoss: 1.900348\n",
      "Train Epoch: 4 [35520/50000 (71%)]\tLoss: 1.781638\n",
      "Train Epoch: 4 [35840/50000 (72%)]\tLoss: 2.014154\n",
      "Train Epoch: 4 [36160/50000 (72%)]\tLoss: 1.904237\n",
      "Train Epoch: 4 [36480/50000 (73%)]\tLoss: 1.771325\n",
      "Train Epoch: 4 [36800/50000 (74%)]\tLoss: 1.696872\n",
      "Train Epoch: 4 [37120/50000 (74%)]\tLoss: 1.756944\n",
      "Train Epoch: 4 [37440/50000 (75%)]\tLoss: 1.880019\n",
      "Train Epoch: 4 [37760/50000 (75%)]\tLoss: 1.810236\n",
      "Train Epoch: 4 [38080/50000 (76%)]\tLoss: 1.955922\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.905336\n",
      "Train Epoch: 4 [38720/50000 (77%)]\tLoss: 1.864734\n",
      "Train Epoch: 4 [39040/50000 (78%)]\tLoss: 1.898396\n",
      "Train Epoch: 4 [39360/50000 (79%)]\tLoss: 2.209908\n",
      "Train Epoch: 4 [39680/50000 (79%)]\tLoss: 1.830590\n",
      "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 1.872312\n",
      "Train Epoch: 4 [40320/50000 (81%)]\tLoss: 1.753241\n",
      "Train Epoch: 4 [40640/50000 (81%)]\tLoss: 1.850541\n",
      "Train Epoch: 4 [40960/50000 (82%)]\tLoss: 1.692767\n",
      "Train Epoch: 4 [41280/50000 (83%)]\tLoss: 1.829998\n",
      "Train Epoch: 4 [41600/50000 (83%)]\tLoss: 1.742976\n",
      "Train Epoch: 4 [41920/50000 (84%)]\tLoss: 1.662168\n",
      "Train Epoch: 4 [42240/50000 (84%)]\tLoss: 1.804457\n",
      "Train Epoch: 4 [42560/50000 (85%)]\tLoss: 1.724925\n",
      "Train Epoch: 4 [42880/50000 (86%)]\tLoss: 1.806262\n",
      "Train Epoch: 4 [43200/50000 (86%)]\tLoss: 1.633543\n",
      "Train Epoch: 4 [43520/50000 (87%)]\tLoss: 1.967037\n",
      "Train Epoch: 4 [43840/50000 (88%)]\tLoss: 1.953886\n",
      "Train Epoch: 4 [44160/50000 (88%)]\tLoss: 1.951118\n",
      "Train Epoch: 4 [44480/50000 (89%)]\tLoss: 1.813647\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.808724\n",
      "Train Epoch: 4 [45120/50000 (90%)]\tLoss: 1.817460\n",
      "Train Epoch: 4 [45440/50000 (91%)]\tLoss: 1.671084\n",
      "Train Epoch: 4 [45760/50000 (91%)]\tLoss: 1.804794\n",
      "Train Epoch: 4 [46080/50000 (92%)]\tLoss: 1.806118\n",
      "Train Epoch: 4 [46400/50000 (93%)]\tLoss: 1.888101\n",
      "Train Epoch: 4 [46720/50000 (93%)]\tLoss: 2.037606\n",
      "Train Epoch: 4 [47040/50000 (94%)]\tLoss: 1.798493\n",
      "Train Epoch: 4 [47360/50000 (95%)]\tLoss: 1.778647\n",
      "Train Epoch: 4 [47680/50000 (95%)]\tLoss: 1.925507\n",
      "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 2.002807\n",
      "Train Epoch: 4 [48320/50000 (97%)]\tLoss: 1.947231\n",
      "Train Epoch: 4 [48640/50000 (97%)]\tLoss: 1.737598\n",
      "Train Epoch: 4 [48960/50000 (98%)]\tLoss: 1.939506\n",
      "Train Epoch: 4 [49280/50000 (99%)]\tLoss: 1.821064\n",
      "Train Epoch: 4 [49600/50000 (99%)]\tLoss: 1.849374\n",
      "Train Epoch: 4 [49920/50000 (100%)]\tLoss: 1.642151\n",
      "\n",
      "Test set: Avg. loss: 1.8134, Accuracy: 3710/10000 (37%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.558495\n",
      "Train Epoch: 5 [320/50000 (1%)]\tLoss: 1.807181\n",
      "Train Epoch: 5 [640/50000 (1%)]\tLoss: 1.833610\n",
      "Train Epoch: 5 [960/50000 (2%)]\tLoss: 1.820902\n",
      "Train Epoch: 5 [1280/50000 (3%)]\tLoss: 1.928417\n",
      "Train Epoch: 5 [1600/50000 (3%)]\tLoss: 1.943415\n",
      "Train Epoch: 5 [1920/50000 (4%)]\tLoss: 1.912339\n",
      "Train Epoch: 5 [2240/50000 (4%)]\tLoss: 1.429637\n",
      "Train Epoch: 5 [2560/50000 (5%)]\tLoss: 1.882852\n",
      "Train Epoch: 5 [2880/50000 (6%)]\tLoss: 1.672673\n",
      "Train Epoch: 5 [3200/50000 (6%)]\tLoss: 1.877239\n",
      "Train Epoch: 5 [3520/50000 (7%)]\tLoss: 1.718592\n",
      "Train Epoch: 5 [3840/50000 (8%)]\tLoss: 1.895694\n",
      "Train Epoch: 5 [4160/50000 (8%)]\tLoss: 2.035367\n",
      "Train Epoch: 5 [4480/50000 (9%)]\tLoss: 1.930080\n",
      "Train Epoch: 5 [4800/50000 (10%)]\tLoss: 1.672711\n",
      "Train Epoch: 5 [5120/50000 (10%)]\tLoss: 1.763466\n",
      "Train Epoch: 5 [5440/50000 (11%)]\tLoss: 1.910885\n",
      "Train Epoch: 5 [5760/50000 (12%)]\tLoss: 1.998385\n",
      "Train Epoch: 5 [6080/50000 (12%)]\tLoss: 1.837333\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 2.015673\n",
      "Train Epoch: 5 [6720/50000 (13%)]\tLoss: 1.808929\n",
      "Train Epoch: 5 [7040/50000 (14%)]\tLoss: 1.710276\n",
      "Train Epoch: 5 [7360/50000 (15%)]\tLoss: 1.648133\n",
      "Train Epoch: 5 [7680/50000 (15%)]\tLoss: 1.794778\n",
      "Train Epoch: 5 [8000/50000 (16%)]\tLoss: 1.815177\n",
      "Train Epoch: 5 [8320/50000 (17%)]\tLoss: 1.884776\n",
      "Train Epoch: 5 [8640/50000 (17%)]\tLoss: 1.726779\n",
      "Train Epoch: 5 [8960/50000 (18%)]\tLoss: 1.680405\n",
      "Train Epoch: 5 [9280/50000 (19%)]\tLoss: 1.781866\n",
      "Train Epoch: 5 [9600/50000 (19%)]\tLoss: 1.732383\n",
      "Train Epoch: 5 [9920/50000 (20%)]\tLoss: 1.857185\n",
      "Train Epoch: 5 [10240/50000 (20%)]\tLoss: 1.838766\n",
      "Train Epoch: 5 [10560/50000 (21%)]\tLoss: 1.755197\n",
      "Train Epoch: 5 [10880/50000 (22%)]\tLoss: 1.985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [11200/50000 (22%)]\tLoss: 1.708094\n",
      "Train Epoch: 5 [11520/50000 (23%)]\tLoss: 1.953123\n",
      "Train Epoch: 5 [11840/50000 (24%)]\tLoss: 1.651391\n",
      "Train Epoch: 5 [12160/50000 (24%)]\tLoss: 2.023808\n",
      "Train Epoch: 5 [12480/50000 (25%)]\tLoss: 1.853244\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.865480\n",
      "Train Epoch: 5 [13120/50000 (26%)]\tLoss: 1.873628\n",
      "Train Epoch: 5 [13440/50000 (27%)]\tLoss: 1.915554\n",
      "Train Epoch: 5 [13760/50000 (28%)]\tLoss: 1.943027\n",
      "Train Epoch: 5 [14080/50000 (28%)]\tLoss: 1.772779\n",
      "Train Epoch: 5 [14400/50000 (29%)]\tLoss: 2.004988\n",
      "Train Epoch: 5 [14720/50000 (29%)]\tLoss: 2.089958\n",
      "Train Epoch: 5 [15040/50000 (30%)]\tLoss: 1.875651\n",
      "Train Epoch: 5 [15360/50000 (31%)]\tLoss: 1.699066\n",
      "Train Epoch: 5 [15680/50000 (31%)]\tLoss: 1.739483\n",
      "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 2.055350\n",
      "Train Epoch: 5 [16320/50000 (33%)]\tLoss: 2.003583\n",
      "Train Epoch: 5 [16640/50000 (33%)]\tLoss: 1.926216\n",
      "Train Epoch: 5 [16960/50000 (34%)]\tLoss: 1.949093\n",
      "Train Epoch: 5 [17280/50000 (35%)]\tLoss: 1.808292\n",
      "Train Epoch: 5 [17600/50000 (35%)]\tLoss: 1.776305\n",
      "Train Epoch: 5 [17920/50000 (36%)]\tLoss: 2.140765\n",
      "Train Epoch: 5 [18240/50000 (36%)]\tLoss: 1.718635\n",
      "Train Epoch: 5 [18560/50000 (37%)]\tLoss: 1.755012\n",
      "Train Epoch: 5 [18880/50000 (38%)]\tLoss: 1.558006\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.658459\n",
      "Train Epoch: 5 [19520/50000 (39%)]\tLoss: 1.671697\n",
      "Train Epoch: 5 [19840/50000 (40%)]\tLoss: 1.713214\n",
      "Train Epoch: 5 [20160/50000 (40%)]\tLoss: 2.054862\n",
      "Train Epoch: 5 [20480/50000 (41%)]\tLoss: 1.662416\n",
      "Train Epoch: 5 [20800/50000 (42%)]\tLoss: 2.144850\n",
      "Train Epoch: 5 [21120/50000 (42%)]\tLoss: 1.876873\n",
      "Train Epoch: 5 [21440/50000 (43%)]\tLoss: 1.864015\n",
      "Train Epoch: 5 [21760/50000 (44%)]\tLoss: 1.606848\n",
      "Train Epoch: 5 [22080/50000 (44%)]\tLoss: 1.949480\n",
      "Train Epoch: 5 [22400/50000 (45%)]\tLoss: 1.766485\n",
      "Train Epoch: 5 [22720/50000 (45%)]\tLoss: 1.694843\n",
      "Train Epoch: 5 [23040/50000 (46%)]\tLoss: 1.598526\n",
      "Train Epoch: 5 [23360/50000 (47%)]\tLoss: 1.972090\n",
      "Train Epoch: 5 [23680/50000 (47%)]\tLoss: 1.864657\n",
      "Train Epoch: 5 [24000/50000 (48%)]\tLoss: 1.923123\n",
      "Train Epoch: 5 [24320/50000 (49%)]\tLoss: 1.802812\n",
      "Train Epoch: 5 [24640/50000 (49%)]\tLoss: 1.771923\n",
      "Train Epoch: 5 [24960/50000 (50%)]\tLoss: 2.078188\n",
      "Train Epoch: 5 [25280/50000 (51%)]\tLoss: 1.731168\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.610331\n",
      "Train Epoch: 5 [25920/50000 (52%)]\tLoss: 1.721231\n",
      "Train Epoch: 5 [26240/50000 (52%)]\tLoss: 1.649611\n",
      "Train Epoch: 5 [26560/50000 (53%)]\tLoss: 1.837302\n",
      "Train Epoch: 5 [26880/50000 (54%)]\tLoss: 1.663614\n",
      "Train Epoch: 5 [27200/50000 (54%)]\tLoss: 1.873187\n",
      "Train Epoch: 5 [27520/50000 (55%)]\tLoss: 1.771052\n",
      "Train Epoch: 5 [27840/50000 (56%)]\tLoss: 1.843631\n",
      "Train Epoch: 5 [28160/50000 (56%)]\tLoss: 1.762274\n",
      "Train Epoch: 5 [28480/50000 (57%)]\tLoss: 2.100287\n",
      "Train Epoch: 5 [28800/50000 (58%)]\tLoss: 1.903185\n",
      "Train Epoch: 5 [29120/50000 (58%)]\tLoss: 1.754601\n",
      "Train Epoch: 5 [29440/50000 (59%)]\tLoss: 1.916182\n",
      "Train Epoch: 5 [29760/50000 (60%)]\tLoss: 1.769420\n",
      "Train Epoch: 5 [30080/50000 (60%)]\tLoss: 1.467910\n",
      "Train Epoch: 5 [30400/50000 (61%)]\tLoss: 1.932667\n",
      "Train Epoch: 5 [30720/50000 (61%)]\tLoss: 1.852811\n",
      "Train Epoch: 5 [31040/50000 (62%)]\tLoss: 1.714642\n",
      "Train Epoch: 5 [31360/50000 (63%)]\tLoss: 1.780783\n",
      "Train Epoch: 5 [31680/50000 (63%)]\tLoss: 1.625780\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.962384\n",
      "Train Epoch: 5 [32320/50000 (65%)]\tLoss: 1.825882\n",
      "Train Epoch: 5 [32640/50000 (65%)]\tLoss: 1.746149\n",
      "Train Epoch: 5 [32960/50000 (66%)]\tLoss: 2.114161\n",
      "Train Epoch: 5 [33280/50000 (67%)]\tLoss: 1.923175\n",
      "Train Epoch: 5 [33600/50000 (67%)]\tLoss: 1.602419\n",
      "Train Epoch: 5 [33920/50000 (68%)]\tLoss: 1.906869\n",
      "Train Epoch: 5 [34240/50000 (68%)]\tLoss: 1.860637\n",
      "Train Epoch: 5 [34560/50000 (69%)]\tLoss: 1.818277\n",
      "Train Epoch: 5 [34880/50000 (70%)]\tLoss: 1.713026\n",
      "Train Epoch: 5 [35200/50000 (70%)]\tLoss: 1.901699\n",
      "Train Epoch: 5 [35520/50000 (71%)]\tLoss: 1.637851\n",
      "Train Epoch: 5 [35840/50000 (72%)]\tLoss: 1.816172\n",
      "Train Epoch: 5 [36160/50000 (72%)]\tLoss: 2.055403\n",
      "Train Epoch: 5 [36480/50000 (73%)]\tLoss: 1.820301\n",
      "Train Epoch: 5 [36800/50000 (74%)]\tLoss: 1.721619\n",
      "Train Epoch: 5 [37120/50000 (74%)]\tLoss: 2.104710\n",
      "Train Epoch: 5 [37440/50000 (75%)]\tLoss: 1.931959\n",
      "Train Epoch: 5 [37760/50000 (75%)]\tLoss: 1.667663\n",
      "Train Epoch: 5 [38080/50000 (76%)]\tLoss: 1.786765\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.892396\n",
      "Train Epoch: 5 [38720/50000 (77%)]\tLoss: 1.575479\n",
      "Train Epoch: 5 [39040/50000 (78%)]\tLoss: 1.883493\n",
      "Train Epoch: 5 [39360/50000 (79%)]\tLoss: 1.832729\n",
      "Train Epoch: 5 [39680/50000 (79%)]\tLoss: 1.701680\n",
      "Train Epoch: 5 [40000/50000 (80%)]\tLoss: 1.750997\n",
      "Train Epoch: 5 [40320/50000 (81%)]\tLoss: 1.684971\n",
      "Train Epoch: 5 [40640/50000 (81%)]\tLoss: 1.940516\n",
      "Train Epoch: 5 [40960/50000 (82%)]\tLoss: 1.828744\n",
      "Train Epoch: 5 [41280/50000 (83%)]\tLoss: 1.773736\n",
      "Train Epoch: 5 [41600/50000 (83%)]\tLoss: 1.973778\n",
      "Train Epoch: 5 [41920/50000 (84%)]\tLoss: 1.800379\n",
      "Train Epoch: 5 [42240/50000 (84%)]\tLoss: 1.942250\n",
      "Train Epoch: 5 [42560/50000 (85%)]\tLoss: 1.720866\n",
      "Train Epoch: 5 [42880/50000 (86%)]\tLoss: 1.908940\n",
      "Train Epoch: 5 [43200/50000 (86%)]\tLoss: 1.790206\n",
      "Train Epoch: 5 [43520/50000 (87%)]\tLoss: 2.040823\n",
      "Train Epoch: 5 [43840/50000 (88%)]\tLoss: 1.723374\n",
      "Train Epoch: 5 [44160/50000 (88%)]\tLoss: 1.976491\n",
      "Train Epoch: 5 [44480/50000 (89%)]\tLoss: 1.840508\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.823307\n",
      "Train Epoch: 5 [45120/50000 (90%)]\tLoss: 2.095709\n",
      "Train Epoch: 5 [45440/50000 (91%)]\tLoss: 1.922137\n",
      "Train Epoch: 5 [45760/50000 (91%)]\tLoss: 1.876413\n",
      "Train Epoch: 5 [46080/50000 (92%)]\tLoss: 1.976587\n",
      "Train Epoch: 5 [46400/50000 (93%)]\tLoss: 1.598765\n",
      "Train Epoch: 5 [46720/50000 (93%)]\tLoss: 1.778515\n",
      "Train Epoch: 5 [47040/50000 (94%)]\tLoss: 1.903630\n",
      "Train Epoch: 5 [47360/50000 (95%)]\tLoss: 1.883233\n",
      "Train Epoch: 5 [47680/50000 (95%)]\tLoss: 1.922191\n",
      "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 1.954274\n",
      "Train Epoch: 5 [48320/50000 (97%)]\tLoss: 1.747207\n",
      "Train Epoch: 5 [48640/50000 (97%)]\tLoss: 1.713401\n",
      "Train Epoch: 5 [48960/50000 (98%)]\tLoss: 1.893907\n",
      "Train Epoch: 5 [49280/50000 (99%)]\tLoss: 1.881626\n",
      "Train Epoch: 5 [49600/50000 (99%)]\tLoss: 1.656090\n",
      "Train Epoch: 5 [49920/50000 (100%)]\tLoss: 1.660857\n",
      "\n",
      "Test set: Avg. loss: 1.7915, Accuracy: 3715/10000 (37%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.881114\n",
      "Train Epoch: 6 [320/50000 (1%)]\tLoss: 1.906941\n",
      "Train Epoch: 6 [640/50000 (1%)]\tLoss: 1.673941\n",
      "Train Epoch: 6 [960/50000 (2%)]\tLoss: 2.136050\n",
      "Train Epoch: 6 [1280/50000 (3%)]\tLoss: 1.609332\n",
      "Train Epoch: 6 [1600/50000 (3%)]\tLoss: 1.920829\n",
      "Train Epoch: 6 [1920/50000 (4%)]\tLoss: 1.807708\n",
      "Train Epoch: 6 [2240/50000 (4%)]\tLoss: 1.692466\n",
      "Train Epoch: 6 [2560/50000 (5%)]\tLoss: 1.768912\n",
      "Train Epoch: 6 [2880/50000 (6%)]\tLoss: 1.895631\n",
      "Train Epoch: 6 [3200/50000 (6%)]\tLoss: 1.704115\n",
      "Train Epoch: 6 [3520/50000 (7%)]\tLoss: 1.743567\n",
      "Train Epoch: 6 [3840/50000 (8%)]\tLoss: 1.730618\n",
      "Train Epoch: 6 [4160/50000 (8%)]\tLoss: 1.742365\n",
      "Train Epoch: 6 [4480/50000 (9%)]\tLoss: 1.739629\n",
      "Train Epoch: 6 [4800/50000 (10%)]\tLoss: 1.743750\n",
      "Train Epoch: 6 [5120/50000 (10%)]\tLoss: 1.766040\n",
      "Train Epoch: 6 [5440/50000 (11%)]\tLoss: 1.678118\n",
      "Train Epoch: 6 [5760/50000 (12%)]\tLoss: 1.773977\n",
      "Train Epoch: 6 [6080/50000 (12%)]\tLoss: 1.747038\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 2.178007\n",
      "Train Epoch: 6 [6720/50000 (13%)]\tLoss: 1.797014\n",
      "Train Epoch: 6 [7040/50000 (14%)]\tLoss: 1.926466\n",
      "Train Epoch: 6 [7360/50000 (15%)]\tLoss: 1.774843\n",
      "Train Epoch: 6 [7680/50000 (15%)]\tLoss: 1.780221\n",
      "Train Epoch: 6 [8000/50000 (16%)]\tLoss: 1.842688\n",
      "Train Epoch: 6 [8320/50000 (17%)]\tLoss: 1.674578\n",
      "Train Epoch: 6 [8640/50000 (17%)]\tLoss: 1.699469\n",
      "Train Epoch: 6 [8960/50000 (18%)]\tLoss: 1.679599\n",
      "Train Epoch: 6 [9280/50000 (19%)]\tLoss: 1.912878\n",
      "Train Epoch: 6 [9600/50000 (19%)]\tLoss: 1.346116\n",
      "Train Epoch: 6 [9920/50000 (20%)]\tLoss: 1.912489\n",
      "Train Epoch: 6 [10240/50000 (20%)]\tLoss: 1.721263\n",
      "Train Epoch: 6 [10560/50000 (21%)]\tLoss: 1.866740\n",
      "Train Epoch: 6 [10880/50000 (22%)]\tLoss: 1.813418\n",
      "Train Epoch: 6 [11200/50000 (22%)]\tLoss: 1.695508\n",
      "Train Epoch: 6 [11520/50000 (23%)]\tLoss: 1.995040\n",
      "Train Epoch: 6 [11840/50000 (24%)]\tLoss: 1.827847\n",
      "Train Epoch: 6 [12160/50000 (24%)]\tLoss: 1.815006\n",
      "Train Epoch: 6 [12480/50000 (25%)]\tLoss: 1.698058\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 1.961692\n",
      "Train Epoch: 6 [13120/50000 (26%)]\tLoss: 1.984405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [13440/50000 (27%)]\tLoss: 1.684497\n",
      "Train Epoch: 6 [13760/50000 (28%)]\tLoss: 1.801134\n",
      "Train Epoch: 6 [14080/50000 (28%)]\tLoss: 1.694059\n",
      "Train Epoch: 6 [14400/50000 (29%)]\tLoss: 1.731117\n",
      "Train Epoch: 6 [14720/50000 (29%)]\tLoss: 1.724581\n",
      "Train Epoch: 6 [15040/50000 (30%)]\tLoss: 2.092232\n",
      "Train Epoch: 6 [15360/50000 (31%)]\tLoss: 2.014477\n",
      "Train Epoch: 6 [15680/50000 (31%)]\tLoss: 1.743608\n",
      "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 1.886157\n",
      "Train Epoch: 6 [16320/50000 (33%)]\tLoss: 1.629804\n",
      "Train Epoch: 6 [16640/50000 (33%)]\tLoss: 1.726549\n",
      "Train Epoch: 6 [16960/50000 (34%)]\tLoss: 1.661667\n",
      "Train Epoch: 6 [17280/50000 (35%)]\tLoss: 2.036995\n",
      "Train Epoch: 6 [17600/50000 (35%)]\tLoss: 1.659845\n",
      "Train Epoch: 6 [17920/50000 (36%)]\tLoss: 1.864445\n",
      "Train Epoch: 6 [18240/50000 (36%)]\tLoss: 1.825259\n",
      "Train Epoch: 6 [18560/50000 (37%)]\tLoss: 1.877351\n",
      "Train Epoch: 6 [18880/50000 (38%)]\tLoss: 1.903811\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 1.957149\n",
      "Train Epoch: 6 [19520/50000 (39%)]\tLoss: 1.880522\n",
      "Train Epoch: 6 [19840/50000 (40%)]\tLoss: 1.724401\n",
      "Train Epoch: 6 [20160/50000 (40%)]\tLoss: 1.947365\n",
      "Train Epoch: 6 [20480/50000 (41%)]\tLoss: 1.639859\n",
      "Train Epoch: 6 [20800/50000 (42%)]\tLoss: 1.765259\n",
      "Train Epoch: 6 [21120/50000 (42%)]\tLoss: 1.706580\n",
      "Train Epoch: 6 [21440/50000 (43%)]\tLoss: 1.687539\n",
      "Train Epoch: 6 [21760/50000 (44%)]\tLoss: 1.990981\n",
      "Train Epoch: 6 [22080/50000 (44%)]\tLoss: 1.605094\n",
      "Train Epoch: 6 [22400/50000 (45%)]\tLoss: 1.555833\n",
      "Train Epoch: 6 [22720/50000 (45%)]\tLoss: 1.691572\n",
      "Train Epoch: 6 [23040/50000 (46%)]\tLoss: 1.760060\n",
      "Train Epoch: 6 [23360/50000 (47%)]\tLoss: 1.732440\n",
      "Train Epoch: 6 [23680/50000 (47%)]\tLoss: 1.655675\n",
      "Train Epoch: 6 [24000/50000 (48%)]\tLoss: 1.807439\n",
      "Train Epoch: 6 [24320/50000 (49%)]\tLoss: 1.945027\n",
      "Train Epoch: 6 [24640/50000 (49%)]\tLoss: 1.946225\n",
      "Train Epoch: 6 [24960/50000 (50%)]\tLoss: 1.557089\n",
      "Train Epoch: 6 [25280/50000 (51%)]\tLoss: 2.024484\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.715911\n",
      "Train Epoch: 6 [25920/50000 (52%)]\tLoss: 1.875929\n",
      "Train Epoch: 6 [26240/50000 (52%)]\tLoss: 1.723238\n",
      "Train Epoch: 6 [26560/50000 (53%)]\tLoss: 1.878122\n",
      "Train Epoch: 6 [26880/50000 (54%)]\tLoss: 1.943369\n",
      "Train Epoch: 6 [27200/50000 (54%)]\tLoss: 1.639919\n",
      "Train Epoch: 6 [27520/50000 (55%)]\tLoss: 1.691956\n",
      "Train Epoch: 6 [27840/50000 (56%)]\tLoss: 1.633442\n",
      "Train Epoch: 6 [28160/50000 (56%)]\tLoss: 1.784705\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-868fba32f6e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mbp_VGG5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleak\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdu_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;31m#             print(\"memory after bp\",torch.cuda.memory_allocated()/10000000)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-c00a8145b33b>\u001b[0m in \u001b[0;36mbp_VGG5\u001b[1;34m(vgg, leak, time_step, du_out, l_r, th)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mdu_conv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_conv1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mde_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_lif1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mu_regs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mth\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_lif1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdu_regs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mleak\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_lif1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms_regs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_lif1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdu_regs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdu_conv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mdW_conv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_weight_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdu_conv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms_regs_inp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         \u001b[0mdW_conv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdW_conv1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mdW_conv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdW_conv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdW_conv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdW_conv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-1d57ad5e12b3>\u001b[0m in \u001b[0;36mconv_weight_update\u001b[1;34m(dH, X, pad)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mdH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mdH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mdH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshap\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mdw_conv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "time_step = 15\n",
    "leak = 0.99\n",
    "toy = VGG_5(time_step,leak).cuda()\n",
    "# vgg = VGG_5(time_step)\n",
    "# vgg =vgg.cuda()\n",
    "# print(\"weight\",toy.fc_1.weight)\n",
    "# torch.nn.init.normal_(toy.fc_1.weight, mean=0.0, std=0.1)\n",
    "# toy.fc_1.weight.data = quant(toy.fc_1.weight,2**4)\n",
    "# torch.nn.init.normal_(toy.fc_2.weight, mean=0.0, std=0.1)\n",
    "# toy.fc_2.weight.data = quant(toy.fc_2.weight,2**4)\n",
    "# torch.nn.init.normal_(toy.fc_out.weight, mean=0.0, std=0.1)\n",
    "# toy.fc_out.weight.data = quant(toy.fc_out.weight,2**4)\n",
    "# print(\"quantized weight\",toy.fc_1.weight)\n",
    "lr = 0.0008\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "test(toy)\n",
    "with torch.no_grad():\n",
    "    for epoch in range(12):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader_cifar10):\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            out = toy(data)\n",
    "#             print(\"memory after fwd\",torch.cuda.memory_allocated()/10000000)\n",
    "\n",
    "            err = loss(out,target)\n",
    "\n",
    "            exp = torch.exp(out)\n",
    "            exp_sum = torch.sum(torch.exp(out),1, keepdim=True)   \n",
    "            target = F.one_hot(target, num_classes=10)\n",
    "            #L = -1*torch.sum((target*torch.log((exp/exp_sum))),1, keepdim=True)\n",
    "            du_out = exp/exp_sum\n",
    "            du_out = (du_out - target)/batch_size_train\n",
    "\n",
    "\n",
    "\n",
    "    #         vgg_out = vgg(data)\n",
    "    #         exp_vgg = torch.exp(vgg_out)\n",
    "    #         exp_sum_vgg = torch.sum(torch.exp(vgg_out),1, keepdim=True)\n",
    "    #         du_out_vgg = exp_vgg/exp_sum_vgg\n",
    "    #         du_out_vgg = du_out_vgg - target\n",
    "    #         print(du_out_vgg)\n",
    "\n",
    "\n",
    "\n",
    "            bp_VGG5(toy,leak,time_step,du_out,lr,0.7)\n",
    "#             print(\"memory after bp\",torch.cuda.memory_allocated()/10000000)\n",
    "\n",
    "    #         bp_MLP(toy,leak,time_step,du_out,toy.s_regs_inp,lr,toy.lif1.thresh)\n",
    "\n",
    "\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader_cifar10.dataset),\n",
    "                100. * batch_idx / len(train_loader_cifar10), err.item()))\n",
    "\n",
    "#             del toy.lif_conv1.s_regs\n",
    "#             del toy.lif_conv1.u_regs\n",
    "#             del toy.lif_conv1.du_regs\n",
    "#             del toy.lif_fc1.du_regs\n",
    "#             del toy.lif_fc1.u_regs\n",
    "#             del toy.lif_fc1.s_regs\n",
    "#             del toy.s_regs_conv\n",
    "#             del toy.s_regs_inp\n",
    "#             del data\n",
    "#             del target\n",
    "#             torch.cuda.empty_cache()\n",
    "            \n",
    "#             gc.collect()\n",
    "#             print(\"memory after clear\",torch.cuda.memory_allocated()/10000000)\n",
    "\n",
    "        test(toy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
